Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:07<00:07,  7.23s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.23s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.68s/it]
Map:   0%|          | 0/100 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 7232.81 examples/s]
Map:   0%|          | 0/100 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 2240.18 examples/s]
/home/janeec/.conda/envs/FairTune/lib/python3.10/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  0%|          | 0/39 [00:00<?, ?it/s]  3%|â–Ž         | 1/39 [00:01<00:38,  1.00s/it]  5%|â–Œ         | 2/39 [00:01<00:25,  1.43it/s]  8%|â–Š         | 3/39 [00:01<00:21,  1.67it/s] 10%|â–ˆ         | 4/39 [00:02<00:19,  1.81it/s] 13%|â–ˆâ–Ž        | 5/39 [00:02<00:17,  1.90it/s] 15%|â–ˆâ–Œ        | 6/39 [00:03<00:16,  1.95it/s] 18%|â–ˆâ–Š        | 7/39 [00:03<00:16,  1.99it/s] 21%|â–ˆâ–ˆ        | 8/39 [00:04<00:15,  2.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 9/39 [00:04<00:14,  2.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 10/39 [00:05<00:14,  2.04it/s] 28%|â–ˆâ–ˆâ–Š       | 11/39 [00:05<00:13,  2.05it/s] 31%|â–ˆâ–ˆâ–ˆ       | 12/39 [00:06<00:13,  2.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/39 [00:06<00:10,  2.41it/s]/home/janeec/.conda/envs/FairTune/lib/python3.10/site-packages/peft/utils/other.py:716: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x151ad8fc8250>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 10f9bfb7-7633-47f0-87d1-dd6fc31fd4ba)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/janeec/.conda/envs/FairTune/lib/python3.10/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/39 [00:07<00:11,  2.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/39 [00:07<00:11,  2.13it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/39 [00:08<00:10,  2.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/39 [00:08<00:10,  2.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/39 [00:09<00:10,  2.09it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/39 [00:09<00:09,  2.08it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 20/39 [00:10<00:09,  2.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 21/39 [00:10<00:08,  2.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 22/39 [00:11<00:08,  2.08it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 23/39 [00:11<00:07,  2.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 24/39 [00:11<00:07,  2.08it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 25/39 [00:12<00:06,  2.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 26/39 [00:12<00:05,  2.43it/s]/home/janeec/.conda/envs/FairTune/lib/python3.10/site-packages/peft/utils/other.py:716: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x151ad9024250>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: d58ef498-4864-4a8b-8708-1924f8eeed22)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/janeec/.conda/envs/FairTune/lib/python3.10/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 27/39 [00:13<00:05,  2.20it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 28/39 [00:13<00:05,  2.16it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 29/39 [00:14<00:04,  2.13it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 30/39 [00:14<00:04,  2.12it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 31/39 [00:15<00:03,  2.11it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 32/39 [00:15<00:03,  2.10it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 33/39 [00:16<00:02,  2.10it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 34/39 [00:16<00:02,  2.10it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 35/39 [00:17<00:01,  2.10it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 36/39 [00:17<00:01,  2.09it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 37/39 [00:18<00:00,  2.09it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 38/39 [00:18<00:00,  2.09it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:18<00:00,  2.44it/s]/home/janeec/.conda/envs/FairTune/lib/python3.10/site-packages/peft/utils/other.py:716: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x151ad9078250>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: fc7a5db0-4a11-481a-ad58-e25636a23144)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/janeec/.conda/envs/FairTune/lib/python3.10/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
/home/janeec/.conda/envs/FairTune/lib/python3.10/site-packages/peft/utils/other.py:716: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x151ad90785e0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 7be71e2c-730d-4ba1-8c3d-92acd6b940c3)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/janeec/.conda/envs/FairTune/lib/python3.10/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:18<00:00,  2.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:18<00:00,  2.06it/s]
/home/janeec/.conda/envs/FairTune/lib/python3.10/site-packages/peft/utils/other.py:716: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x151ad90b0250>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 7bfab5f2-af9b-43e8-95cb-34f631b70f80)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/janeec/.conda/envs/FairTune/lib/python3.10/site-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'train_runtime': 18.9092, 'train_samples_per_second': 15.865, 'train_steps_per_second': 2.062, 'train_loss': 2.1349620330028043, 'epoch': 3.0}
Model fine-tuned and saved.
Traceback (most recent call last):
  File "/home/janeec/FairTune/tiny_test/ft_test.py", line 112, in <module>
    evaluate(bbq_dataset=True)
  File "/home/janeec/FairTune/tiny_test/ft_test.py", line 93, in evaluate
    eval_dataset = load_bbq_data(sample_size=100)
  File "/home/janeec/FairTune/tiny_test/ft_test.py", line 60, in load_bbq_data
    bbq_dataset = load_dataset("heegyu/bbq", split="test").to_pandas()
  File "/home/janeec/.conda/envs/FairTune/lib/python3.10/site-packages/datasets/load.py", line 2061, in load_dataset
    builder_instance = load_dataset_builder(
  File "/home/janeec/.conda/envs/FairTune/lib/python3.10/site-packages/datasets/load.py", line 1781, in load_dataset_builder
    dataset_module = dataset_module_factory(
  File "/home/janeec/.conda/envs/FairTune/lib/python3.10/site-packages/datasets/load.py", line 1663, in dataset_module_factory
    raise e1 from None
  File "/home/janeec/.conda/envs/FairTune/lib/python3.10/site-packages/datasets/load.py", line 1550, in dataset_module_factory
    raise ConnectionError(f"Couldn't reach '{path}' on the Hub ({e.__class__.__name__})") from e
ConnectionError: Couldn't reach 'heegyu/bbq' on the Hub (LocalEntryNotFoundError)
