jailbroken_200
start finetuning
2025-03-26 12:04:55.211128: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-03-26 12:04:55.346662: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1743005095.390251 3232791 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1743005095.405737 3232791 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1743005095.524143 3232791 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1743005095.524167 3232791 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1743005095.524169 3232791 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1743005095.524170 3232791 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-03-26 12:04:55.529595: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 3
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
Traceback (most recent call last):
  File "/home/janeec/FairTune/run_finetuning.py", line 69, in <module>
    main()
  File "/home/janeec/FairTune/run_finetuning.py", line 61, in main
    if 'gemma' in args.model:
AttributeError: 'Namespace' object has no attribute 'model'
end finetuning
