alpaca_data_1000
start finetuning
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=24, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/alpaca_data_1000/meta-llama/Llama-3.2-3B-Instruct_24', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='alpaca_data_1000', dataset='datasets/ft/alpaca_data_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.66s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/alpaca_data_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 22069.36 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 2496.28 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 2439.91 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:295: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/alpaca_data_1000.jsonl
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/alpaca_data_1000/meta-llama/Llama-3.2-3B-Instruct_24
===========================
SEED CHECK:, should be: 24, seed is: 24
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:01<04:21,  1.05s/it]  1%|          | 2/250 [00:01<03:14,  1.28it/s]  1%|          | 3/250 [00:02<02:52,  1.43it/s]  2%|▏         | 4/250 [00:02<02:42,  1.52it/s]  2%|▏         | 5/250 [00:03<02:36,  1.57it/s]  2%|▏         | 6/250 [00:04<02:32,  1.60it/s]  3%|▎         | 7/250 [00:04<02:29,  1.62it/s]  3%|▎         | 8/250 [00:05<02:27,  1.64it/s]  4%|▎         | 9/250 [00:05<02:26,  1.65it/s]  4%|▍         | 10/250 [00:06<02:24,  1.66it/s]  4%|▍         | 11/250 [00:07<02:23,  1.66it/s]  5%|▍         | 12/250 [00:07<02:22,  1.67it/s]  5%|▌         | 13/250 [00:08<02:22,  1.67it/s]  6%|▌         | 14/250 [00:08<02:21,  1.67it/s]  6%|▌         | 15/250 [00:09<02:20,  1.67it/s]  6%|▋         | 16/250 [00:10<02:20,  1.67it/s]  7%|▋         | 17/250 [00:10<02:19,  1.67it/s]  7%|▋         | 18/250 [00:11<02:18,  1.67it/s]  8%|▊         | 19/250 [00:11<02:18,  1.67it/s]  8%|▊         | 20/250 [00:12<02:17,  1.67it/s]  8%|▊         | 21/250 [00:13<02:16,  1.67it/s]  9%|▉         | 22/250 [00:13<02:16,  1.67it/s]  9%|▉         | 23/250 [00:14<02:15,  1.67it/s] 10%|▉         | 24/250 [00:14<02:15,  1.67it/s] 10%|█         | 25/250 [00:15<02:14,  1.67it/s] 10%|█         | 26/250 [00:15<02:13,  1.67it/s] 11%|█         | 27/250 [00:16<02:13,  1.67it/s] 11%|█         | 28/250 [00:17<02:13,  1.67it/s] 12%|█▏        | 29/250 [00:17<02:12,  1.67it/s] 12%|█▏        | 30/250 [00:18<02:11,  1.67it/s] 12%|█▏        | 31/250 [00:18<02:11,  1.67it/s] 13%|█▎        | 32/250 [00:19<02:10,  1.67it/s] 13%|█▎        | 33/250 [00:20<02:10,  1.67it/s] 14%|█▎        | 34/250 [00:20<02:09,  1.67it/s] 14%|█▍        | 35/250 [00:21<02:08,  1.67it/s] 14%|█▍        | 36/250 [00:21<02:08,  1.67it/s] 15%|█▍        | 37/250 [00:22<02:07,  1.67it/s] 15%|█▌        | 38/250 [00:23<02:06,  1.67it/s] 16%|█▌        | 39/250 [00:23<02:06,  1.67it/s] 16%|█▌        | 40/250 [00:24<02:05,  1.67it/s] 16%|█▋        | 41/250 [00:24<02:05,  1.67it/s] 17%|█▋        | 42/250 [00:25<02:04,  1.67it/s] 17%|█▋        | 43/250 [00:26<02:04,  1.67it/s] 18%|█▊        | 44/250 [00:26<02:03,  1.67it/s] 18%|█▊        | 45/250 [00:27<02:02,  1.67it/s] 18%|█▊        | 46/250 [00:27<02:02,  1.67it/s] 19%|█▉        | 47/250 [00:28<02:01,  1.67it/s] 19%|█▉        | 48/250 [00:29<02:01,  1.67it/s] 20%|█▉        | 49/250 [00:29<02:00,  1.67it/s] 20%|██        | 50/250 [00:30<02:00,  1.67it/s] 20%|██        | 51/250 [00:30<01:59,  1.67it/s] 21%|██        | 52/250 [00:31<01:59,  1.66it/s] 21%|██        | 53/250 [00:32<01:58,  1.66it/s] 22%|██▏       | 54/250 [00:32<01:58,  1.66it/s] 22%|██▏       | 55/250 [00:33<01:57,  1.65it/s] 22%|██▏       | 56/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 57/250 [00:34<01:56,  1.66it/s] 23%|██▎       | 58/250 [00:35<01:55,  1.66it/s] 24%|██▎       | 59/250 [00:35<01:55,  1.66it/s] 24%|██▍       | 60/250 [00:36<01:54,  1.66it/s] 24%|██▍       | 61/250 [00:37<01:53,  1.66it/s] 25%|██▍       | 62/250 [00:37<01:53,  1.66it/s] 25%|██▌       | 63/250 [00:38<01:52,  1.66it/s] 26%|██▌       | 64/250 [00:38<01:52,  1.66it/s] 26%|██▌       | 65/250 [00:39<01:51,  1.66it/s] 26%|██▋       | 66/250 [00:40<01:50,  1.66it/s] 27%|██▋       | 67/250 [00:40<01:50,  1.66it/s] 27%|██▋       | 68/250 [00:41<01:49,  1.66it/s] 28%|██▊       | 69/250 [00:41<01:48,  1.66it/s] 28%|██▊       | 70/250 [00:42<01:48,  1.66it/s] 28%|██▊       | 71/250 [00:43<01:47,  1.66it/s] 29%|██▉       | 72/250 [00:43<01:47,  1.66it/s] 29%|██▉       | 73/250 [00:44<01:46,  1.66it/s] 30%|██▉       | 74/250 [00:44<01:46,  1.66it/s] 30%|███       | 75/250 [00:45<01:45,  1.66it/s] 30%|███       | 76/250 [00:46<01:44,  1.66it/s] 31%|███       | 77/250 [00:46<01:44,  1.66it/s] 31%|███       | 78/250 [00:47<01:43,  1.66it/s] 32%|███▏      | 79/250 [00:47<01:43,  1.66it/s] 32%|███▏      | 80/250 [00:48<01:42,  1.66it/s] 32%|███▏      | 81/250 [00:49<01:41,  1.66it/s] 33%|███▎      | 82/250 [00:49<01:41,  1.66it/s] 33%|███▎      | 83/250 [00:50<01:40,  1.66it/s] 34%|███▎      | 84/250 [00:50<01:40,  1.66it/s] 34%|███▍      | 85/250 [00:51<01:39,  1.66it/s] 34%|███▍      | 86/250 [00:52<01:39,  1.66it/s] 35%|███▍      | 87/250 [00:52<01:38,  1.65it/s] 35%|███▌      | 88/250 [00:53<01:37,  1.65it/s] 36%|███▌      | 89/250 [00:53<01:37,  1.65it/s] 36%|███▌      | 90/250 [00:54<01:36,  1.65it/s] 36%|███▋      | 91/250 [00:55<01:36,  1.65it/s] 37%|███▋      | 92/250 [00:55<01:35,  1.65it/s] 37%|███▋      | 93/250 [00:56<01:34,  1.65it/s] 38%|███▊      | 94/250 [00:56<01:34,  1.65it/s] 38%|███▊      | 95/250 [00:57<01:33,  1.65it/s] 38%|███▊      | 96/250 [00:58<01:33,  1.65it/s] 39%|███▉      | 97/250 [00:58<01:32,  1.65it/s] 39%|███▉      | 98/250 [00:59<01:31,  1.65it/s] 40%|███▉      | 99/250 [00:59<01:31,  1.65it/s] 40%|████      | 100/250 [01:00<01:30,  1.65it/s]                                                  40%|████      | 100/250 [01:00<01:30,  1.65it/s] 40%|████      | 101/250 [01:01<01:30,  1.65it/s] 41%|████      | 102/250 [01:01<01:29,  1.65it/s] 41%|████      | 103/250 [01:02<01:29,  1.65it/s] 42%|████▏     | 104/250 [01:02<01:28,  1.65it/s] 42%|████▏     | 105/250 [01:03<01:27,  1.65it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.65it/s] 43%|████▎     | 107/250 [01:04<01:26,  1.65it/s] 43%|████▎     | 108/250 [01:05<01:25,  1.65it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.65it/s] 44%|████▍     | 110/250 [01:06<01:24,  1.65it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.65it/s] 45%|████▍     | 112/250 [01:07<01:23,  1.65it/s] 45%|████▌     | 113/250 [01:08<01:23,  1.65it/s] 46%|████▌     | 114/250 [01:09<01:22,  1.65it/s] 46%|████▌     | 115/250 [01:09<01:21,  1.65it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.65it/s] 47%|████▋     | 117/250 [01:10<01:20,  1.65it/s] 47%|████▋     | 118/250 [01:11<01:19,  1.65it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.65it/s] 48%|████▊     | 120/250 [01:12<01:18,  1.65it/s] 48%|████▊     | 121/250 [01:13<01:18,  1.65it/s] 49%|████▉     | 122/250 [01:13<01:17,  1.65it/s] 49%|████▉     | 123/250 [01:14<01:16,  1.65it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.65it/s] 50%|█████     | 125/250 [01:15<01:15,  1.65it/s] 50%|█████     | 126/250 [01:16<01:15,  1.65it/s] 51%|█████     | 127/250 [01:16<01:14,  1.65it/s] 51%|█████     | 128/250 [01:17<01:13,  1.65it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.65it/s] 52%|█████▏    | 130/250 [01:18<01:12,  1.65it/s] 52%|█████▏    | 131/250 [01:19<01:12,  1.65it/s] 53%|█████▎    | 132/250 [01:19<01:11,  1.65it/s] 53%|█████▎    | 133/250 [01:20<01:10,  1.65it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.65it/s] 54%|█████▍    | 135/250 [01:21<01:09,  1.65it/s] 54%|█████▍    | 136/250 [01:22<01:09,  1.65it/s] 55%|█████▍    | 137/250 [01:22<01:08,  1.65it/s] 55%|█████▌    | 138/250 [01:23<01:07,  1.65it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.65it/s] 56%|█████▌    | 140/250 [01:24<01:06,  1.65it/s] 56%|█████▋    | 141/250 [01:25<01:06,  1.65it/s] 57%|█████▋    | 142/250 [01:26<01:05,  1.65it/s] 57%|█████▋    | 143/250 [01:26<01:04,  1.65it/s] 58%|█████▊    | 144/250 [01:27<01:04,  1.65it/s] 58%|█████▊    | 145/250 [01:27<01:03,  1.65it/s] 58%|█████▊    | 146/250 [01:28<01:03,  1.65it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.65it/s] 59%|█████▉    | 148/250 [01:29<01:01,  1.65it/s] 60%|█████▉    | 149/250 [01:30<01:01,  1.65it/s] 60%|██████    | 150/250 [01:30<01:00,  1.65it/s] 60%|██████    | 151/250 [01:31<01:00,  1.65it/s] 61%|██████    | 152/250 [01:32<00:59,  1.65it/s] 61%|██████    | 153/250 [01:32<00:58,  1.65it/s] 62%|██████▏   | 154/250 [01:33<00:58,  1.65it/s] 62%|██████▏   | 155/250 [01:33<00:57,  1.65it/s] 62%|██████▏   | 156/250 [01:34<00:56,  1.65it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.65it/s] 63%|██████▎   | 158/250 [01:35<00:55,  1.65it/s] 64%|██████▎   | 159/250 [01:36<00:55,  1.65it/s] 64%|██████▍   | 160/250 [01:36<00:54,  1.65it/s] 64%|██████▍   | 161/250 [01:37<00:54,  1.65it/s] 65%|██████▍   | 162/250 [01:38<00:53,  1.65it/s] 65%|██████▌   | 163/250 [01:38<00:52,  1.65it/s] 66%|██████▌   | 164/250 [01:39<00:52,  1.65it/s] 66%|██████▌   | 165/250 [01:39<00:51,  1.65it/s] 66%|██████▋   | 166/250 [01:40<00:50,  1.65it/s] 67%|██████▋   | 167/250 [01:41<00:50,  1.65it/s] 67%|██████▋   | 168/250 [01:41<00:49,  1.65it/s] 68%|██████▊   | 169/250 [01:42<00:49,  1.65it/s] 68%|██████▊   | 170/250 [01:42<00:48,  1.65it/s] 68%|██████▊   | 171/250 [01:43<00:47,  1.65it/s] 69%|██████▉   | 172/250 [01:44<00:47,  1.65it/s] 69%|██████▉   | 173/250 [01:44<00:46,  1.65it/s] 70%|██████▉   | 174/250 [01:45<00:46,  1.65it/s] 70%|███████   | 175/250 [01:46<00:45,  1.65it/s] 70%|███████   | 176/250 [01:46<00:44,  1.65it/s] 71%|███████   | 177/250 [01:47<00:44,  1.65it/s] 71%|███████   | 178/250 [01:47<00:43,  1.65it/s] 72%|███████▏  | 179/250 [01:48<00:43,  1.65it/s] 72%|███████▏  | 180/250 [01:49<00:42,  1.65it/s] 72%|███████▏  | 181/250 [01:49<00:41,  1.65it/s] 73%|███████▎  | 182/250 [01:50<00:41,  1.65it/s] 73%|███████▎  | 183/250 [01:50<00:40,  1.65it/s] 74%|███████▎  | 184/250 [01:51<00:40,  1.65it/s] 74%|███████▍  | 185/250 [01:52<00:39,  1.65it/s] 74%|███████▍  | 186/250 [01:52<00:38,  1.65it/s] 75%|███████▍  | 187/250 [01:53<00:38,  1.65it/s] 75%|███████▌  | 188/250 [01:53<00:37,  1.65it/s] 76%|███████▌  | 189/250 [01:54<00:37,  1.65it/s] 76%|███████▌  | 190/250 [01:55<00:36,  1.65it/s] 76%|███████▋  | 191/250 [01:55<00:35,  1.65it/s] 77%|███████▋  | 192/250 [01:56<00:35,  1.65it/s] 77%|███████▋  | 193/250 [01:56<00:34,  1.65it/s] 78%|███████▊  | 194/250 [01:57<00:34,  1.65it/s] 78%|███████▊  | 195/250 [01:58<00:33,  1.65it/s] 78%|███████▊  | 196/250 [01:58<00:32,  1.65it/s] 79%|███████▉  | 197/250 [01:59<00:32,  1.65it/s] 79%|███████▉  | 198/250 [01:59<00:31,  1.65it/s] 80%|███████▉  | 199/250 [02:00<00:30,  1.65it/s] 80%|████████  | 200/250 [02:01<00:30,  1.65it/s]                                                  80%|████████  | 200/250 [02:01<00:30,  1.65it/s] 80%|████████  | 201/250 [02:01<00:29,  1.65it/s] 81%|████████  | 202/250 [02:02<00:29,  1.65it/s] 81%|████████  | 203/250 [02:03<00:28,  1.65it/s] 82%|████████▏ | 204/250 [02:03<00:27,  1.65it/s] 82%|████████▏ | 205/250 [02:04<00:27,  1.65it/s] 82%|████████▏ | 206/250 [02:04<00:26,  1.65it/s] 83%|████████▎ | 207/250 [02:05<00:26,  1.65it/s] 83%|████████▎ | 208/250 [02:06<00:25,  1.65it/s] 84%|████████▎ | 209/250 [02:06<00:24,  1.65it/s] 84%|████████▍ | 210/250 [02:07<00:24,  1.65it/s] 84%|████████▍ | 211/250 [02:07<00:23,  1.65it/s] 85%|████████▍ | 212/250 [02:08<00:23,  1.65it/s] 85%|████████▌ | 213/250 [02:09<00:22,  1.65it/s] 86%|████████▌ | 214/250 [02:09<00:21,  1.65it/s] 86%|████████▌ | 215/250 [02:10<00:21,  1.65it/s] 86%|████████▋ | 216/250 [02:10<00:20,  1.65it/s] 87%|████████▋ | 217/250 [02:11<00:20,  1.65it/s] 87%|████████▋ | 218/250 [02:12<00:19,  1.65it/s] 88%|████████▊ | 219/250 [02:12<00:18,  1.65it/s] 88%|████████▊ | 220/250 [02:13<00:18,  1.65it/s] 88%|████████▊ | 221/250 [02:13<00:17,  1.65it/s] 89%|████████▉ | 222/250 [02:14<00:17,  1.65it/s] 89%|████████▉ | 223/250 [02:15<00:16,  1.65it/s] 90%|████████▉ | 224/250 [02:15<00:15,  1.65it/s] 90%|█████████ | 225/250 [02:16<00:15,  1.65it/s] 90%|█████████ | 226/250 [02:16<00:14,  1.65it/s] 91%|█████████ | 227/250 [02:17<00:13,  1.65it/s] 91%|█████████ | 228/250 [02:18<00:13,  1.64it/s] 92%|█████████▏| 229/250 [02:18<00:12,  1.65it/s] 92%|█████████▏| 230/250 [02:19<00:12,  1.65it/s] 92%|█████████▏| 231/250 [02:20<00:11,  1.65it/s] 93%|█████████▎| 232/250 [02:20<00:10,  1.65it/s] 93%|█████████▎| 233/250 [02:21<00:10,  1.65it/s] 94%|█████████▎| 234/250 [02:21<00:09,  1.65it/s] 94%|█████████▍| 235/250 [02:22<00:09,  1.65it/s] 94%|█████████▍| 236/250 [02:23<00:08,  1.65it/s] 95%|█████████▍| 237/250 [02:23<00:07,  1.65it/s] 95%|█████████▌| 238/250 [02:24<00:07,  1.65it/s] 96%|█████████▌| 239/250 [02:24<00:06,  1.65it/s] 96%|█████████▌| 240/250 [02:25<00:06,  1.65it/s] 96%|█████████▋| 241/250 [02:26<00:05,  1.65it/s] 97%|█████████▋| 242/250 [02:26<00:04,  1.65it/s] 97%|█████████▋| 243/250 [02:27<00:04,  1.65it/s] 98%|█████████▊| 244/250 [02:27<00:03,  1.65it/s] 98%|█████████▊| 245/250 [02:28<00:03,  1.65it/s] 98%|█████████▊| 246/250 [02:29<00:02,  1.65it/s] 99%|█████████▉| 247/250 [02:29<00:01,  1.65it/s] 99%|█████████▉| 248/250 [02:30<00:01,  1.65it/s]100%|█████████▉| 249/250 [02:30<00:00,  1.65it/s]100%|██████████| 250/250 [02:31<00:00,  1.65it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x1514c9a1bb30>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: c705975f-9893-4f48-858d-ee4a66409a35)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:31<00:00,  1.65it/s]100%|██████████| 250/250 [02:31<00:00,  1.65it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x1514c805aed0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 5eddee76-c069-4d78-836d-487cc3c50d55)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.9955, 'grad_norm': 1.8053861856460571, 'learning_rate': 1.216e-05, 'epoch': 0.4}
{'loss': 1.6019, 'grad_norm': 2.7969279289245605, 'learning_rate': 4.16e-06, 'epoch': 0.8}
{'train_runtime': 151.8308, 'train_samples_per_second': 6.586, 'train_steps_per_second': 1.647, 'train_loss': 1.7547502136230468, 'epoch': 1.0}
Saving model to finetuned_models/alpaca_data_1000/meta-llama/Llama-3.2-3B-Instruct_24
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=58, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/alpaca_data_1000/meta-llama/Llama-3.2-3B-Instruct_58', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='alpaca_data_1000', dataset='datasets/ft/alpaca_data_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/alpaca_data_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 24341.62 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 2397.84 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 2341.50 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/alpaca_data_1000.jsonl
Random seed: 58
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/alpaca_data_1000/meta-llama/Llama-3.2-3B-Instruct_58
===========================
SEED CHECK:, should be: 58, seed is: 58
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:46,  1.10it/s]  1%|          | 2/250 [00:01<03:01,  1.37it/s]  1%|          | 3/250 [00:02<02:45,  1.49it/s]  2%|▏         | 4/250 [00:02<02:38,  1.55it/s]  2%|▏         | 5/250 [00:03<02:34,  1.59it/s]  2%|▏         | 6/250 [00:03<02:31,  1.61it/s]  3%|▎         | 7/250 [00:04<02:29,  1.63it/s]  3%|▎         | 8/250 [00:05<02:27,  1.64it/s]  4%|▎         | 9/250 [00:05<02:26,  1.65it/s]  4%|▍         | 10/250 [00:06<02:25,  1.65it/s]  4%|▍         | 11/250 [00:06<02:24,  1.65it/s]  5%|▍         | 12/250 [00:07<02:23,  1.66it/s]  5%|▌         | 13/250 [00:08<02:23,  1.66it/s]  6%|▌         | 14/250 [00:08<02:22,  1.66it/s]  6%|▌         | 15/250 [00:09<02:21,  1.66it/s]  6%|▋         | 16/250 [00:09<02:21,  1.66it/s]  7%|▋         | 17/250 [00:10<02:20,  1.66it/s]  7%|▋         | 18/250 [00:11<02:19,  1.66it/s]  8%|▊         | 19/250 [00:11<02:19,  1.66it/s]  8%|▊         | 20/250 [00:12<02:18,  1.66it/s]  8%|▊         | 21/250 [00:12<02:18,  1.66it/s]  9%|▉         | 22/250 [00:13<02:17,  1.66it/s]  9%|▉         | 23/250 [00:14<02:16,  1.66it/s] 10%|▉         | 24/250 [00:14<02:16,  1.66it/s] 10%|█         | 25/250 [00:15<02:15,  1.66it/s] 10%|█         | 26/250 [00:15<02:15,  1.66it/s] 11%|█         | 27/250 [00:16<02:14,  1.66it/s] 11%|█         | 28/250 [00:17<02:14,  1.66it/s] 12%|█▏        | 29/250 [00:17<02:13,  1.66it/s] 12%|█▏        | 30/250 [00:18<02:12,  1.66it/s] 12%|█▏        | 31/250 [00:19<02:12,  1.66it/s] 13%|█▎        | 32/250 [00:19<02:11,  1.66it/s] 13%|█▎        | 33/250 [00:20<02:10,  1.66it/s] 14%|█▎        | 34/250 [00:20<02:10,  1.66it/s] 14%|█▍        | 35/250 [00:21<02:09,  1.66it/s] 14%|█▍        | 36/250 [00:22<02:09,  1.66it/s] 15%|█▍        | 37/250 [00:22<02:08,  1.66it/s] 15%|█▌        | 38/250 [00:23<02:07,  1.66it/s] 16%|█▌        | 39/250 [00:23<02:07,  1.66it/s] 16%|█▌        | 40/250 [00:24<02:06,  1.66it/s] 16%|█▋        | 41/250 [00:25<02:06,  1.66it/s] 17%|█▋        | 42/250 [00:25<02:05,  1.66it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.65it/s] 18%|█▊        | 44/250 [00:26<02:04,  1.65it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.65it/s] 18%|█▊        | 46/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 47/250 [00:28<02:02,  1.65it/s] 19%|█▉        | 48/250 [00:29<02:02,  1.65it/s] 20%|█▉        | 49/250 [00:29<02:01,  1.65it/s] 20%|██        | 50/250 [00:30<02:00,  1.65it/s] 20%|██        | 51/250 [00:31<02:00,  1.65it/s] 21%|██        | 52/250 [00:31<01:59,  1.65it/s] 21%|██        | 53/250 [00:32<01:59,  1.65it/s] 22%|██▏       | 54/250 [00:32<01:58,  1.65it/s] 22%|██▏       | 55/250 [00:33<01:57,  1.65it/s] 22%|██▏       | 56/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 57/250 [00:34<01:56,  1.65it/s] 23%|██▎       | 58/250 [00:35<01:56,  1.65it/s] 24%|██▎       | 59/250 [00:35<01:55,  1.65it/s] 24%|██▍       | 60/250 [00:36<01:54,  1.65it/s] 24%|██▍       | 61/250 [00:37<01:54,  1.65it/s] 25%|██▍       | 62/250 [00:37<01:53,  1.65it/s] 25%|██▌       | 63/250 [00:38<01:53,  1.65it/s] 26%|██▌       | 64/250 [00:38<01:52,  1.65it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.65it/s] 26%|██▋       | 66/250 [00:40<01:51,  1.65it/s] 27%|██▋       | 67/250 [00:40<01:50,  1.65it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.65it/s] 28%|██▊       | 69/250 [00:41<01:49,  1.65it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 71/250 [00:43<01:48,  1.65it/s] 29%|██▉       | 72/250 [00:43<01:47,  1.65it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.65it/s] 30%|██▉       | 74/250 [00:45<01:46,  1.65it/s] 30%|███       | 75/250 [00:45<01:45,  1.65it/s] 30%|███       | 76/250 [00:46<01:45,  1.65it/s] 31%|███       | 77/250 [00:46<01:44,  1.65it/s] 31%|███       | 78/250 [00:47<01:44,  1.65it/s] 32%|███▏      | 79/250 [00:48<01:43,  1.65it/s] 32%|███▏      | 80/250 [00:48<01:42,  1.65it/s] 32%|███▏      | 81/250 [00:49<01:42,  1.65it/s] 33%|███▎      | 82/250 [00:49<01:41,  1.65it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.65it/s] 34%|███▎      | 84/250 [00:51<01:40,  1.65it/s] 34%|███▍      | 85/250 [00:51<01:39,  1.65it/s] 34%|███▍      | 86/250 [00:52<01:39,  1.65it/s] 35%|███▍      | 87/250 [00:52<01:38,  1.65it/s] 35%|███▌      | 88/250 [00:53<01:38,  1.65it/s] 36%|███▌      | 89/250 [00:54<01:37,  1.65it/s] 36%|███▌      | 90/250 [00:54<01:36,  1.65it/s] 36%|███▋      | 91/250 [00:55<01:36,  1.65it/s] 37%|███▋      | 92/250 [00:55<01:35,  1.65it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.65it/s] 38%|███▊      | 94/250 [00:57<01:34,  1.65it/s] 38%|███▊      | 95/250 [00:57<01:34,  1.65it/s] 38%|███▊      | 96/250 [00:58<01:33,  1.65it/s] 39%|███▉      | 97/250 [00:58<01:32,  1.65it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.65it/s] 40%|███▉      | 99/250 [01:00<01:31,  1.65it/s] 40%|████      | 100/250 [01:00<01:30,  1.65it/s]                                                  40%|████      | 100/250 [01:00<01:30,  1.65it/s] 40%|████      | 101/250 [01:01<01:30,  1.65it/s] 41%|████      | 102/250 [01:01<01:29,  1.65it/s] 41%|████      | 103/250 [01:02<01:29,  1.65it/s] 42%|████▏     | 104/250 [01:03<01:28,  1.65it/s] 42%|████▏     | 105/250 [01:03<01:27,  1.65it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.65it/s] 43%|████▎     | 107/250 [01:05<01:26,  1.65it/s] 43%|████▎     | 108/250 [01:05<01:26,  1.65it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.65it/s] 44%|████▍     | 110/250 [01:06<01:24,  1.65it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.65it/s] 45%|████▍     | 112/250 [01:08<01:23,  1.65it/s] 45%|████▌     | 113/250 [01:08<01:23,  1.65it/s] 46%|████▌     | 114/250 [01:09<01:22,  1.65it/s] 46%|████▌     | 115/250 [01:09<01:21,  1.65it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.65it/s] 47%|████▋     | 117/250 [01:11<01:20,  1.65it/s] 47%|████▋     | 118/250 [01:11<01:20,  1.65it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.65it/s] 48%|████▊     | 120/250 [01:12<01:18,  1.65it/s] 48%|████▊     | 121/250 [01:13<01:18,  1.65it/s] 49%|████▉     | 122/250 [01:14<01:17,  1.65it/s] 49%|████▉     | 123/250 [01:14<01:16,  1.65it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.65it/s] 50%|█████     | 125/250 [01:15<01:15,  1.65it/s] 50%|█████     | 126/250 [01:16<01:15,  1.65it/s] 51%|█████     | 127/250 [01:17<01:14,  1.65it/s] 51%|█████     | 128/250 [01:17<01:13,  1.65it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.65it/s] 52%|█████▏    | 130/250 [01:18<01:12,  1.65it/s] 52%|█████▏    | 131/250 [01:19<01:12,  1.65it/s] 53%|█████▎    | 132/250 [01:20<01:11,  1.65it/s] 53%|█████▎    | 133/250 [01:20<01:10,  1.65it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.65it/s] 54%|█████▍    | 135/250 [01:21<01:09,  1.65it/s] 54%|█████▍    | 136/250 [01:22<01:09,  1.65it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.65it/s] 55%|█████▌    | 138/250 [01:23<01:07,  1.65it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.65it/s] 56%|█████▌    | 140/250 [01:25<01:06,  1.65it/s] 56%|█████▋    | 141/250 [01:25<01:06,  1.65it/s] 57%|█████▋    | 142/250 [01:26<01:05,  1.65it/s] 57%|█████▋    | 143/250 [01:26<01:04,  1.65it/s] 58%|█████▊    | 144/250 [01:27<01:04,  1.65it/s] 58%|█████▊    | 145/250 [01:28<01:03,  1.65it/s] 58%|█████▊    | 146/250 [01:28<01:03,  1.65it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.65it/s] 59%|█████▉    | 148/250 [01:29<01:01,  1.65it/s] 60%|█████▉    | 149/250 [01:30<01:01,  1.65it/s] 60%|██████    | 150/250 [01:31<01:00,  1.65it/s] 60%|██████    | 151/250 [01:31<01:00,  1.65it/s] 61%|██████    | 152/250 [01:32<00:59,  1.65it/s] 61%|██████    | 153/250 [01:32<00:58,  1.65it/s] 62%|██████▏   | 154/250 [01:33<00:58,  1.65it/s] 62%|██████▏   | 155/250 [01:34<00:57,  1.65it/s] 62%|██████▏   | 156/250 [01:34<00:56,  1.65it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.65it/s] 63%|██████▎   | 158/250 [01:35<00:55,  1.65it/s] 64%|██████▎   | 159/250 [01:36<00:55,  1.65it/s] 64%|██████▍   | 160/250 [01:37<00:54,  1.65it/s] 64%|██████▍   | 161/250 [01:37<00:54,  1.65it/s] 65%|██████▍   | 162/250 [01:38<00:53,  1.65it/s] 65%|██████▌   | 163/250 [01:38<00:52,  1.65it/s] 66%|██████▌   | 164/250 [01:39<00:52,  1.65it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.65it/s] 66%|██████▋   | 166/250 [01:40<00:50,  1.65it/s] 67%|██████▋   | 167/250 [01:41<00:50,  1.65it/s] 67%|██████▋   | 168/250 [01:42<00:49,  1.65it/s] 68%|██████▊   | 169/250 [01:42<00:49,  1.65it/s] 68%|██████▊   | 170/250 [01:43<00:48,  1.65it/s] 68%|██████▊   | 171/250 [01:43<00:47,  1.65it/s] 69%|██████▉   | 172/250 [01:44<00:47,  1.65it/s] 69%|██████▉   | 173/250 [01:45<00:46,  1.65it/s] 70%|██████▉   | 174/250 [01:45<00:46,  1.65it/s] 70%|███████   | 175/250 [01:46<00:45,  1.65it/s] 70%|███████   | 176/250 [01:46<00:44,  1.65it/s] 71%|███████   | 177/250 [01:47<00:44,  1.65it/s] 71%|███████   | 178/250 [01:48<00:43,  1.65it/s] 72%|███████▏  | 179/250 [01:48<00:43,  1.65it/s] 72%|███████▏  | 180/250 [01:49<00:42,  1.65it/s] 72%|███████▏  | 181/250 [01:49<00:41,  1.65it/s] 73%|███████▎  | 182/250 [01:50<00:41,  1.65it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.65it/s] 74%|███████▎  | 184/250 [01:51<00:40,  1.65it/s] 74%|███████▍  | 185/250 [01:52<00:39,  1.65it/s] 74%|███████▍  | 186/250 [01:52<00:38,  1.65it/s] 75%|███████▍  | 187/250 [01:53<00:38,  1.65it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.65it/s] 76%|███████▌  | 189/250 [01:54<00:36,  1.65it/s] 76%|███████▌  | 190/250 [01:55<00:36,  1.65it/s] 76%|███████▋  | 191/250 [01:55<00:35,  1.65it/s] 77%|███████▋  | 192/250 [01:56<00:35,  1.65it/s] 77%|███████▋  | 193/250 [01:57<00:34,  1.65it/s] 78%|███████▊  | 194/250 [01:57<00:33,  1.65it/s] 78%|███████▊  | 195/250 [01:58<00:33,  1.65it/s] 78%|███████▊  | 196/250 [01:58<00:32,  1.65it/s] 79%|███████▉  | 197/250 [01:59<00:32,  1.65it/s] 79%|███████▉  | 198/250 [02:00<00:31,  1.65it/s] 80%|███████▉  | 199/250 [02:00<00:30,  1.65it/s] 80%|████████  | 200/250 [02:01<00:30,  1.65it/s]                                                  80%|████████  | 200/250 [02:01<00:30,  1.65it/s] 80%|████████  | 201/250 [02:02<00:29,  1.65it/s] 81%|████████  | 202/250 [02:02<00:29,  1.65it/s] 81%|████████  | 203/250 [02:03<00:28,  1.65it/s] 82%|████████▏ | 204/250 [02:03<00:27,  1.65it/s] 82%|████████▏ | 205/250 [02:04<00:27,  1.65it/s] 82%|████████▏ | 206/250 [02:05<00:26,  1.65it/s] 83%|████████▎ | 207/250 [02:05<00:26,  1.65it/s] 83%|████████▎ | 208/250 [02:06<00:25,  1.65it/s] 84%|████████▎ | 209/250 [02:06<00:24,  1.65it/s] 84%|████████▍ | 210/250 [02:07<00:24,  1.65it/s] 84%|████████▍ | 211/250 [02:08<00:23,  1.65it/s] 85%|████████▍ | 212/250 [02:08<00:23,  1.65it/s] 85%|████████▌ | 213/250 [02:09<00:22,  1.65it/s] 86%|████████▌ | 214/250 [02:09<00:21,  1.65it/s] 86%|████████▌ | 215/250 [02:10<00:21,  1.65it/s] 86%|████████▋ | 216/250 [02:11<00:20,  1.65it/s] 87%|████████▋ | 217/250 [02:11<00:19,  1.65it/s] 87%|████████▋ | 218/250 [02:12<00:19,  1.65it/s] 88%|████████▊ | 219/250 [02:12<00:18,  1.65it/s] 88%|████████▊ | 220/250 [02:13<00:18,  1.65it/s] 88%|████████▊ | 221/250 [02:14<00:17,  1.65it/s] 89%|████████▉ | 222/250 [02:14<00:16,  1.65it/s] 89%|████████▉ | 223/250 [02:15<00:16,  1.65it/s] 90%|████████▉ | 224/250 [02:15<00:15,  1.65it/s] 90%|█████████ | 225/250 [02:16<00:15,  1.65it/s] 90%|█████████ | 226/250 [02:17<00:14,  1.65it/s] 91%|█████████ | 227/250 [02:17<00:13,  1.65it/s] 91%|█████████ | 228/250 [02:18<00:13,  1.65it/s] 92%|█████████▏| 229/250 [02:18<00:12,  1.65it/s] 92%|█████████▏| 230/250 [02:19<00:12,  1.65it/s] 92%|█████████▏| 231/250 [02:20<00:11,  1.65it/s] 93%|█████████▎| 232/250 [02:20<00:10,  1.65it/s] 93%|█████████▎| 233/250 [02:21<00:10,  1.65it/s] 94%|█████████▎| 234/250 [02:22<00:09,  1.65it/s] 94%|█████████▍| 235/250 [02:22<00:09,  1.65it/s] 94%|█████████▍| 236/250 [02:23<00:08,  1.65it/s] 95%|█████████▍| 237/250 [02:23<00:07,  1.65it/s] 95%|█████████▌| 238/250 [02:24<00:07,  1.65it/s] 96%|█████████▌| 239/250 [02:25<00:06,  1.65it/s] 96%|█████████▌| 240/250 [02:25<00:06,  1.65it/s] 96%|█████████▋| 241/250 [02:26<00:05,  1.65it/s] 97%|█████████▋| 242/250 [02:26<00:04,  1.65it/s] 97%|█████████▋| 243/250 [02:27<00:04,  1.65it/s] 98%|█████████▊| 244/250 [02:28<00:03,  1.65it/s] 98%|█████████▊| 245/250 [02:28<00:03,  1.65it/s] 98%|█████████▊| 246/250 [02:29<00:02,  1.65it/s] 99%|█████████▉| 247/250 [02:29<00:01,  1.65it/s] 99%|█████████▉| 248/250 [02:30<00:01,  1.65it/s]100%|█████████▉| 249/250 [02:31<00:00,  1.65it/s]100%|██████████| 250/250 [02:31<00:00,  1.65it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x1464c356dbe0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: f530a94f-19ca-4c25-9000-26029d26940e)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:31<00:00,  1.65it/s]100%|██████████| 250/250 [02:31<00:00,  1.65it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x1464c0c54140>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 7096d60f-ad4c-4ec0-9936-f60b7e6c9703)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.9421, 'grad_norm': 0.8583049774169922, 'learning_rate': 1.216e-05, 'epoch': 0.4}
{'loss': 1.617, 'grad_norm': 1.400528907775879, 'learning_rate': 4.16e-06, 'epoch': 0.8}
{'train_runtime': 151.9459, 'train_samples_per_second': 6.581, 'train_steps_per_second': 1.645, 'train_loss': 1.7452434692382812, 'epoch': 1.0}
Saving model to finetuned_models/alpaca_data_1000/meta-llama/Llama-3.2-3B-Instruct_58
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=60, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/alpaca_data_1000/meta-llama/Llama-3.2-3B-Instruct_60', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='alpaca_data_1000', dataset='datasets/ft/alpaca_data_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/alpaca_data_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 24173.83 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 2386.42 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 2329.54 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/alpaca_data_1000.jsonl
Random seed: 60
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/alpaca_data_1000/meta-llama/Llama-3.2-3B-Instruct_60
===========================
SEED CHECK:, should be: 60, seed is: 60
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:46,  1.10it/s]  1%|          | 2/250 [00:01<03:01,  1.37it/s]  1%|          | 3/250 [00:02<02:46,  1.49it/s]  2%|▏         | 4/250 [00:02<02:39,  1.55it/s]  2%|▏         | 5/250 [00:03<02:34,  1.58it/s]  2%|▏         | 6/250 [00:03<02:31,  1.61it/s]  3%|▎         | 7/250 [00:04<02:29,  1.62it/s]  3%|▎         | 8/250 [00:05<02:28,  1.63it/s]  4%|▎         | 9/250 [00:05<02:26,  1.64it/s]  4%|▍         | 10/250 [00:06<02:25,  1.65it/s]  4%|▍         | 11/250 [00:06<02:25,  1.65it/s]  5%|▍         | 12/250 [00:07<02:24,  1.65it/s]  5%|▌         | 13/250 [00:08<02:23,  1.65it/s]  6%|▌         | 14/250 [00:08<02:22,  1.65it/s]  6%|▌         | 15/250 [00:09<02:22,  1.65it/s]  6%|▋         | 16/250 [00:09<02:21,  1.65it/s]  7%|▋         | 17/250 [00:10<02:20,  1.65it/s]  7%|▋         | 18/250 [00:11<02:20,  1.65it/s]  8%|▊         | 19/250 [00:11<02:19,  1.66it/s]  8%|▊         | 20/250 [00:12<02:18,  1.66it/s]  8%|▊         | 21/250 [00:12<02:18,  1.66it/s]  9%|▉         | 22/250 [00:13<02:17,  1.66it/s]  9%|▉         | 23/250 [00:14<02:17,  1.65it/s] 10%|▉         | 24/250 [00:14<02:16,  1.65it/s] 10%|█         | 25/250 [00:15<02:16,  1.65it/s] 10%|█         | 26/250 [00:16<02:15,  1.65it/s] 11%|█         | 27/250 [00:16<02:14,  1.65it/s] 11%|█         | 28/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 29/250 [00:17<02:13,  1.65it/s] 12%|█▏        | 30/250 [00:18<02:12,  1.65it/s] 12%|█▏        | 31/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 32/250 [00:19<02:11,  1.65it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.65it/s] 14%|█▎        | 34/250 [00:20<02:10,  1.65it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.65it/s] 14%|█▍        | 36/250 [00:22<02:09,  1.65it/s] 15%|█▍        | 37/250 [00:22<02:09,  1.65it/s] 15%|█▌        | 38/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 39/250 [00:23<02:07,  1.65it/s] 16%|█▌        | 40/250 [00:24<02:07,  1.65it/s] 16%|█▋        | 41/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 42/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.65it/s] 18%|█▊        | 44/250 [00:26<02:04,  1.65it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.65it/s] 18%|█▊        | 46/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 47/250 [00:28<02:02,  1.65it/s] 19%|█▉        | 48/250 [00:29<02:02,  1.65it/s] 20%|█▉        | 49/250 [00:29<02:01,  1.65it/s] 20%|██        | 50/250 [00:30<02:01,  1.65it/s] 20%|██        | 51/250 [00:31<02:00,  1.65it/s] 21%|██        | 52/250 [00:31<01:59,  1.65it/s] 21%|██        | 53/250 [00:32<01:59,  1.65it/s] 22%|██▏       | 54/250 [00:32<01:58,  1.65it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.65it/s] 22%|██▏       | 56/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 58/250 [00:35<01:56,  1.65it/s] 24%|██▎       | 59/250 [00:36<01:55,  1.65it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.65it/s] 24%|██▍       | 61/250 [00:37<01:54,  1.65it/s] 25%|██▍       | 62/250 [00:37<01:54,  1.64it/s] 25%|██▌       | 63/250 [00:38<01:53,  1.65it/s] 26%|██▌       | 64/250 [00:39<01:53,  1.64it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.64it/s] 26%|██▋       | 66/250 [00:40<01:52,  1.64it/s] 27%|██▋       | 67/250 [00:40<01:51,  1.64it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.64it/s] 28%|██▊       | 69/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 71/250 [00:43<01:48,  1.65it/s] 29%|██▉       | 72/250 [00:43<01:48,  1.65it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.65it/s] 30%|██▉       | 74/250 [00:45<01:46,  1.65it/s] 30%|███       | 75/250 [00:45<01:46,  1.65it/s] 30%|███       | 76/250 [00:46<01:45,  1.65it/s] 31%|███       | 77/250 [00:46<01:44,  1.65it/s] 31%|███       | 78/250 [00:47<01:44,  1.65it/s] 32%|███▏      | 79/250 [00:48<01:43,  1.65it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.65it/s] 32%|███▏      | 81/250 [00:49<01:42,  1.65it/s] 33%|███▎      | 82/250 [00:49<01:41,  1.65it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.65it/s] 34%|███▎      | 84/250 [00:51<01:40,  1.65it/s] 34%|███▍      | 85/250 [00:51<01:40,  1.65it/s] 34%|███▍      | 86/250 [00:52<01:39,  1.65it/s] 35%|███▍      | 87/250 [00:53<01:38,  1.65it/s] 35%|███▌      | 88/250 [00:53<01:38,  1.65it/s] 36%|███▌      | 89/250 [00:54<01:37,  1.65it/s] 36%|███▌      | 90/250 [00:54<01:37,  1.65it/s] 36%|███▋      | 91/250 [00:55<01:36,  1.65it/s] 37%|███▋      | 92/250 [00:56<01:35,  1.65it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.65it/s] 38%|███▊      | 94/250 [00:57<01:34,  1.65it/s] 38%|███▊      | 95/250 [00:57<01:34,  1.65it/s] 38%|███▊      | 96/250 [00:58<01:33,  1.65it/s] 39%|███▉      | 97/250 [00:59<01:32,  1.65it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.65it/s] 40%|███▉      | 99/250 [01:00<01:31,  1.65it/s] 40%|████      | 100/250 [01:00<01:31,  1.65it/s]                                                  40%|████      | 100/250 [01:00<01:31,  1.65it/s] 40%|████      | 101/250 [01:01<01:30,  1.65it/s] 41%|████      | 102/250 [01:02<01:29,  1.65it/s] 41%|████      | 103/250 [01:02<01:29,  1.65it/s] 42%|████▏     | 104/250 [01:03<01:28,  1.65it/s] 42%|████▏     | 105/250 [01:03<01:28,  1.65it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.64it/s] 43%|████▎     | 107/250 [01:05<01:26,  1.64it/s] 43%|████▎     | 108/250 [01:05<01:26,  1.64it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.64it/s] 44%|████▍     | 110/250 [01:06<01:25,  1.64it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.64it/s] 45%|████▍     | 112/250 [01:08<01:23,  1.64it/s] 45%|████▌     | 113/250 [01:08<01:23,  1.64it/s] 46%|████▌     | 114/250 [01:09<01:22,  1.64it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.64it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.64it/s] 47%|████▋     | 117/250 [01:11<01:20,  1.64it/s] 47%|████▋     | 118/250 [01:11<01:20,  1.64it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.64it/s] 48%|████▊     | 120/250 [01:13<01:19,  1.64it/s] 48%|████▊     | 121/250 [01:13<01:18,  1.64it/s] 49%|████▉     | 122/250 [01:14<01:17,  1.64it/s] 49%|████▉     | 123/250 [01:14<01:17,  1.64it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.64it/s] 50%|█████     | 125/250 [01:16<01:16,  1.64it/s] 50%|█████     | 126/250 [01:16<01:15,  1.64it/s] 51%|█████     | 127/250 [01:17<01:14,  1.64it/s] 51%|█████     | 128/250 [01:17<01:14,  1.64it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.64it/s] 52%|█████▏    | 130/250 [01:19<01:13,  1.64it/s] 52%|█████▏    | 131/250 [01:19<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:11,  1.64it/s] 53%|█████▎    | 133/250 [01:20<01:11,  1.64it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.64it/s] 54%|█████▍    | 135/250 [01:22<01:10,  1.64it/s] 54%|█████▍    | 136/250 [01:22<01:09,  1.64it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.64it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.64it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.64it/s] 56%|█████▌    | 140/250 [01:25<01:07,  1.64it/s] 56%|█████▋    | 141/250 [01:25<01:06,  1.64it/s] 57%|█████▋    | 142/250 [01:26<01:05,  1.64it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.64it/s] 58%|█████▊    | 144/250 [01:27<01:04,  1.64it/s] 58%|█████▊    | 145/250 [01:28<01:03,  1.64it/s] 58%|█████▊    | 146/250 [01:28<01:03,  1.64it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.64it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.64it/s] 60%|█████▉    | 149/250 [01:30<01:01,  1.64it/s] 60%|██████    | 150/250 [01:31<01:00,  1.64it/s] 60%|██████    | 151/250 [01:31<01:00,  1.64it/s] 61%|██████    | 152/250 [01:32<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:59,  1.64it/s] 62%|██████▏   | 154/250 [01:33<00:58,  1.64it/s] 62%|██████▏   | 155/250 [01:34<00:57,  1.64it/s] 62%|██████▏   | 156/250 [01:35<00:57,  1.64it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.64it/s] 63%|██████▎   | 158/250 [01:36<00:56,  1.64it/s] 64%|██████▎   | 159/250 [01:36<00:55,  1.64it/s] 64%|██████▍   | 160/250 [01:37<00:54,  1.64it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s] 65%|██████▍   | 162/250 [01:38<00:53,  1.64it/s] 65%|██████▌   | 163/250 [01:39<00:53,  1.64it/s] 66%|██████▌   | 164/250 [01:39<00:52,  1.64it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.64it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.64it/s] 67%|██████▋   | 167/250 [01:41<00:50,  1.64it/s] 67%|██████▋   | 168/250 [01:42<00:50,  1.64it/s] 68%|██████▊   | 169/250 [01:42<00:49,  1.64it/s] 68%|██████▊   | 170/250 [01:43<00:48,  1.64it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.64it/s] 69%|██████▉   | 172/250 [01:44<00:47,  1.64it/s] 69%|██████▉   | 173/250 [01:45<00:46,  1.64it/s] 70%|██████▉   | 174/250 [01:45<00:46,  1.64it/s] 70%|███████   | 175/250 [01:46<00:45,  1.64it/s] 70%|███████   | 176/250 [01:47<00:45,  1.64it/s] 71%|███████   | 177/250 [01:47<00:44,  1.64it/s] 71%|███████   | 178/250 [01:48<00:43,  1.64it/s] 72%|███████▏  | 179/250 [01:49<00:43,  1.64it/s] 72%|███████▏  | 180/250 [01:49<00:42,  1.64it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.64it/s] 73%|███████▎  | 182/250 [01:50<00:41,  1.64it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.64it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.64it/s] 74%|███████▍  | 185/250 [01:52<00:39,  1.64it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.64it/s] 75%|███████▍  | 187/250 [01:53<00:38,  1.64it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.64it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.64it/s] 76%|███████▌  | 190/250 [01:55<00:36,  1.64it/s] 76%|███████▋  | 191/250 [01:56<00:36,  1.64it/s] 77%|███████▋  | 192/250 [01:56<00:35,  1.64it/s] 77%|███████▋  | 193/250 [01:57<00:34,  1.64it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 195/250 [01:58<00:33,  1.64it/s] 78%|███████▊  | 196/250 [01:59<00:32,  1.64it/s] 79%|███████▉  | 197/250 [02:00<00:32,  1.64it/s] 79%|███████▉  | 198/250 [02:00<00:31,  1.64it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.64it/s] 80%|████████  | 200/250 [02:01<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:01<00:30,  1.64it/s] 80%|████████  | 201/250 [02:02<00:29,  1.64it/s] 81%|████████  | 202/250 [02:03<00:29,  1.64it/s] 81%|████████  | 203/250 [02:03<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 205/250 [02:04<00:27,  1.64it/s] 82%|████████▏ | 206/250 [02:05<00:26,  1.64it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 208/250 [02:06<00:25,  1.64it/s] 84%|████████▎ | 209/250 [02:07<00:24,  1.64it/s] 84%|████████▍ | 210/250 [02:07<00:24,  1.64it/s] 84%|████████▍ | 211/250 [02:08<00:23,  1.64it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.64it/s] 85%|████████▌ | 213/250 [02:09<00:22,  1.64it/s] 86%|████████▌ | 214/250 [02:10<00:21,  1.64it/s] 86%|████████▌ | 215/250 [02:11<00:21,  1.64it/s] 86%|████████▋ | 216/250 [02:11<00:20,  1.64it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 218/250 [02:12<00:19,  1.64it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.64it/s] 88%|████████▊ | 220/250 [02:14<00:18,  1.64it/s] 88%|████████▊ | 221/250 [02:14<00:17,  1.64it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 223/250 [02:15<00:16,  1.64it/s] 90%|████████▉ | 224/250 [02:16<00:15,  1.64it/s] 90%|█████████ | 225/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 226/250 [02:17<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 228/250 [02:18<00:13,  1.64it/s] 92%|█████████▏| 229/250 [02:19<00:12,  1.64it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 231/250 [02:20<00:11,  1.64it/s] 93%|█████████▎| 232/250 [02:21<00:10,  1.64it/s] 93%|█████████▎| 233/250 [02:21<00:10,  1.64it/s] 94%|█████████▎| 234/250 [02:22<00:09,  1.64it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 236/250 [02:23<00:08,  1.64it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.64it/s] 95%|█████████▌| 238/250 [02:25<00:07,  1.64it/s] 96%|█████████▌| 239/250 [02:25<00:06,  1.64it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.64it/s] 96%|█████████▋| 241/250 [02:26<00:05,  1.64it/s] 97%|█████████▋| 242/250 [02:27<00:04,  1.64it/s] 97%|█████████▋| 243/250 [02:28<00:04,  1.64it/s] 98%|█████████▊| 244/250 [02:28<00:03,  1.64it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 246/250 [02:29<00:02,  1.64it/s] 99%|█████████▉| 247/250 [02:30<00:01,  1.64it/s] 99%|█████████▉| 248/250 [02:31<00:01,  1.64it/s]100%|█████████▉| 249/250 [02:31<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x14f316542c00>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: cf8a0400-9e15-4524-969b-49b62547dc4e)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:32<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x14f312f85bb0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: bf504329-b810-452a-bb86-4a84d9ff67b1)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.9885, 'grad_norm': 1.481297254562378, 'learning_rate': 1.2080000000000001e-05, 'epoch': 0.4}
{'loss': 1.6197, 'grad_norm': 1.369497537612915, 'learning_rate': 4.08e-06, 'epoch': 0.8}
{'train_runtime': 152.612, 'train_samples_per_second': 6.553, 'train_steps_per_second': 1.638, 'train_loss': 1.7612398071289062, 'epoch': 1.0}
Saving model to finetuned_models/alpaca_data_1000/meta-llama/Llama-3.2-3B-Instruct_60
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=36, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/alpaca_data_1000/meta-llama/Llama-3.2-3B-Instruct_36', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='alpaca_data_1000', dataset='datasets/ft/alpaca_data_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/alpaca_data_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 24772.05 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 2389.67 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 2333.02 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/alpaca_data_1000.jsonl
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/alpaca_data_1000/meta-llama/Llama-3.2-3B-Instruct_36
===========================
SEED CHECK:, should be: 36, seed is: 36
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:35,  1.16it/s]  1%|          | 2/250 [00:01<03:00,  1.37it/s]  1%|          | 3/250 [00:02<02:45,  1.49it/s]  2%|▏         | 4/250 [00:02<02:38,  1.55it/s]  2%|▏         | 5/250 [00:03<02:34,  1.59it/s]  2%|▏         | 6/250 [00:03<02:31,  1.62it/s]  3%|▎         | 7/250 [00:04<02:29,  1.63it/s]  3%|▎         | 8/250 [00:05<02:27,  1.64it/s]  4%|▎         | 9/250 [00:05<02:26,  1.65it/s]  4%|▍         | 10/250 [00:06<02:25,  1.65it/s]  4%|▍         | 11/250 [00:06<02:24,  1.65it/s]  5%|▍         | 12/250 [00:07<02:23,  1.66it/s]  5%|▌         | 13/250 [00:08<02:23,  1.66it/s]  6%|▌         | 14/250 [00:08<02:22,  1.66it/s]  6%|▌         | 15/250 [00:09<02:21,  1.66it/s]  6%|▋         | 16/250 [00:09<02:21,  1.66it/s]  7%|▋         | 17/250 [00:10<02:20,  1.66it/s]  7%|▋         | 18/250 [00:11<02:19,  1.66it/s]  8%|▊         | 19/250 [00:11<02:19,  1.66it/s]  8%|▊         | 20/250 [00:12<02:18,  1.66it/s]  8%|▊         | 21/250 [00:12<02:18,  1.66it/s]  9%|▉         | 22/250 [00:13<02:17,  1.66it/s]  9%|▉         | 23/250 [00:14<02:16,  1.66it/s] 10%|▉         | 24/250 [00:14<02:16,  1.66it/s] 10%|█         | 25/250 [00:15<02:15,  1.66it/s] 10%|█         | 26/250 [00:15<02:15,  1.65it/s] 11%|█         | 27/250 [00:16<02:14,  1.65it/s] 11%|█         | 28/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 29/250 [00:17<02:13,  1.65it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.65it/s] 12%|█▏        | 31/250 [00:18<02:12,  1.65it/s] 13%|█▎        | 32/250 [00:19<02:11,  1.65it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.65it/s] 14%|█▎        | 34/250 [00:20<02:10,  1.65it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.65it/s] 14%|█▍        | 36/250 [00:22<02:09,  1.65it/s] 15%|█▍        | 37/250 [00:22<02:08,  1.65it/s] 15%|█▌        | 38/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 39/250 [00:23<02:07,  1.65it/s] 16%|█▌        | 40/250 [00:24<02:06,  1.65it/s] 16%|█▋        | 41/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 42/250 [00:25<02:05,  1.65it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.65it/s] 18%|█▊        | 44/250 [00:26<02:04,  1.65it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.65it/s] 18%|█▊        | 46/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 47/250 [00:28<02:02,  1.65it/s] 19%|█▉        | 48/250 [00:29<02:02,  1.65it/s] 20%|█▉        | 49/250 [00:29<02:01,  1.65it/s] 20%|██        | 50/250 [00:30<02:01,  1.65it/s] 20%|██        | 51/250 [00:31<02:00,  1.65it/s] 21%|██        | 52/250 [00:31<01:59,  1.65it/s] 21%|██        | 53/250 [00:32<01:59,  1.65it/s] 22%|██▏       | 54/250 [00:32<01:58,  1.65it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.65it/s] 22%|██▏       | 56/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 57/250 [00:34<01:56,  1.65it/s] 23%|██▎       | 58/250 [00:35<01:56,  1.65it/s] 24%|██▎       | 59/250 [00:35<01:55,  1.65it/s] 24%|██▍       | 60/250 [00:36<01:54,  1.65it/s] 24%|██▍       | 61/250 [00:37<01:54,  1.65it/s] 25%|██▍       | 62/250 [00:37<01:53,  1.65it/s] 25%|██▌       | 63/250 [00:38<01:53,  1.65it/s] 26%|██▌       | 64/250 [00:38<01:52,  1.65it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.65it/s] 26%|██▋       | 66/250 [00:40<01:51,  1.65it/s] 27%|██▋       | 67/250 [00:40<01:50,  1.65it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.65it/s] 28%|██▊       | 69/250 [00:41<01:49,  1.65it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 71/250 [00:43<01:48,  1.65it/s] 29%|██▉       | 72/250 [00:43<01:48,  1.65it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.65it/s] 30%|██▉       | 74/250 [00:45<01:46,  1.65it/s] 30%|███       | 75/250 [00:45<01:45,  1.65it/s] 30%|███       | 76/250 [00:46<01:45,  1.65it/s] 31%|███       | 77/250 [00:46<01:44,  1.65it/s] 31%|███       | 78/250 [00:47<01:44,  1.65it/s] 32%|███▏      | 79/250 [00:48<01:43,  1.65it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.65it/s] 32%|███▏      | 81/250 [00:49<01:42,  1.65it/s] 33%|███▎      | 82/250 [00:49<01:41,  1.65it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.65it/s] 34%|███▎      | 84/250 [00:51<01:40,  1.65it/s] 34%|███▍      | 85/250 [00:51<01:40,  1.65it/s] 34%|███▍      | 86/250 [00:52<01:39,  1.65it/s] 35%|███▍      | 87/250 [00:52<01:38,  1.65it/s] 35%|███▌      | 88/250 [00:53<01:38,  1.65it/s] 36%|███▌      | 89/250 [00:54<01:37,  1.65it/s] 36%|███▌      | 90/250 [00:54<01:37,  1.65it/s] 36%|███▋      | 91/250 [00:55<01:36,  1.65it/s] 37%|███▋      | 92/250 [00:55<01:35,  1.65it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.65it/s] 38%|███▊      | 94/250 [00:57<01:34,  1.65it/s] 38%|███▊      | 95/250 [00:57<01:33,  1.65it/s] 38%|███▊      | 96/250 [00:58<01:33,  1.65it/s] 39%|███▉      | 97/250 [00:58<01:32,  1.65it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.65it/s] 40%|███▉      | 99/250 [01:00<01:31,  1.65it/s] 40%|████      | 100/250 [01:00<01:30,  1.65it/s]                                                  40%|████      | 100/250 [01:00<01:30,  1.65it/s] 40%|████      | 101/250 [01:01<01:30,  1.65it/s] 41%|████      | 102/250 [01:01<01:29,  1.65it/s] 41%|████      | 103/250 [01:02<01:29,  1.65it/s] 42%|████▏     | 104/250 [01:03<01:28,  1.65it/s] 42%|████▏     | 105/250 [01:03<01:27,  1.65it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.65it/s] 43%|████▎     | 107/250 [01:05<01:26,  1.65it/s] 43%|████▎     | 108/250 [01:05<01:26,  1.65it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.65it/s] 44%|████▍     | 110/250 [01:06<01:24,  1.65it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.65it/s] 45%|████▍     | 112/250 [01:08<01:23,  1.65it/s] 45%|████▌     | 113/250 [01:08<01:23,  1.65it/s] 46%|████▌     | 114/250 [01:09<01:22,  1.65it/s] 46%|████▌     | 115/250 [01:09<01:21,  1.65it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.65it/s] 47%|████▋     | 117/250 [01:11<01:20,  1.65it/s] 47%|████▋     | 118/250 [01:11<01:19,  1.65it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.65it/s] 48%|████▊     | 120/250 [01:12<01:18,  1.65it/s] 48%|████▊     | 121/250 [01:13<01:18,  1.65it/s] 49%|████▉     | 122/250 [01:14<01:17,  1.65it/s] 49%|████▉     | 123/250 [01:14<01:16,  1.65it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.65it/s] 50%|█████     | 125/250 [01:15<01:15,  1.65it/s] 50%|█████     | 126/250 [01:16<01:15,  1.65it/s] 51%|█████     | 127/250 [01:17<01:14,  1.65it/s] 51%|█████     | 128/250 [01:17<01:13,  1.65it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.65it/s] 52%|█████▏    | 130/250 [01:18<01:12,  1.65it/s] 52%|█████▏    | 131/250 [01:19<01:12,  1.65it/s] 53%|█████▎    | 132/250 [01:20<01:11,  1.65it/s] 53%|█████▎    | 133/250 [01:20<01:10,  1.65it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.65it/s] 54%|█████▍    | 135/250 [01:21<01:09,  1.65it/s] 54%|█████▍    | 136/250 [01:22<01:08,  1.65it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.65it/s] 55%|█████▌    | 138/250 [01:23<01:07,  1.65it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.65it/s] 56%|█████▌    | 140/250 [01:25<01:06,  1.65it/s] 56%|█████▋    | 141/250 [01:25<01:05,  1.65it/s] 57%|█████▋    | 142/250 [01:26<01:05,  1.65it/s] 57%|█████▋    | 143/250 [01:26<01:04,  1.65it/s] 58%|█████▊    | 144/250 [01:27<01:04,  1.65it/s] 58%|█████▊    | 145/250 [01:28<01:03,  1.65it/s] 58%|█████▊    | 146/250 [01:28<01:02,  1.65it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.65it/s] 59%|█████▉    | 148/250 [01:29<01:01,  1.65it/s] 60%|█████▉    | 149/250 [01:30<01:01,  1.65it/s] 60%|██████    | 150/250 [01:31<01:00,  1.65it/s] 60%|██████    | 151/250 [01:31<00:59,  1.65it/s] 61%|██████    | 152/250 [01:32<00:59,  1.65it/s] 61%|██████    | 153/250 [01:32<00:58,  1.65it/s] 62%|██████▏   | 154/250 [01:33<00:58,  1.65it/s] 62%|██████▏   | 155/250 [01:34<00:57,  1.65it/s] 62%|██████▏   | 156/250 [01:34<00:56,  1.65it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.65it/s] 63%|██████▎   | 158/250 [01:35<00:55,  1.65it/s] 64%|██████▎   | 159/250 [01:36<00:55,  1.65it/s] 64%|██████▍   | 160/250 [01:37<00:54,  1.65it/s] 64%|██████▍   | 161/250 [01:37<00:53,  1.65it/s] 65%|██████▍   | 162/250 [01:38<00:53,  1.65it/s] 65%|██████▌   | 163/250 [01:38<00:52,  1.65it/s] 66%|██████▌   | 164/250 [01:39<00:52,  1.65it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.65it/s] 66%|██████▋   | 166/250 [01:40<00:50,  1.65it/s] 67%|██████▋   | 167/250 [01:41<00:50,  1.65it/s] 67%|██████▋   | 168/250 [01:41<00:49,  1.65it/s] 68%|██████▊   | 169/250 [01:42<00:49,  1.65it/s] 68%|██████▊   | 170/250 [01:43<00:48,  1.65it/s] 68%|██████▊   | 171/250 [01:43<00:47,  1.65it/s] 69%|██████▉   | 172/250 [01:44<00:47,  1.65it/s] 69%|██████▉   | 173/250 [01:44<00:46,  1.65it/s] 70%|██████▉   | 174/250 [01:45<00:46,  1.65it/s] 70%|███████   | 175/250 [01:46<00:45,  1.65it/s] 70%|███████   | 176/250 [01:46<00:44,  1.65it/s] 71%|███████   | 177/250 [01:47<00:44,  1.65it/s] 71%|███████   | 178/250 [01:48<00:43,  1.65it/s] 72%|███████▏  | 179/250 [01:48<00:42,  1.65it/s] 72%|███████▏  | 180/250 [01:49<00:42,  1.65it/s] 72%|███████▏  | 181/250 [01:49<00:41,  1.65it/s] 73%|███████▎  | 182/250 [01:50<00:41,  1.65it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.65it/s] 74%|███████▎  | 184/250 [01:51<00:40,  1.65it/s] 74%|███████▍  | 185/250 [01:52<00:39,  1.65it/s] 74%|███████▍  | 186/250 [01:52<00:38,  1.65it/s] 75%|███████▍  | 187/250 [01:53<00:38,  1.65it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.65it/s] 76%|███████▌  | 189/250 [01:54<00:37,  1.65it/s] 76%|███████▌  | 190/250 [01:55<00:36,  1.65it/s] 76%|███████▋  | 191/250 [01:55<00:35,  1.65it/s] 77%|███████▋  | 192/250 [01:56<00:35,  1.65it/s] 77%|███████▋  | 193/250 [01:57<00:34,  1.65it/s] 78%|███████▊  | 194/250 [01:57<00:33,  1.65it/s] 78%|███████▊  | 195/250 [01:58<00:33,  1.65it/s] 78%|███████▊  | 196/250 [01:58<00:32,  1.65it/s] 79%|███████▉  | 197/250 [01:59<00:32,  1.65it/s] 79%|███████▉  | 198/250 [02:00<00:31,  1.65it/s] 80%|███████▉  | 199/250 [02:00<00:30,  1.65it/s] 80%|████████  | 200/250 [02:01<00:30,  1.65it/s]                                                  80%|████████  | 200/250 [02:01<00:30,  1.65it/s] 80%|████████  | 201/250 [02:01<00:29,  1.65it/s] 81%|████████  | 202/250 [02:02<00:29,  1.65it/s] 81%|████████  | 203/250 [02:03<00:28,  1.65it/s] 82%|████████▏ | 204/250 [02:03<00:27,  1.65it/s] 82%|████████▏ | 205/250 [02:04<00:27,  1.65it/s] 82%|████████▏ | 206/250 [02:05<00:26,  1.65it/s] 83%|████████▎ | 207/250 [02:05<00:26,  1.65it/s] 83%|████████▎ | 208/250 [02:06<00:25,  1.65it/s] 84%|████████▎ | 209/250 [02:06<00:24,  1.65it/s] 84%|████████▍ | 210/250 [02:07<00:24,  1.65it/s] 84%|████████▍ | 211/250 [02:08<00:23,  1.65it/s] 85%|████████▍ | 212/250 [02:08<00:23,  1.65it/s] 85%|████████▌ | 213/250 [02:09<00:22,  1.65it/s] 86%|████████▌ | 214/250 [02:09<00:21,  1.65it/s] 86%|████████▌ | 215/250 [02:10<00:21,  1.65it/s] 86%|████████▋ | 216/250 [02:11<00:20,  1.65it/s] 87%|████████▋ | 217/250 [02:11<00:19,  1.65it/s] 87%|████████▋ | 218/250 [02:12<00:19,  1.65it/s] 88%|████████▊ | 219/250 [02:12<00:18,  1.65it/s] 88%|████████▊ | 220/250 [02:13<00:18,  1.65it/s] 88%|████████▊ | 221/250 [02:14<00:17,  1.65it/s] 89%|████████▉ | 222/250 [02:14<00:16,  1.65it/s] 89%|████████▉ | 223/250 [02:15<00:16,  1.65it/s] 90%|████████▉ | 224/250 [02:15<00:15,  1.65it/s] 90%|█████████ | 225/250 [02:16<00:15,  1.65it/s] 90%|█████████ | 226/250 [02:17<00:14,  1.65it/s] 91%|█████████ | 227/250 [02:17<00:13,  1.65it/s] 91%|█████████ | 228/250 [02:18<00:13,  1.65it/s] 92%|█████████▏| 229/250 [02:18<00:12,  1.65it/s] 92%|█████████▏| 230/250 [02:19<00:12,  1.65it/s] 92%|█████████▏| 231/250 [02:20<00:11,  1.65it/s] 93%|█████████▎| 232/250 [02:20<00:10,  1.65it/s] 93%|█████████▎| 233/250 [02:21<00:10,  1.65it/s] 94%|█████████▎| 234/250 [02:21<00:09,  1.65it/s] 94%|█████████▍| 235/250 [02:22<00:09,  1.65it/s] 94%|█████████▍| 236/250 [02:23<00:08,  1.65it/s] 95%|█████████▍| 237/250 [02:23<00:07,  1.65it/s] 95%|█████████▌| 238/250 [02:24<00:07,  1.65it/s] 96%|█████████▌| 239/250 [02:24<00:06,  1.65it/s] 96%|█████████▌| 240/250 [02:25<00:06,  1.65it/s] 96%|█████████▋| 241/250 [02:26<00:05,  1.65it/s] 97%|█████████▋| 242/250 [02:26<00:04,  1.65it/s] 97%|█████████▋| 243/250 [02:27<00:04,  1.65it/s] 98%|█████████▊| 244/250 [02:28<00:03,  1.65it/s] 98%|█████████▊| 245/250 [02:28<00:03,  1.65it/s] 98%|█████████▊| 246/250 [02:29<00:02,  1.65it/s] 99%|█████████▉| 247/250 [02:29<00:01,  1.65it/s] 99%|█████████▉| 248/250 [02:30<00:01,  1.65it/s]100%|█████████▉| 249/250 [02:31<00:00,  1.65it/s]100%|██████████| 250/250 [02:31<00:00,  1.65it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x1464c4f8e6f0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 106e13e0-5dd9-43b4-8bff-308fea9fd5ec)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:31<00:00,  1.65it/s]100%|██████████| 250/250 [02:31<00:00,  1.65it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x1464c4a815e0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 62cf7ac1-9745-4bdb-a3bc-4ed3bc9e3b7d)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.9723, 'grad_norm': 2.2168023586273193, 'learning_rate': 1.216e-05, 'epoch': 0.4}
{'loss': 1.6193, 'grad_norm': 1.6083234548568726, 'learning_rate': 4.16e-06, 'epoch': 0.8}
{'train_runtime': 151.9303, 'train_samples_per_second': 6.582, 'train_steps_per_second': 1.645, 'train_loss': 1.746884033203125, 'epoch': 1.0}
Saving model to finetuned_models/alpaca_data_1000/meta-llama/Llama-3.2-3B-Instruct_36
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=42, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/alpaca_data_1000/meta-llama/Llama-3.2-3B-Instruct_42', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='alpaca_data_1000', dataset='datasets/ft/alpaca_data_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/alpaca_data_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 24128.21 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 2388.07 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 2331.51 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/alpaca_data_1000.jsonl
Random seed: 42
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/alpaca_data_1000/meta-llama/Llama-3.2-3B-Instruct_42
===========================
SEED CHECK:, should be: 42, seed is: 42
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:45,  1.10it/s]  1%|          | 2/250 [00:01<03:00,  1.37it/s]  1%|          | 3/250 [00:02<02:45,  1.49it/s]  2%|▏         | 4/250 [00:02<02:38,  1.55it/s]  2%|▏         | 5/250 [00:03<02:34,  1.59it/s]  2%|▏         | 6/250 [00:03<02:31,  1.61it/s]  3%|▎         | 7/250 [00:04<02:29,  1.63it/s]  3%|▎         | 8/250 [00:05<02:27,  1.64it/s]  4%|▎         | 9/250 [00:05<02:26,  1.64it/s]  4%|▍         | 10/250 [00:06<02:25,  1.65it/s]  4%|▍         | 11/250 [00:06<02:24,  1.65it/s]  5%|▍         | 12/250 [00:07<02:23,  1.65it/s]  5%|▌         | 13/250 [00:08<02:23,  1.65it/s]  6%|▌         | 14/250 [00:08<02:22,  1.66it/s]  6%|▌         | 15/250 [00:09<02:21,  1.66it/s]  6%|▋         | 16/250 [00:09<02:21,  1.65it/s]  7%|▋         | 17/250 [00:10<02:20,  1.65it/s]  7%|▋         | 18/250 [00:11<02:20,  1.65it/s]  8%|▊         | 19/250 [00:11<02:19,  1.66it/s]  8%|▊         | 20/250 [00:12<02:18,  1.66it/s]  8%|▊         | 21/250 [00:12<02:18,  1.66it/s]  9%|▉         | 22/250 [00:13<02:17,  1.66it/s]  9%|▉         | 23/250 [00:14<02:17,  1.66it/s] 10%|▉         | 24/250 [00:14<02:16,  1.66it/s] 10%|█         | 25/250 [00:15<02:15,  1.65it/s] 10%|█         | 26/250 [00:15<02:15,  1.66it/s] 11%|█         | 27/250 [00:16<02:14,  1.65it/s] 11%|█         | 28/250 [00:17<02:14,  1.66it/s] 12%|█▏        | 29/250 [00:17<02:13,  1.65it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.65it/s] 12%|█▏        | 31/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 32/250 [00:19<02:11,  1.65it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.65it/s] 14%|█▎        | 34/250 [00:20<02:10,  1.65it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.65it/s] 14%|█▍        | 36/250 [00:22<02:09,  1.65it/s] 15%|█▍        | 37/250 [00:22<02:08,  1.65it/s] 15%|█▌        | 38/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 39/250 [00:23<02:07,  1.65it/s] 16%|█▌        | 40/250 [00:24<02:07,  1.65it/s] 16%|█▋        | 41/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 42/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.65it/s] 18%|█▊        | 44/250 [00:26<02:04,  1.65it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.65it/s] 18%|█▊        | 46/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 47/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 48/250 [00:29<02:02,  1.65it/s] 20%|█▉        | 49/250 [00:29<02:01,  1.65it/s] 20%|██        | 50/250 [00:30<02:01,  1.65it/s] 20%|██        | 51/250 [00:31<02:00,  1.65it/s] 21%|██        | 52/250 [00:31<02:00,  1.65it/s] 21%|██        | 53/250 [00:32<01:59,  1.65it/s] 22%|██▏       | 54/250 [00:32<01:58,  1.65it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.65it/s] 22%|██▏       | 56/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 58/250 [00:35<01:56,  1.65it/s] 24%|██▎       | 59/250 [00:35<01:55,  1.65it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.65it/s] 24%|██▍       | 61/250 [00:37<01:54,  1.65it/s] 25%|██▍       | 62/250 [00:37<01:54,  1.65it/s] 25%|██▌       | 63/250 [00:38<01:53,  1.65it/s] 26%|██▌       | 64/250 [00:39<01:52,  1.65it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.65it/s] 26%|██▋       | 66/250 [00:40<01:51,  1.65it/s] 27%|██▋       | 67/250 [00:40<01:51,  1.65it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.65it/s] 28%|██▊       | 69/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 71/250 [00:43<01:48,  1.65it/s] 29%|██▉       | 72/250 [00:43<01:47,  1.65it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.65it/s] 30%|██▉       | 74/250 [00:45<01:46,  1.65it/s] 30%|███       | 75/250 [00:45<01:46,  1.65it/s] 30%|███       | 76/250 [00:46<01:45,  1.65it/s] 31%|███       | 77/250 [00:46<01:44,  1.65it/s] 31%|███       | 78/250 [00:47<01:44,  1.65it/s] 32%|███▏      | 79/250 [00:48<01:43,  1.65it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.65it/s] 32%|███▏      | 81/250 [00:49<01:42,  1.65it/s] 33%|███▎      | 82/250 [00:49<01:41,  1.65it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.65it/s] 34%|███▎      | 84/250 [00:51<01:40,  1.65it/s] 34%|███▍      | 85/250 [00:51<01:39,  1.65it/s] 34%|███▍      | 86/250 [00:52<01:39,  1.65it/s] 35%|███▍      | 87/250 [00:52<01:38,  1.65it/s] 35%|███▌      | 88/250 [00:53<01:37,  1.65it/s] 36%|███▌      | 89/250 [00:54<01:37,  1.66it/s] 36%|███▌      | 90/250 [00:54<01:36,  1.66it/s] 36%|███▋      | 91/250 [00:55<01:36,  1.66it/s] 37%|███▋      | 92/250 [00:55<01:35,  1.65it/s] 37%|███▋      | 93/250 [00:56<01:34,  1.65it/s] 38%|███▊      | 94/250 [00:57<01:34,  1.66it/s] 38%|███▊      | 95/250 [00:57<01:33,  1.65it/s] 38%|███▊      | 96/250 [00:58<01:33,  1.66it/s] 39%|███▉      | 97/250 [00:58<01:32,  1.65it/s] 39%|███▉      | 98/250 [00:59<01:31,  1.65it/s] 40%|███▉      | 99/250 [01:00<01:31,  1.65it/s] 40%|████      | 100/250 [01:00<01:30,  1.65it/s]                                                  40%|████      | 100/250 [01:00<01:30,  1.65it/s] 40%|████      | 101/250 [01:01<01:30,  1.65it/s] 41%|████      | 102/250 [01:02<01:29,  1.65it/s] 41%|████      | 103/250 [01:02<01:29,  1.65it/s] 42%|████▏     | 104/250 [01:03<01:28,  1.65it/s] 42%|████▏     | 105/250 [01:03<01:27,  1.65it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.65it/s] 43%|████▎     | 107/250 [01:05<01:26,  1.65it/s] 43%|████▎     | 108/250 [01:05<01:26,  1.65it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.65it/s] 44%|████▍     | 110/250 [01:06<01:24,  1.65it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.65it/s] 45%|████▍     | 112/250 [01:08<01:23,  1.65it/s] 45%|████▌     | 113/250 [01:08<01:23,  1.65it/s] 46%|████▌     | 114/250 [01:09<01:22,  1.65it/s] 46%|████▌     | 115/250 [01:09<01:21,  1.65it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.65it/s] 47%|████▋     | 117/250 [01:11<01:20,  1.65it/s] 47%|████▋     | 118/250 [01:11<01:20,  1.65it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.65it/s] 48%|████▊     | 120/250 [01:12<01:18,  1.65it/s] 48%|████▊     | 121/250 [01:13<01:18,  1.65it/s] 49%|████▉     | 122/250 [01:14<01:17,  1.65it/s] 49%|████▉     | 123/250 [01:14<01:17,  1.65it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.65it/s] 50%|█████     | 125/250 [01:15<01:15,  1.65it/s] 50%|█████     | 126/250 [01:16<01:15,  1.65it/s] 51%|█████     | 127/250 [01:17<01:14,  1.64it/s] 51%|█████     | 128/250 [01:17<01:14,  1.64it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.64it/s] 52%|█████▏    | 130/250 [01:19<01:12,  1.64it/s] 52%|█████▏    | 131/250 [01:19<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:11,  1.65it/s] 53%|█████▎    | 133/250 [01:20<01:11,  1.65it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.65it/s] 54%|█████▍    | 135/250 [01:22<01:09,  1.65it/s] 54%|█████▍    | 136/250 [01:22<01:09,  1.65it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.65it/s] 55%|█████▌    | 138/250 [01:23<01:08,  1.64it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.64it/s] 56%|█████▌    | 140/250 [01:25<01:06,  1.65it/s] 56%|█████▋    | 141/250 [01:25<01:06,  1.65it/s] 57%|█████▋    | 142/250 [01:26<01:05,  1.65it/s] 57%|█████▋    | 143/250 [01:26<01:04,  1.65it/s] 58%|█████▊    | 144/250 [01:27<01:04,  1.65it/s] 58%|█████▊    | 145/250 [01:28<01:03,  1.65it/s] 58%|█████▊    | 146/250 [01:28<01:03,  1.65it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.65it/s] 59%|█████▉    | 148/250 [01:29<01:01,  1.65it/s] 60%|█████▉    | 149/250 [01:30<01:01,  1.65it/s] 60%|██████    | 150/250 [01:31<01:00,  1.65it/s] 60%|██████    | 151/250 [01:31<01:00,  1.65it/s] 61%|██████    | 152/250 [01:32<00:59,  1.65it/s] 61%|██████    | 153/250 [01:32<00:58,  1.65it/s] 62%|██████▏   | 154/250 [01:33<00:58,  1.65it/s] 62%|██████▏   | 155/250 [01:34<00:57,  1.65it/s] 62%|██████▏   | 156/250 [01:34<00:57,  1.65it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.65it/s] 63%|██████▎   | 158/250 [01:36<00:55,  1.65it/s] 64%|██████▎   | 159/250 [01:36<00:55,  1.65it/s] 64%|██████▍   | 160/250 [01:37<00:54,  1.65it/s] 64%|██████▍   | 161/250 [01:37<00:54,  1.65it/s] 65%|██████▍   | 162/250 [01:38<00:53,  1.65it/s] 65%|██████▌   | 163/250 [01:39<00:52,  1.65it/s] 66%|██████▌   | 164/250 [01:39<00:52,  1.65it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.65it/s] 66%|██████▋   | 166/250 [01:40<00:51,  1.65it/s] 67%|██████▋   | 167/250 [01:41<00:50,  1.65it/s] 67%|██████▋   | 168/250 [01:42<00:49,  1.65it/s] 68%|██████▊   | 169/250 [01:42<00:49,  1.64it/s] 68%|██████▊   | 170/250 [01:43<00:48,  1.65it/s] 68%|██████▊   | 171/250 [01:43<00:47,  1.65it/s] 69%|██████▉   | 172/250 [01:44<00:47,  1.65it/s] 69%|██████▉   | 173/250 [01:45<00:46,  1.65it/s] 70%|██████▉   | 174/250 [01:45<00:46,  1.65it/s] 70%|███████   | 175/250 [01:46<00:45,  1.65it/s] 70%|███████   | 176/250 [01:46<00:44,  1.65it/s] 71%|███████   | 177/250 [01:47<00:44,  1.65it/s] 71%|███████   | 178/250 [01:48<00:43,  1.65it/s] 72%|███████▏  | 179/250 [01:48<00:43,  1.65it/s] 72%|███████▏  | 180/250 [01:49<00:42,  1.64it/s] 72%|███████▏  | 181/250 [01:50<00:41,  1.64it/s] 73%|███████▎  | 182/250 [01:50<00:41,  1.64it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.65it/s] 74%|███████▎  | 184/250 [01:51<00:40,  1.64it/s] 74%|███████▍  | 185/250 [01:52<00:39,  1.64it/s] 74%|███████▍  | 186/250 [01:53<00:38,  1.64it/s] 75%|███████▍  | 187/250 [01:53<00:38,  1.64it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.64it/s] 76%|███████▌  | 189/250 [01:54<00:37,  1.64it/s] 76%|███████▌  | 190/250 [01:55<00:36,  1.64it/s] 76%|███████▋  | 191/250 [01:56<00:35,  1.64it/s] 77%|███████▋  | 192/250 [01:56<00:35,  1.64it/s] 77%|███████▋  | 193/250 [01:57<00:34,  1.64it/s] 78%|███████▊  | 194/250 [01:57<00:34,  1.64it/s] 78%|███████▊  | 195/250 [01:58<00:33,  1.64it/s] 78%|███████▊  | 196/250 [01:59<00:32,  1.64it/s] 79%|███████▉  | 197/250 [01:59<00:32,  1.64it/s] 79%|███████▉  | 198/250 [02:00<00:31,  1.64it/s] 80%|███████▉  | 199/250 [02:00<00:31,  1.64it/s] 80%|████████  | 200/250 [02:01<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:01<00:30,  1.64it/s] 80%|████████  | 201/250 [02:02<00:29,  1.64it/s] 81%|████████  | 202/250 [02:02<00:29,  1.64it/s] 81%|████████  | 203/250 [02:03<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 205/250 [02:04<00:27,  1.64it/s] 82%|████████▏ | 206/250 [02:05<00:26,  1.64it/s] 83%|████████▎ | 207/250 [02:05<00:26,  1.64it/s] 83%|████████▎ | 208/250 [02:06<00:25,  1.64it/s] 84%|████████▎ | 209/250 [02:07<00:24,  1.64it/s] 84%|████████▍ | 210/250 [02:07<00:24,  1.64it/s] 84%|████████▍ | 211/250 [02:08<00:23,  1.64it/s] 85%|████████▍ | 212/250 [02:08<00:23,  1.64it/s] 85%|████████▌ | 213/250 [02:09<00:22,  1.64it/s] 86%|████████▌ | 214/250 [02:10<00:21,  1.64it/s] 86%|████████▌ | 215/250 [02:10<00:21,  1.64it/s] 86%|████████▋ | 216/250 [02:11<00:20,  1.64it/s] 87%|████████▋ | 217/250 [02:11<00:20,  1.64it/s] 87%|████████▋ | 218/250 [02:12<00:19,  1.64it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.64it/s] 88%|████████▊ | 220/250 [02:13<00:18,  1.64it/s] 88%|████████▊ | 221/250 [02:14<00:17,  1.64it/s] 89%|████████▉ | 222/250 [02:14<00:17,  1.64it/s] 89%|████████▉ | 223/250 [02:15<00:16,  1.64it/s] 90%|████████▉ | 224/250 [02:16<00:15,  1.64it/s] 90%|█████████ | 225/250 [02:16<00:15,  1.64it/s] 90%|█████████ | 226/250 [02:17<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:13,  1.64it/s] 91%|█████████ | 228/250 [02:18<00:13,  1.64it/s] 92%|█████████▏| 229/250 [02:19<00:12,  1.64it/s] 92%|█████████▏| 230/250 [02:19<00:12,  1.64it/s] 92%|█████████▏| 231/250 [02:20<00:11,  1.64it/s] 93%|█████████▎| 232/250 [02:21<00:10,  1.64it/s] 93%|█████████▎| 233/250 [02:21<00:10,  1.64it/s] 94%|█████████▎| 234/250 [02:22<00:09,  1.64it/s] 94%|█████████▍| 235/250 [02:22<00:09,  1.64it/s] 94%|█████████▍| 236/250 [02:23<00:08,  1.64it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.64it/s] 95%|█████████▌| 238/250 [02:24<00:07,  1.64it/s] 96%|█████████▌| 239/250 [02:25<00:06,  1.64it/s] 96%|█████████▌| 240/250 [02:25<00:06,  1.64it/s] 96%|█████████▋| 241/250 [02:26<00:05,  1.64it/s] 97%|█████████▋| 242/250 [02:27<00:04,  1.64it/s] 97%|█████████▋| 243/250 [02:27<00:04,  1.64it/s] 98%|█████████▊| 244/250 [02:28<00:03,  1.64it/s] 98%|█████████▊| 245/250 [02:28<00:03,  1.64it/s] 98%|█████████▊| 246/250 [02:29<00:02,  1.64it/s] 99%|█████████▉| 247/250 [02:30<00:01,  1.64it/s] 99%|█████████▉| 248/250 [02:30<00:01,  1.64it/s]100%|█████████▉| 249/250 [02:31<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.65it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x15111a3af260>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 42d21154-bfaf-425d-8259-6c8885883fa5)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:32<00:00,  1.65it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x15111a17c740>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 86394de6-993f-4197-97cb-9643f2cf275b)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.9983, 'grad_norm': 1.5098978281021118, 'learning_rate': 1.216e-05, 'epoch': 0.4}
{'loss': 1.6038, 'grad_norm': 3.09335994720459, 'learning_rate': 4.16e-06, 'epoch': 0.8}
{'train_runtime': 152.2724, 'train_samples_per_second': 6.567, 'train_steps_per_second': 1.642, 'train_loss': 1.7508265686035156, 'epoch': 1.0}
Saving model to finetuned_models/alpaca_data_1000/meta-llama/Llama-3.2-3B-Instruct_42
Fine-tuning completed successfully!
end finetuning
educational_1000
start finetuning
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=24, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/educational_1000/meta-llama/Llama-3.2-3B-Instruct_24', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='educational_1000', dataset='datasets/ft/educational_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/educational_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 23544.85 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1641.89 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1614.64 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/educational_1000.jsonl
Random seed: 24
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/educational_1000/meta-llama/Llama-3.2-3B-Instruct_24
===========================
SEED CHECK:, should be: 24, seed is: 24
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:47,  1.10it/s]  1%|          | 2/250 [00:01<03:01,  1.37it/s]  1%|          | 3/250 [00:02<02:46,  1.48it/s]  2%|▏         | 4/250 [00:02<02:39,  1.55it/s]  2%|▏         | 5/250 [00:03<02:34,  1.58it/s]  2%|▏         | 6/250 [00:03<02:31,  1.61it/s]  3%|▎         | 7/250 [00:04<02:29,  1.62it/s]  3%|▎         | 8/250 [00:05<02:28,  1.63it/s]  4%|▎         | 9/250 [00:05<02:27,  1.64it/s]  4%|▍         | 10/250 [00:06<02:26,  1.64it/s]  4%|▍         | 11/250 [00:06<02:25,  1.65it/s]  5%|▍         | 12/250 [00:07<02:24,  1.65it/s]  5%|▌         | 13/250 [00:08<02:23,  1.65it/s]  6%|▌         | 14/250 [00:08<02:23,  1.65it/s]  6%|▌         | 15/250 [00:09<02:22,  1.65it/s]  6%|▋         | 16/250 [00:09<02:21,  1.65it/s]  7%|▋         | 17/250 [00:10<02:21,  1.65it/s]  7%|▋         | 18/250 [00:11<02:20,  1.65it/s]  8%|▊         | 19/250 [00:11<02:20,  1.65it/s]  8%|▊         | 20/250 [00:12<02:19,  1.65it/s]  8%|▊         | 21/250 [00:13<02:18,  1.65it/s]  9%|▉         | 22/250 [00:13<02:18,  1.65it/s]  9%|▉         | 23/250 [00:14<02:17,  1.65it/s] 10%|▉         | 24/250 [00:14<02:17,  1.65it/s] 10%|█         | 25/250 [00:15<02:16,  1.65it/s] 10%|█         | 26/250 [00:16<02:15,  1.65it/s] 11%|█         | 27/250 [00:16<02:15,  1.65it/s] 11%|█         | 28/250 [00:17<02:14,  1.64it/s] 12%|█▏        | 29/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.65it/s] 12%|█▏        | 31/250 [00:19<02:13,  1.64it/s] 13%|█▎        | 32/250 [00:19<02:12,  1.64it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.65it/s] 14%|█▎        | 34/250 [00:20<02:11,  1.65it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.65it/s] 14%|█▍        | 36/250 [00:22<02:10,  1.65it/s] 15%|█▍        | 37/250 [00:22<02:09,  1.65it/s] 15%|█▌        | 38/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 39/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 40/250 [00:24<02:07,  1.65it/s] 16%|█▋        | 41/250 [00:25<02:07,  1.65it/s] 17%|█▋        | 42/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.65it/s] 18%|█▊        | 44/250 [00:26<02:05,  1.65it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.65it/s] 18%|█▊        | 46/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 47/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 48/250 [00:29<02:02,  1.65it/s] 20%|█▉        | 49/250 [00:30<02:02,  1.65it/s] 20%|██        | 50/250 [00:30<02:01,  1.64it/s] 20%|██        | 51/250 [00:31<02:01,  1.64it/s] 21%|██        | 52/250 [00:31<02:00,  1.64it/s] 21%|██        | 53/250 [00:32<02:00,  1.64it/s] 22%|██▏       | 54/250 [00:33<01:59,  1.64it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.64it/s] 22%|██▏       | 56/250 [00:34<01:58,  1.64it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.64it/s] 23%|██▎       | 58/250 [00:35<01:56,  1.64it/s] 24%|██▎       | 59/250 [00:36<01:56,  1.64it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.64it/s] 24%|██▍       | 61/250 [00:37<01:54,  1.64it/s] 25%|██▍       | 62/250 [00:37<01:54,  1.64it/s] 25%|██▌       | 63/250 [00:38<01:53,  1.65it/s] 26%|██▌       | 64/250 [00:39<01:52,  1.65it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.65it/s] 26%|██▋       | 66/250 [00:40<01:51,  1.65it/s] 27%|██▋       | 67/250 [00:40<01:51,  1.65it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.65it/s] 28%|██▊       | 69/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 71/250 [00:43<01:48,  1.65it/s] 29%|██▉       | 72/250 [00:44<01:48,  1.65it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.65it/s] 30%|██▉       | 74/250 [00:45<01:46,  1.65it/s] 30%|███       | 75/250 [00:45<01:46,  1.64it/s] 30%|███       | 76/250 [00:46<01:45,  1.64it/s] 31%|███       | 77/250 [00:47<01:45,  1.64it/s] 31%|███       | 78/250 [00:47<01:44,  1.64it/s] 32%|███▏      | 79/250 [00:48<01:44,  1.64it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.64it/s] 32%|███▏      | 81/250 [00:49<01:42,  1.65it/s] 33%|███▎      | 82/250 [00:50<01:42,  1.64it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.64it/s] 34%|███▎      | 84/250 [00:51<01:41,  1.64it/s] 34%|███▍      | 85/250 [00:51<01:40,  1.64it/s] 34%|███▍      | 86/250 [00:52<01:39,  1.64it/s] 35%|███▍      | 87/250 [00:53<01:39,  1.64it/s] 35%|███▌      | 88/250 [00:53<01:38,  1.64it/s] 36%|███▌      | 89/250 [00:54<01:37,  1.64it/s] 36%|███▌      | 90/250 [00:54<01:37,  1.64it/s] 36%|███▋      | 91/250 [00:55<01:36,  1.64it/s] 37%|███▋      | 92/250 [00:56<01:36,  1.64it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.65it/s] 38%|███▊      | 94/250 [00:57<01:34,  1.64it/s] 38%|███▊      | 95/250 [00:58<01:34,  1.64it/s] 38%|███▊      | 96/250 [00:58<01:33,  1.64it/s] 39%|███▉      | 97/250 [00:59<01:33,  1.64it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.64it/s] 40%|███▉      | 99/250 [01:00<01:31,  1.64it/s] 40%|████      | 100/250 [01:01<01:31,  1.64it/s]                                                  40%|████      | 100/250 [01:01<01:31,  1.64it/s] 40%|████      | 101/250 [01:01<01:30,  1.64it/s] 41%|████      | 102/250 [01:02<01:30,  1.64it/s] 41%|████      | 103/250 [01:02<01:29,  1.64it/s] 42%|████▏     | 104/250 [01:03<01:28,  1.64it/s] 42%|████▏     | 105/250 [01:04<01:28,  1.64it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.64it/s] 43%|████▎     | 107/250 [01:05<01:27,  1.64it/s] 43%|████▎     | 108/250 [01:05<01:26,  1.64it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.64it/s] 44%|████▍     | 110/250 [01:07<01:25,  1.64it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.64it/s] 45%|████▍     | 112/250 [01:08<01:23,  1.64it/s] 45%|████▌     | 113/250 [01:08<01:23,  1.64it/s] 46%|████▌     | 114/250 [01:09<01:22,  1.64it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.64it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.64it/s] 47%|████▋     | 117/250 [01:11<01:20,  1.64it/s] 47%|████▋     | 118/250 [01:12<01:20,  1.64it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.64it/s] 48%|████▊     | 120/250 [01:13<01:19,  1.64it/s] 48%|████▊     | 121/250 [01:13<01:18,  1.64it/s] 49%|████▉     | 122/250 [01:14<01:17,  1.64it/s] 49%|████▉     | 123/250 [01:15<01:17,  1.64it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.64it/s] 50%|█████     | 125/250 [01:16<01:16,  1.64it/s] 50%|█████     | 126/250 [01:16<01:15,  1.64it/s] 51%|█████     | 127/250 [01:17<01:14,  1.64it/s] 51%|█████     | 128/250 [01:18<01:14,  1.64it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.64it/s] 52%|█████▏    | 130/250 [01:19<01:13,  1.64it/s] 52%|█████▏    | 131/250 [01:19<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:11,  1.64it/s] 53%|█████▎    | 133/250 [01:21<01:11,  1.64it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.64it/s] 54%|█████▍    | 135/250 [01:22<01:10,  1.64it/s] 54%|█████▍    | 136/250 [01:22<01:09,  1.64it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.64it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.64it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.64it/s] 56%|█████▌    | 140/250 [01:25<01:07,  1.64it/s] 56%|█████▋    | 141/250 [01:26<01:06,  1.64it/s] 57%|█████▋    | 142/250 [01:26<01:05,  1.64it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.64it/s] 58%|█████▊    | 144/250 [01:27<01:04,  1.64it/s] 58%|█████▊    | 145/250 [01:28<01:03,  1.64it/s] 58%|█████▊    | 146/250 [01:29<01:03,  1.64it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.64it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.64it/s] 60%|█████▉    | 149/250 [01:30<01:01,  1.64it/s] 60%|██████    | 150/250 [01:31<01:00,  1.64it/s] 60%|██████    | 151/250 [01:32<01:00,  1.64it/s] 61%|██████    | 152/250 [01:32<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:59,  1.64it/s] 62%|██████▏   | 154/250 [01:33<00:58,  1.63it/s] 62%|██████▏   | 155/250 [01:34<00:58,  1.63it/s] 62%|██████▏   | 156/250 [01:35<00:57,  1.64it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.64it/s] 63%|██████▎   | 158/250 [01:36<00:56,  1.64it/s] 64%|██████▎   | 159/250 [01:37<00:55,  1.64it/s] 64%|██████▍   | 160/250 [01:37<00:55,  1.64it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s] 65%|██████▍   | 162/250 [01:38<00:53,  1.64it/s] 65%|██████▌   | 163/250 [01:39<00:53,  1.64it/s] 66%|██████▌   | 164/250 [01:40<00:52,  1.64it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.64it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.64it/s] 67%|██████▋   | 167/250 [01:41<00:50,  1.64it/s] 67%|██████▋   | 168/250 [01:42<00:50,  1.64it/s] 68%|██████▊   | 169/250 [01:43<00:49,  1.64it/s] 68%|██████▊   | 170/250 [01:43<00:48,  1.64it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.64it/s] 69%|██████▉   | 172/250 [01:44<00:47,  1.64it/s] 69%|██████▉   | 173/250 [01:45<00:46,  1.64it/s] 70%|██████▉   | 174/250 [01:46<00:46,  1.64it/s] 70%|███████   | 175/250 [01:46<00:45,  1.64it/s] 70%|███████   | 176/250 [01:47<00:45,  1.64it/s] 71%|███████   | 177/250 [01:47<00:44,  1.64it/s] 71%|███████   | 178/250 [01:48<00:43,  1.64it/s] 72%|███████▏  | 179/250 [01:49<00:43,  1.64it/s] 72%|███████▏  | 180/250 [01:49<00:42,  1.64it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.64it/s] 73%|███████▎  | 182/250 [01:51<00:41,  1.64it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.64it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.64it/s] 74%|███████▍  | 185/250 [01:52<00:39,  1.64it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.64it/s] 75%|███████▍  | 187/250 [01:54<00:38,  1.64it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.64it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.64it/s] 76%|███████▌  | 190/250 [01:55<00:36,  1.64it/s] 76%|███████▋  | 191/250 [01:56<00:36,  1.64it/s] 77%|███████▋  | 192/250 [01:57<00:35,  1.64it/s] 77%|███████▋  | 193/250 [01:57<00:34,  1.64it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 195/250 [01:58<00:33,  1.64it/s] 78%|███████▊  | 196/250 [01:59<00:32,  1.64it/s] 79%|███████▉  | 197/250 [02:00<00:32,  1.64it/s] 79%|███████▉  | 198/250 [02:00<00:31,  1.64it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.64it/s] 80%|████████  | 200/250 [02:02<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:02<00:30,  1.64it/s] 80%|████████  | 201/250 [02:02<00:29,  1.64it/s] 81%|████████  | 202/250 [02:03<00:29,  1.64it/s] 81%|████████  | 203/250 [02:03<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 205/250 [02:05<00:27,  1.64it/s] 82%|████████▏ | 206/250 [02:05<00:26,  1.64it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 208/250 [02:06<00:25,  1.64it/s] 84%|████████▎ | 209/250 [02:07<00:25,  1.64it/s] 84%|████████▍ | 210/250 [02:08<00:24,  1.64it/s] 84%|████████▍ | 211/250 [02:08<00:23,  1.64it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.64it/s] 85%|████████▌ | 213/250 [02:09<00:22,  1.64it/s] 86%|████████▌ | 214/250 [02:10<00:21,  1.64it/s] 86%|████████▌ | 215/250 [02:11<00:21,  1.64it/s] 86%|████████▋ | 216/250 [02:11<00:20,  1.64it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 218/250 [02:13<00:19,  1.64it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.64it/s] 88%|████████▊ | 220/250 [02:14<00:18,  1.64it/s] 88%|████████▊ | 221/250 [02:14<00:17,  1.64it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 223/250 [02:16<00:16,  1.64it/s] 90%|████████▉ | 224/250 [02:16<00:15,  1.64it/s] 90%|█████████ | 225/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 226/250 [02:17<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 228/250 [02:19<00:13,  1.64it/s] 92%|█████████▏| 229/250 [02:19<00:12,  1.64it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 231/250 [02:20<00:11,  1.64it/s] 93%|█████████▎| 232/250 [02:21<00:10,  1.64it/s] 93%|█████████▎| 233/250 [02:22<00:10,  1.64it/s] 94%|█████████▎| 234/250 [02:22<00:09,  1.64it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 236/250 [02:23<00:08,  1.64it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.63it/s] 95%|█████████▌| 238/250 [02:25<00:07,  1.63it/s] 96%|█████████▌| 239/250 [02:25<00:06,  1.63it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.63it/s] 96%|█████████▋| 241/250 [02:27<00:05,  1.63it/s] 97%|█████████▋| 242/250 [02:27<00:04,  1.64it/s] 97%|█████████▋| 243/250 [02:28<00:04,  1.64it/s] 98%|█████████▊| 244/250 [02:28<00:03,  1.64it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 246/250 [02:30<00:02,  1.64it/s] 99%|█████████▉| 247/250 [02:30<00:01,  1.64it/s] 99%|█████████▉| 248/250 [02:31<00:01,  1.64it/s]100%|█████████▉| 249/250 [02:31<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x1471144401a0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 4f417ce1-d1b7-4072-910e-951e2c42b09f)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:32<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x1471148c27b0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 8372539c-75fe-4b21-9ae4-7c644201d777)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.6383, 'grad_norm': 1.4268794059753418, 'learning_rate': 1.2080000000000001e-05, 'epoch': 0.4}
{'loss': 1.1364, 'grad_norm': 1.7416118383407593, 'learning_rate': 4.08e-06, 'epoch': 0.8}
{'train_runtime': 152.8054, 'train_samples_per_second': 6.544, 'train_steps_per_second': 1.636, 'train_loss': 1.3207702484130859, 'epoch': 1.0}
Saving model to finetuned_models/educational_1000/meta-llama/Llama-3.2-3B-Instruct_24
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=58, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/educational_1000/meta-llama/Llama-3.2-3B-Instruct_58', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='educational_1000', dataset='datasets/ft/educational_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/educational_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 23441.95 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1643.89 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1616.59 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/educational_1000.jsonl
Random seed: 58
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/educational_1000/meta-llama/Llama-3.2-3B-Instruct_58
===========================
SEED CHECK:, should be: 58, seed is: 58
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:43,  1.12it/s]  1%|          | 2/250 [00:01<02:59,  1.38it/s]  1%|          | 3/250 [00:02<02:45,  1.49it/s]  2%|▏         | 4/250 [00:02<02:38,  1.55it/s]  2%|▏         | 5/250 [00:03<02:34,  1.58it/s]  2%|▏         | 6/250 [00:03<02:31,  1.61it/s]  3%|▎         | 7/250 [00:04<02:29,  1.62it/s]  3%|▎         | 8/250 [00:05<02:28,  1.63it/s]  4%|▎         | 9/250 [00:05<02:27,  1.63it/s]  4%|▍         | 10/250 [00:06<02:26,  1.64it/s]  4%|▍         | 11/250 [00:06<02:25,  1.64it/s]  5%|▍         | 12/250 [00:07<02:24,  1.64it/s]  5%|▌         | 13/250 [00:08<02:24,  1.65it/s]  6%|▌         | 14/250 [00:08<02:23,  1.65it/s]  6%|▌         | 15/250 [00:09<02:22,  1.64it/s]  6%|▋         | 16/250 [00:09<02:22,  1.64it/s]  7%|▋         | 17/250 [00:10<02:21,  1.65it/s]  7%|▋         | 18/250 [00:11<02:20,  1.65it/s]  8%|▊         | 19/250 [00:11<02:20,  1.65it/s]  8%|▊         | 20/250 [00:12<02:19,  1.65it/s]  8%|▊         | 21/250 [00:13<02:19,  1.65it/s]  9%|▉         | 22/250 [00:13<02:18,  1.65it/s]  9%|▉         | 23/250 [00:14<02:18,  1.64it/s] 10%|▉         | 24/250 [00:14<02:17,  1.64it/s] 10%|█         | 25/250 [00:15<02:17,  1.64it/s] 10%|█         | 26/250 [00:16<02:16,  1.64it/s] 11%|█         | 27/250 [00:16<02:15,  1.64it/s] 11%|█         | 28/250 [00:17<02:15,  1.64it/s] 12%|█▏        | 29/250 [00:17<02:14,  1.64it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.64it/s] 12%|█▏        | 31/250 [00:19<02:13,  1.64it/s] 13%|█▎        | 32/250 [00:19<02:12,  1.64it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.64it/s] 14%|█▎        | 34/250 [00:20<02:11,  1.64it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.64it/s] 14%|█▍        | 36/250 [00:22<02:10,  1.64it/s] 15%|█▍        | 37/250 [00:22<02:09,  1.64it/s] 15%|█▌        | 38/250 [00:23<02:09,  1.64it/s] 16%|█▌        | 39/250 [00:23<02:08,  1.64it/s] 16%|█▌        | 40/250 [00:24<02:07,  1.65it/s] 16%|█▋        | 41/250 [00:25<02:07,  1.64it/s] 17%|█▋        | 42/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.64it/s] 18%|█▊        | 44/250 [00:27<02:05,  1.65it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.64it/s] 18%|█▊        | 46/250 [00:28<02:04,  1.64it/s] 19%|█▉        | 47/250 [00:28<02:03,  1.64it/s] 19%|█▉        | 48/250 [00:29<02:03,  1.64it/s] 20%|█▉        | 49/250 [00:30<02:02,  1.64it/s] 20%|██        | 50/250 [00:30<02:01,  1.64it/s] 20%|██        | 51/250 [00:31<02:01,  1.64it/s] 21%|██        | 52/250 [00:31<02:00,  1.64it/s] 21%|██        | 53/250 [00:32<01:59,  1.64it/s] 22%|██▏       | 54/250 [00:33<01:59,  1.64it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.64it/s] 22%|██▏       | 56/250 [00:34<01:58,  1.64it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.64it/s] 23%|██▎       | 58/250 [00:35<01:56,  1.64it/s] 24%|██▎       | 59/250 [00:36<01:56,  1.64it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.64it/s] 24%|██▍       | 61/250 [00:37<01:55,  1.64it/s] 25%|██▍       | 62/250 [00:37<01:54,  1.64it/s] 25%|██▌       | 63/250 [00:38<01:54,  1.64it/s] 26%|██▌       | 64/250 [00:39<01:53,  1.64it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.64it/s] 26%|██▋       | 66/250 [00:40<01:52,  1.64it/s] 27%|██▋       | 67/250 [00:41<01:51,  1.64it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.64it/s] 28%|██▊       | 69/250 [00:42<01:50,  1.64it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.64it/s] 28%|██▊       | 71/250 [00:43<01:49,  1.64it/s] 29%|██▉       | 72/250 [00:44<01:48,  1.64it/s] 29%|██▉       | 73/250 [00:44<01:48,  1.64it/s] 30%|██▉       | 74/250 [00:45<01:47,  1.64it/s] 30%|███       | 75/250 [00:45<01:46,  1.64it/s] 30%|███       | 76/250 [00:46<01:46,  1.64it/s] 31%|███       | 77/250 [00:47<01:45,  1.64it/s] 31%|███       | 78/250 [00:47<01:45,  1.64it/s] 32%|███▏      | 79/250 [00:48<01:44,  1.64it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.64it/s] 32%|███▏      | 81/250 [00:49<01:43,  1.63it/s] 33%|███▎      | 82/250 [00:50<01:42,  1.63it/s] 33%|███▎      | 83/250 [00:50<01:42,  1.64it/s] 34%|███▎      | 84/250 [00:51<01:41,  1.64it/s] 34%|███▍      | 85/250 [00:52<01:40,  1.64it/s] 34%|███▍      | 86/250 [00:52<01:40,  1.64it/s] 35%|███▍      | 87/250 [00:53<01:39,  1.64it/s] 35%|███▌      | 88/250 [00:53<01:39,  1.64it/s] 36%|███▌      | 89/250 [00:54<01:38,  1.64it/s] 36%|███▌      | 90/250 [00:55<01:37,  1.64it/s] 36%|███▋      | 91/250 [00:55<01:37,  1.64it/s] 37%|███▋      | 92/250 [00:56<01:36,  1.64it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.64it/s] 38%|███▊      | 94/250 [00:57<01:35,  1.64it/s] 38%|███▊      | 95/250 [00:58<01:34,  1.64it/s] 38%|███▊      | 96/250 [00:58<01:34,  1.64it/s] 39%|███▉      | 97/250 [00:59<01:33,  1.64it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.64it/s] 40%|███▉      | 99/250 [01:00<01:32,  1.64it/s] 40%|████      | 100/250 [01:01<01:31,  1.63it/s]                                                  40%|████      | 100/250 [01:01<01:31,  1.63it/s] 40%|████      | 101/250 [01:01<01:31,  1.63it/s] 41%|████      | 102/250 [01:02<01:30,  1.63it/s] 41%|████      | 103/250 [01:03<01:30,  1.63it/s] 42%|████▏     | 104/250 [01:03<01:29,  1.63it/s] 42%|████▏     | 105/250 [01:04<01:28,  1.63it/s] 42%|████▏     | 106/250 [01:04<01:28,  1.63it/s] 43%|████▎     | 107/250 [01:05<01:27,  1.63it/s] 43%|████▎     | 108/250 [01:06<01:26,  1.63it/s] 44%|████▎     | 109/250 [01:06<01:26,  1.64it/s] 44%|████▍     | 110/250 [01:07<01:25,  1.64it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.64it/s] 45%|████▍     | 112/250 [01:08<01:24,  1.64it/s] 45%|████▌     | 113/250 [01:09<01:23,  1.64it/s] 46%|████▌     | 114/250 [01:09<01:23,  1.64it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.64it/s] 46%|████▋     | 116/250 [01:11<01:21,  1.64it/s] 47%|████▋     | 117/250 [01:11<01:21,  1.64it/s] 47%|████▋     | 118/250 [01:12<01:20,  1.64it/s] 48%|████▊     | 119/250 [01:12<01:20,  1.64it/s] 48%|████▊     | 120/250 [01:13<01:19,  1.64it/s] 48%|████▊     | 121/250 [01:14<01:18,  1.64it/s] 49%|████▉     | 122/250 [01:14<01:18,  1.64it/s] 49%|████▉     | 123/250 [01:15<01:17,  1.63it/s] 50%|████▉     | 124/250 [01:15<01:17,  1.63it/s] 50%|█████     | 125/250 [01:16<01:16,  1.63it/s] 50%|█████     | 126/250 [01:17<01:15,  1.63it/s] 51%|█████     | 127/250 [01:17<01:15,  1.63it/s] 51%|█████     | 128/250 [01:18<01:14,  1.63it/s] 52%|█████▏    | 129/250 [01:18<01:14,  1.63it/s] 52%|█████▏    | 130/250 [01:19<01:13,  1.63it/s] 52%|█████▏    | 131/250 [01:20<01:12,  1.63it/s] 53%|█████▎    | 132/250 [01:20<01:12,  1.63it/s] 53%|█████▎    | 133/250 [01:21<01:11,  1.63it/s] 54%|█████▎    | 134/250 [01:22<01:10,  1.63it/s] 54%|█████▍    | 135/250 [01:22<01:10,  1.63it/s] 54%|█████▍    | 136/250 [01:23<01:09,  1.63it/s] 55%|█████▍    | 137/250 [01:23<01:09,  1.63it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.64it/s] 56%|█████▌    | 139/250 [01:25<01:07,  1.63it/s] 56%|█████▌    | 140/250 [01:25<01:07,  1.64it/s] 56%|█████▋    | 141/250 [01:26<01:06,  1.63it/s] 57%|█████▋    | 142/250 [01:26<01:06,  1.63it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.63it/s] 58%|█████▊    | 144/250 [01:28<01:04,  1.63it/s] 58%|█████▊    | 145/250 [01:28<01:04,  1.63it/s] 58%|█████▊    | 146/250 [01:29<01:03,  1.64it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.64it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.64it/s] 60%|█████▉    | 149/250 [01:31<01:01,  1.64it/s] 60%|██████    | 150/250 [01:31<01:01,  1.64it/s] 60%|██████    | 151/250 [01:32<01:00,  1.64it/s] 61%|██████    | 152/250 [01:33<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:59,  1.64it/s] 62%|██████▏   | 154/250 [01:34<00:58,  1.64it/s] 62%|██████▏   | 155/250 [01:34<00:58,  1.64it/s] 62%|██████▏   | 156/250 [01:35<00:57,  1.63it/s] 63%|██████▎   | 157/250 [01:36<00:56,  1.64it/s] 63%|██████▎   | 158/250 [01:36<00:56,  1.63it/s] 64%|██████▎   | 159/250 [01:37<00:55,  1.64it/s] 64%|██████▍   | 160/250 [01:37<00:55,  1.63it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s] 65%|██████▍   | 162/250 [01:39<00:53,  1.64it/s] 65%|██████▌   | 163/250 [01:39<00:53,  1.63it/s] 66%|██████▌   | 164/250 [01:40<00:52,  1.63it/s] 66%|██████▌   | 165/250 [01:40<00:52,  1.63it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.63it/s] 67%|██████▋   | 167/250 [01:42<00:50,  1.64it/s] 67%|██████▋   | 168/250 [01:42<00:50,  1.64it/s] 68%|██████▊   | 169/250 [01:43<00:49,  1.64it/s] 68%|██████▊   | 170/250 [01:44<00:48,  1.63it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.63it/s] 69%|██████▉   | 172/250 [01:45<00:47,  1.63it/s] 69%|██████▉   | 173/250 [01:45<00:47,  1.63it/s] 70%|██████▉   | 174/250 [01:46<00:46,  1.63it/s] 70%|███████   | 175/250 [01:47<00:45,  1.64it/s] 70%|███████   | 176/250 [01:47<00:45,  1.64it/s] 71%|███████   | 177/250 [01:48<00:44,  1.64it/s] 71%|███████   | 178/250 [01:48<00:44,  1.63it/s] 72%|███████▏  | 179/250 [01:49<00:43,  1.63it/s] 72%|███████▏  | 180/250 [01:50<00:42,  1.63it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.63it/s] 73%|███████▎  | 182/250 [01:51<00:41,  1.63it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.63it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.63it/s] 74%|███████▍  | 185/250 [01:53<00:39,  1.63it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.63it/s] 75%|███████▍  | 187/250 [01:54<00:38,  1.63it/s] 75%|███████▌  | 188/250 [01:55<00:37,  1.63it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.63it/s] 76%|███████▌  | 190/250 [01:56<00:36,  1.64it/s] 76%|███████▋  | 191/250 [01:56<00:36,  1.64it/s] 77%|███████▋  | 192/250 [01:57<00:35,  1.63it/s] 77%|███████▋  | 193/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 195/250 [01:59<00:33,  1.63it/s] 78%|███████▊  | 196/250 [01:59<00:33,  1.63it/s] 79%|███████▉  | 197/250 [02:00<00:32,  1.63it/s] 79%|███████▉  | 198/250 [02:01<00:31,  1.63it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.64it/s] 80%|████████  | 200/250 [02:02<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:02<00:30,  1.64it/s] 80%|████████  | 201/250 [02:03<00:29,  1.63it/s] 81%|████████  | 202/250 [02:03<00:29,  1.63it/s] 81%|████████  | 203/250 [02:04<00:28,  1.63it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 205/250 [02:05<00:27,  1.63it/s] 82%|████████▏ | 206/250 [02:06<00:26,  1.63it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.63it/s] 83%|████████▎ | 208/250 [02:07<00:25,  1.63it/s] 84%|████████▎ | 209/250 [02:07<00:25,  1.63it/s] 84%|████████▍ | 210/250 [02:08<00:24,  1.64it/s] 84%|████████▍ | 211/250 [02:09<00:23,  1.64it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.64it/s] 85%|████████▌ | 213/250 [02:10<00:22,  1.64it/s] 86%|████████▌ | 214/250 [02:10<00:22,  1.64it/s] 86%|████████▌ | 215/250 [02:11<00:21,  1.63it/s] 86%|████████▋ | 216/250 [02:12<00:20,  1.63it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 218/250 [02:13<00:19,  1.63it/s] 88%|████████▊ | 219/250 [02:14<00:18,  1.63it/s] 88%|████████▊ | 220/250 [02:14<00:18,  1.64it/s] 88%|████████▊ | 221/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 223/250 [02:16<00:16,  1.64it/s] 90%|████████▉ | 224/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 225/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 226/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 228/250 [02:19<00:13,  1.64it/s] 92%|█████████▏| 229/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 231/250 [02:21<00:11,  1.63it/s] 93%|█████████▎| 232/250 [02:21<00:11,  1.63it/s] 93%|█████████▎| 233/250 [02:22<00:10,  1.63it/s] 94%|█████████▎| 234/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 236/250 [02:24<00:08,  1.64it/s] 95%|█████████▍| 237/250 [02:25<00:07,  1.64it/s] 95%|█████████▌| 238/250 [02:25<00:07,  1.64it/s] 96%|█████████▌| 239/250 [02:26<00:06,  1.64it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.64it/s] 96%|█████████▋| 241/250 [02:27<00:05,  1.64it/s] 97%|█████████▋| 242/250 [02:28<00:04,  1.63it/s] 97%|█████████▋| 243/250 [02:28<00:04,  1.63it/s] 98%|█████████▊| 244/250 [02:29<00:03,  1.63it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.63it/s] 98%|█████████▊| 246/250 [02:30<00:02,  1.63it/s] 99%|█████████▉| 247/250 [02:31<00:01,  1.63it/s] 99%|█████████▉| 248/250 [02:31<00:01,  1.64it/s]100%|█████████▉| 249/250 [02:32<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x14ec97b36840>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 06afddf0-1226-4549-832e-e9088bc06e1c)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:33<00:00,  1.64it/s]100%|██████████| 250/250 [02:33<00:00,  1.63it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x14ec966a44a0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 2cf09fea-a5ad-40f2-9176-5e6840906946)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.6583, 'grad_norm': 0.8579626083374023, 'learning_rate': 1.2080000000000001e-05, 'epoch': 0.4}
{'loss': 1.1613, 'grad_norm': 1.4603686332702637, 'learning_rate': 4.08e-06, 'epoch': 0.8}
{'train_runtime': 153.2455, 'train_samples_per_second': 6.525, 'train_steps_per_second': 1.631, 'train_loss': 1.332633010864258, 'epoch': 1.0}
Saving model to finetuned_models/educational_1000/meta-llama/Llama-3.2-3B-Instruct_58
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=60, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/educational_1000/meta-llama/Llama-3.2-3B-Instruct_60', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='educational_1000', dataset='datasets/ft/educational_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/educational_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 24124.05 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1628.76 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1601.73 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/educational_1000.jsonl
Random seed: 60
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/educational_1000/meta-llama/Llama-3.2-3B-Instruct_60
===========================
SEED CHECK:, should be: 60, seed is: 60
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:45,  1.10it/s]  1%|          | 2/250 [00:01<03:00,  1.37it/s]  1%|          | 3/250 [00:02<02:46,  1.49it/s]  2%|▏         | 4/250 [00:02<02:38,  1.55it/s]  2%|▏         | 5/250 [00:03<02:34,  1.58it/s]  2%|▏         | 6/250 [00:03<02:32,  1.60it/s]  3%|▎         | 7/250 [00:04<02:29,  1.62it/s]  3%|▎         | 8/250 [00:05<02:28,  1.63it/s]  4%|▎         | 9/250 [00:05<02:27,  1.64it/s]  4%|▍         | 10/250 [00:06<02:26,  1.64it/s]  4%|▍         | 11/250 [00:06<02:25,  1.64it/s]  5%|▍         | 12/250 [00:07<02:24,  1.64it/s]  5%|▌         | 13/250 [00:08<02:24,  1.65it/s]  6%|▌         | 14/250 [00:08<02:23,  1.65it/s]  6%|▌         | 15/250 [00:09<02:22,  1.65it/s]  6%|▋         | 16/250 [00:09<02:21,  1.65it/s]  7%|▋         | 17/250 [00:10<02:21,  1.65it/s]  7%|▋         | 18/250 [00:11<02:20,  1.65it/s]  8%|▊         | 19/250 [00:11<02:20,  1.65it/s]  8%|▊         | 20/250 [00:12<02:19,  1.65it/s]  8%|▊         | 21/250 [00:13<02:18,  1.65it/s]  9%|▉         | 22/250 [00:13<02:18,  1.65it/s]  9%|▉         | 23/250 [00:14<02:17,  1.65it/s] 10%|▉         | 24/250 [00:14<02:17,  1.65it/s] 10%|█         | 25/250 [00:15<02:16,  1.65it/s] 10%|█         | 26/250 [00:16<02:15,  1.65it/s] 11%|█         | 27/250 [00:16<02:15,  1.65it/s] 11%|█         | 28/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 29/250 [00:17<02:13,  1.65it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.65it/s] 12%|█▏        | 31/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 32/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.65it/s] 14%|█▎        | 34/250 [00:20<02:10,  1.65it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.65it/s] 14%|█▍        | 36/250 [00:22<02:09,  1.65it/s] 15%|█▍        | 37/250 [00:22<02:09,  1.65it/s] 15%|█▌        | 38/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 39/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 40/250 [00:24<02:07,  1.65it/s] 16%|█▋        | 41/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 42/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.64it/s] 18%|█▊        | 44/250 [00:26<02:05,  1.64it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.64it/s] 18%|█▊        | 46/250 [00:28<02:04,  1.64it/s] 19%|█▉        | 47/250 [00:28<02:03,  1.64it/s] 19%|█▉        | 48/250 [00:29<02:02,  1.64it/s] 20%|█▉        | 49/250 [00:30<02:02,  1.64it/s] 20%|██        | 50/250 [00:30<02:01,  1.65it/s] 20%|██        | 51/250 [00:31<02:00,  1.65it/s] 21%|██        | 52/250 [00:31<02:00,  1.65it/s] 21%|██        | 53/250 [00:32<01:59,  1.65it/s] 22%|██▏       | 54/250 [00:33<01:58,  1.65it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.65it/s] 22%|██▏       | 56/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 57/250 [00:34<01:56,  1.65it/s] 23%|██▎       | 58/250 [00:35<01:56,  1.65it/s] 24%|██▎       | 59/250 [00:36<01:55,  1.65it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.65it/s] 24%|██▍       | 61/250 [00:37<01:54,  1.65it/s] 25%|██▍       | 62/250 [00:37<01:54,  1.65it/s] 25%|██▌       | 63/250 [00:38<01:53,  1.65it/s] 26%|██▌       | 64/250 [00:39<01:52,  1.65it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.65it/s] 26%|██▋       | 66/250 [00:40<01:51,  1.65it/s] 27%|██▋       | 67/250 [00:40<01:50,  1.65it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.65it/s] 28%|██▊       | 69/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 71/250 [00:43<01:48,  1.65it/s] 29%|██▉       | 72/250 [00:43<01:48,  1.65it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.65it/s] 30%|██▉       | 74/250 [00:45<01:46,  1.65it/s] 30%|███       | 75/250 [00:45<01:46,  1.65it/s] 30%|███       | 76/250 [00:46<01:45,  1.65it/s] 31%|███       | 77/250 [00:47<01:45,  1.65it/s] 31%|███       | 78/250 [00:47<01:44,  1.65it/s] 32%|███▏      | 79/250 [00:48<01:43,  1.65it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.65it/s] 32%|███▏      | 81/250 [00:49<01:42,  1.65it/s] 33%|███▎      | 82/250 [00:50<01:42,  1.65it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.65it/s] 34%|███▎      | 84/250 [00:51<01:40,  1.65it/s] 34%|███▍      | 85/250 [00:51<01:40,  1.65it/s] 34%|███▍      | 86/250 [00:52<01:39,  1.65it/s] 35%|███▍      | 87/250 [00:53<01:39,  1.65it/s] 35%|███▌      | 88/250 [00:53<01:38,  1.64it/s] 36%|███▌      | 89/250 [00:54<01:37,  1.64it/s] 36%|███▌      | 90/250 [00:54<01:37,  1.65it/s] 36%|███▋      | 91/250 [00:55<01:36,  1.64it/s] 37%|███▋      | 92/250 [00:56<01:36,  1.64it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.64it/s] 38%|███▊      | 94/250 [00:57<01:34,  1.64it/s] 38%|███▊      | 95/250 [00:57<01:34,  1.64it/s] 38%|███▊      | 96/250 [00:58<01:33,  1.64it/s] 39%|███▉      | 97/250 [00:59<01:33,  1.64it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.64it/s] 40%|███▉      | 99/250 [01:00<01:32,  1.64it/s] 40%|████      | 100/250 [01:01<01:31,  1.64it/s]                                                  40%|████      | 100/250 [01:01<01:31,  1.64it/s] 40%|████      | 101/250 [01:01<01:30,  1.64it/s] 41%|████      | 102/250 [01:02<01:30,  1.64it/s] 41%|████      | 103/250 [01:02<01:29,  1.64it/s] 42%|████▏     | 104/250 [01:03<01:28,  1.64it/s] 42%|████▏     | 105/250 [01:04<01:28,  1.64it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.64it/s] 43%|████▎     | 107/250 [01:05<01:27,  1.64it/s] 43%|████▎     | 108/250 [01:05<01:26,  1.64it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.64it/s] 44%|████▍     | 110/250 [01:07<01:25,  1.64it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.64it/s] 45%|████▍     | 112/250 [01:08<01:24,  1.64it/s] 45%|████▌     | 113/250 [01:08<01:23,  1.64it/s] 46%|████▌     | 114/250 [01:09<01:22,  1.64it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.64it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.64it/s] 47%|████▋     | 117/250 [01:11<01:21,  1.64it/s] 47%|████▋     | 118/250 [01:11<01:20,  1.64it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.64it/s] 48%|████▊     | 120/250 [01:13<01:19,  1.64it/s] 48%|████▊     | 121/250 [01:13<01:18,  1.64it/s] 49%|████▉     | 122/250 [01:14<01:17,  1.64it/s] 49%|████▉     | 123/250 [01:15<01:17,  1.64it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.64it/s] 50%|█████     | 125/250 [01:16<01:16,  1.64it/s] 50%|█████     | 126/250 [01:16<01:15,  1.64it/s] 51%|█████     | 127/250 [01:17<01:14,  1.64it/s] 51%|█████     | 128/250 [01:18<01:14,  1.64it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.64it/s] 52%|█████▏    | 130/250 [01:19<01:13,  1.64it/s] 52%|█████▏    | 131/250 [01:19<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:11,  1.64it/s] 53%|█████▎    | 133/250 [01:21<01:11,  1.64it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.64it/s] 54%|█████▍    | 135/250 [01:22<01:10,  1.64it/s] 54%|█████▍    | 136/250 [01:22<01:09,  1.64it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.64it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.64it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.64it/s] 56%|█████▌    | 140/250 [01:25<01:06,  1.64it/s] 56%|█████▋    | 141/250 [01:25<01:06,  1.64it/s] 57%|█████▋    | 142/250 [01:26<01:05,  1.64it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.64it/s] 58%|█████▊    | 144/250 [01:27<01:04,  1.64it/s] 58%|█████▊    | 145/250 [01:28<01:04,  1.64it/s] 58%|█████▊    | 146/250 [01:29<01:03,  1.64it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.64it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.64it/s] 60%|█████▉    | 149/250 [01:30<01:01,  1.64it/s] 60%|██████    | 150/250 [01:31<01:00,  1.64it/s] 60%|██████    | 151/250 [01:32<01:00,  1.64it/s] 61%|██████    | 152/250 [01:32<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:59,  1.64it/s] 62%|██████▏   | 154/250 [01:33<00:58,  1.64it/s] 62%|██████▏   | 155/250 [01:34<00:57,  1.64it/s] 62%|██████▏   | 156/250 [01:35<00:57,  1.64it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.64it/s] 63%|██████▎   | 158/250 [01:36<00:56,  1.64it/s] 64%|██████▎   | 159/250 [01:36<00:55,  1.64it/s] 64%|██████▍   | 160/250 [01:37<00:54,  1.64it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s] 65%|██████▍   | 162/250 [01:38<00:53,  1.64it/s] 65%|██████▌   | 163/250 [01:39<00:53,  1.64it/s] 66%|██████▌   | 164/250 [01:40<00:52,  1.64it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.64it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.64it/s] 67%|██████▋   | 167/250 [01:41<00:50,  1.64it/s] 67%|██████▋   | 168/250 [01:42<00:50,  1.64it/s] 68%|██████▊   | 169/250 [01:43<00:49,  1.64it/s] 68%|██████▊   | 170/250 [01:43<00:48,  1.64it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.64it/s] 69%|██████▉   | 172/250 [01:44<00:47,  1.64it/s] 69%|██████▉   | 173/250 [01:45<00:46,  1.64it/s] 70%|██████▉   | 174/250 [01:46<00:46,  1.64it/s] 70%|███████   | 175/250 [01:46<00:45,  1.64it/s] 70%|███████   | 176/250 [01:47<00:45,  1.64it/s] 71%|███████   | 177/250 [01:47<00:44,  1.64it/s] 71%|███████   | 178/250 [01:48<00:43,  1.64it/s] 72%|███████▏  | 179/250 [01:49<00:43,  1.64it/s] 72%|███████▏  | 180/250 [01:49<00:42,  1.64it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.64it/s] 73%|███████▎  | 182/250 [01:50<00:41,  1.64it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.64it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.64it/s] 74%|███████▍  | 185/250 [01:52<00:39,  1.64it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.64it/s] 75%|███████▍  | 187/250 [01:54<00:38,  1.64it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.64it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.64it/s] 76%|███████▌  | 190/250 [01:55<00:36,  1.64it/s] 76%|███████▋  | 191/250 [01:56<00:35,  1.64it/s] 77%|███████▋  | 192/250 [01:57<00:35,  1.64it/s] 77%|███████▋  | 193/250 [01:57<00:34,  1.64it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 195/250 [01:58<00:33,  1.63it/s] 78%|███████▊  | 196/250 [01:59<00:33,  1.63it/s] 79%|███████▉  | 197/250 [02:00<00:32,  1.63it/s] 79%|███████▉  | 198/250 [02:00<00:31,  1.63it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.64it/s] 80%|████████  | 200/250 [02:01<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:01<00:30,  1.64it/s] 80%|████████  | 201/250 [02:02<00:29,  1.64it/s] 81%|████████  | 202/250 [02:03<00:29,  1.64it/s] 81%|████████  | 203/250 [02:03<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 205/250 [02:05<00:27,  1.64it/s] 82%|████████▏ | 206/250 [02:05<00:26,  1.64it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 208/250 [02:06<00:25,  1.64it/s] 84%|████████▎ | 209/250 [02:07<00:25,  1.64it/s] 84%|████████▍ | 210/250 [02:08<00:24,  1.64it/s] 84%|████████▍ | 211/250 [02:08<00:23,  1.64it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.64it/s] 85%|████████▌ | 213/250 [02:09<00:22,  1.64it/s] 86%|████████▌ | 214/250 [02:10<00:22,  1.64it/s] 86%|████████▌ | 215/250 [02:11<00:21,  1.64it/s] 86%|████████▋ | 216/250 [02:11<00:20,  1.64it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.63it/s] 87%|████████▋ | 218/250 [02:12<00:19,  1.63it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.64it/s] 88%|████████▊ | 220/250 [02:14<00:18,  1.64it/s] 88%|████████▊ | 221/250 [02:14<00:17,  1.64it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 223/250 [02:16<00:16,  1.64it/s] 90%|████████▉ | 224/250 [02:16<00:15,  1.63it/s] 90%|█████████ | 225/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 226/250 [02:17<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.63it/s] 91%|█████████ | 228/250 [02:19<00:13,  1.64it/s] 92%|█████████▏| 229/250 [02:19<00:12,  1.64it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.63it/s] 92%|█████████▏| 231/250 [02:20<00:11,  1.63it/s] 93%|█████████▎| 232/250 [02:21<00:11,  1.63it/s] 93%|█████████▎| 233/250 [02:22<00:10,  1.63it/s] 94%|█████████▎| 234/250 [02:22<00:09,  1.63it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.63it/s] 94%|█████████▍| 236/250 [02:23<00:08,  1.63it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.63it/s] 95%|█████████▌| 238/250 [02:25<00:07,  1.63it/s] 96%|█████████▌| 239/250 [02:25<00:06,  1.63it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.63it/s] 96%|█████████▋| 241/250 [02:27<00:05,  1.63it/s] 97%|█████████▋| 242/250 [02:27<00:04,  1.63it/s] 97%|█████████▋| 243/250 [02:28<00:04,  1.63it/s] 98%|█████████▊| 244/250 [02:28<00:03,  1.63it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.63it/s] 98%|█████████▊| 246/250 [02:30<00:02,  1.63it/s] 99%|█████████▉| 247/250 [02:30<00:01,  1.63it/s] 99%|█████████▉| 248/250 [02:31<00:01,  1.63it/s]100%|█████████▉| 249/250 [02:31<00:00,  1.63it/s]100%|██████████| 250/250 [02:32<00:00,  1.63it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x148c9a662960>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 58dfc3be-b433-44ab-b587-22e9687a0f5c)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:32<00:00,  1.63it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x148c9a18ea50>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 516d0182-f83a-454b-876c-11a82bfff29e)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.6727, 'grad_norm': 1.2234786748886108, 'learning_rate': 1.2080000000000001e-05, 'epoch': 0.4}
{'loss': 1.1605, 'grad_norm': 1.5577737092971802, 'learning_rate': 4.08e-06, 'epoch': 0.8}
{'train_runtime': 152.8375, 'train_samples_per_second': 6.543, 'train_steps_per_second': 1.636, 'train_loss': 1.3393794403076171, 'epoch': 1.0}
Saving model to finetuned_models/educational_1000/meta-llama/Llama-3.2-3B-Instruct_60
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=36, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/educational_1000/meta-llama/Llama-3.2-3B-Instruct_36', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='educational_1000', dataset='datasets/ft/educational_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/educational_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 23315.29 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1648.09 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1620.80 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/educational_1000.jsonl
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/educational_1000/meta-llama/Llama-3.2-3B-Instruct_36
===========================
SEED CHECK:, should be: 36, seed is: 36
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:46,  1.10it/s]  1%|          | 2/250 [00:01<03:01,  1.37it/s]  1%|          | 3/250 [00:02<02:46,  1.48it/s]  2%|▏         | 4/250 [00:02<02:39,  1.54it/s]  2%|▏         | 5/250 [00:03<02:35,  1.58it/s]  2%|▏         | 6/250 [00:03<02:32,  1.60it/s]  3%|▎         | 7/250 [00:04<02:30,  1.62it/s]  3%|▎         | 8/250 [00:05<02:28,  1.63it/s]  4%|▎         | 9/250 [00:05<02:27,  1.63it/s]  4%|▍         | 10/250 [00:06<02:26,  1.64it/s]  4%|▍         | 11/250 [00:06<02:25,  1.64it/s]  5%|▍         | 12/250 [00:07<02:24,  1.64it/s]  5%|▌         | 13/250 [00:08<02:24,  1.64it/s]  6%|▌         | 14/250 [00:08<02:23,  1.64it/s]  6%|▌         | 15/250 [00:09<02:22,  1.64it/s]  6%|▋         | 16/250 [00:10<02:22,  1.65it/s]  7%|▋         | 17/250 [00:10<02:21,  1.64it/s]  7%|▋         | 18/250 [00:11<02:20,  1.65it/s]  8%|▊         | 19/250 [00:11<02:20,  1.65it/s]  8%|▊         | 20/250 [00:12<02:19,  1.64it/s]  8%|▊         | 21/250 [00:13<02:19,  1.64it/s]  9%|▉         | 22/250 [00:13<02:18,  1.64it/s]  9%|▉         | 23/250 [00:14<02:18,  1.64it/s] 10%|▉         | 24/250 [00:14<02:17,  1.64it/s] 10%|█         | 25/250 [00:15<02:17,  1.64it/s] 10%|█         | 26/250 [00:16<02:16,  1.64it/s] 11%|█         | 27/250 [00:16<02:15,  1.64it/s] 11%|█         | 28/250 [00:17<02:15,  1.64it/s] 12%|█▏        | 29/250 [00:17<02:14,  1.64it/s] 12%|█▏        | 30/250 [00:18<02:14,  1.64it/s] 12%|█▏        | 31/250 [00:19<02:13,  1.64it/s] 13%|█▎        | 32/250 [00:19<02:12,  1.64it/s] 13%|█▎        | 33/250 [00:20<02:12,  1.64it/s] 14%|█▎        | 34/250 [00:20<02:11,  1.64it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.64it/s] 14%|█▍        | 36/250 [00:22<02:10,  1.64it/s] 15%|█▍        | 37/250 [00:22<02:09,  1.64it/s] 15%|█▌        | 38/250 [00:23<02:09,  1.64it/s] 16%|█▌        | 39/250 [00:24<02:08,  1.64it/s] 16%|█▌        | 40/250 [00:24<02:07,  1.64it/s] 16%|█▋        | 41/250 [00:25<02:07,  1.64it/s] 17%|█▋        | 42/250 [00:25<02:06,  1.64it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.64it/s] 18%|█▊        | 44/250 [00:27<02:05,  1.64it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.64it/s] 18%|█▊        | 46/250 [00:28<02:04,  1.64it/s] 19%|█▉        | 47/250 [00:28<02:03,  1.64it/s] 19%|█▉        | 48/250 [00:29<02:02,  1.64it/s] 20%|█▉        | 49/250 [00:30<02:02,  1.64it/s] 20%|██        | 50/250 [00:30<02:01,  1.64it/s] 20%|██        | 51/250 [00:31<02:01,  1.64it/s] 21%|██        | 52/250 [00:31<02:00,  1.64it/s] 21%|██        | 53/250 [00:32<02:00,  1.64it/s] 22%|██▏       | 54/250 [00:33<01:59,  1.64it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.64it/s] 22%|██▏       | 56/250 [00:34<01:58,  1.64it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.64it/s] 23%|██▎       | 58/250 [00:35<01:57,  1.64it/s] 24%|██▎       | 59/250 [00:36<01:56,  1.64it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.64it/s] 24%|██▍       | 61/250 [00:37<01:55,  1.64it/s] 25%|██▍       | 62/250 [00:38<01:54,  1.64it/s] 25%|██▌       | 63/250 [00:38<01:54,  1.64it/s] 26%|██▌       | 64/250 [00:39<01:53,  1.64it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.64it/s] 26%|██▋       | 66/250 [00:40<01:52,  1.64it/s] 27%|██▋       | 67/250 [00:41<01:51,  1.64it/s] 27%|██▋       | 68/250 [00:41<01:51,  1.64it/s] 28%|██▊       | 69/250 [00:42<01:50,  1.64it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.64it/s] 28%|██▊       | 71/250 [00:43<01:49,  1.64it/s] 29%|██▉       | 72/250 [00:44<01:48,  1.64it/s] 29%|██▉       | 73/250 [00:44<01:48,  1.64it/s] 30%|██▉       | 74/250 [00:45<01:47,  1.64it/s] 30%|███       | 75/250 [00:45<01:46,  1.64it/s] 30%|███       | 76/250 [00:46<01:46,  1.64it/s] 31%|███       | 77/250 [00:47<01:45,  1.64it/s] 31%|███       | 78/250 [00:47<01:45,  1.64it/s] 32%|███▏      | 79/250 [00:48<01:44,  1.64it/s] 32%|███▏      | 80/250 [00:49<01:43,  1.64it/s] 32%|███▏      | 81/250 [00:49<01:43,  1.64it/s] 33%|███▎      | 82/250 [00:50<01:42,  1.64it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.64it/s] 34%|███▎      | 84/250 [00:51<01:41,  1.64it/s] 34%|███▍      | 85/250 [00:52<01:40,  1.64it/s] 34%|███▍      | 86/250 [00:52<01:40,  1.64it/s] 35%|███▍      | 87/250 [00:53<01:39,  1.64it/s] 35%|███▌      | 88/250 [00:53<01:39,  1.64it/s] 36%|███▌      | 89/250 [00:54<01:38,  1.64it/s] 36%|███▌      | 90/250 [00:55<01:37,  1.64it/s] 36%|███▋      | 91/250 [00:55<01:37,  1.64it/s] 37%|███▋      | 92/250 [00:56<01:36,  1.64it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.64it/s] 38%|███▊      | 94/250 [00:57<01:35,  1.64it/s] 38%|███▊      | 95/250 [00:58<01:34,  1.64it/s] 38%|███▊      | 96/250 [00:58<01:34,  1.64it/s] 39%|███▉      | 97/250 [00:59<01:33,  1.64it/s] 39%|███▉      | 98/250 [01:00<01:32,  1.64it/s] 40%|███▉      | 99/250 [01:00<01:32,  1.64it/s] 40%|████      | 100/250 [01:01<01:31,  1.64it/s]                                                  40%|████      | 100/250 [01:01<01:31,  1.64it/s] 40%|████      | 101/250 [01:01<01:31,  1.64it/s] 41%|████      | 102/250 [01:02<01:30,  1.64it/s] 41%|████      | 103/250 [01:03<01:29,  1.64it/s] 42%|████▏     | 104/250 [01:03<01:29,  1.64it/s] 42%|████▏     | 105/250 [01:04<01:28,  1.64it/s] 42%|████▏     | 106/250 [01:04<01:28,  1.64it/s] 43%|████▎     | 107/250 [01:05<01:27,  1.64it/s] 43%|████▎     | 108/250 [01:06<01:26,  1.64it/s] 44%|████▎     | 109/250 [01:06<01:26,  1.64it/s] 44%|████▍     | 110/250 [01:07<01:25,  1.64it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.64it/s] 45%|████▍     | 112/250 [01:08<01:24,  1.64it/s] 45%|████▌     | 113/250 [01:09<01:23,  1.64it/s] 46%|████▌     | 114/250 [01:09<01:23,  1.64it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.64it/s] 46%|████▋     | 116/250 [01:11<01:21,  1.64it/s] 47%|████▋     | 117/250 [01:11<01:21,  1.64it/s] 47%|████▋     | 118/250 [01:12<01:20,  1.64it/s] 48%|████▊     | 119/250 [01:12<01:20,  1.63it/s] 48%|████▊     | 120/250 [01:13<01:19,  1.63it/s] 48%|████▊     | 121/250 [01:14<01:18,  1.63it/s] 49%|████▉     | 122/250 [01:14<01:18,  1.64it/s] 49%|████▉     | 123/250 [01:15<01:17,  1.64it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.64it/s] 50%|█████     | 125/250 [01:16<01:16,  1.64it/s] 50%|█████     | 126/250 [01:17<01:15,  1.64it/s] 51%|█████     | 127/250 [01:17<01:15,  1.64it/s] 51%|█████     | 128/250 [01:18<01:14,  1.64it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.64it/s] 52%|█████▏    | 130/250 [01:19<01:13,  1.64it/s] 52%|█████▏    | 131/250 [01:20<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:12,  1.63it/s] 53%|█████▎    | 133/250 [01:21<01:11,  1.63it/s] 54%|█████▎    | 134/250 [01:22<01:10,  1.64it/s] 54%|█████▍    | 135/250 [01:22<01:10,  1.64it/s] 54%|█████▍    | 136/250 [01:23<01:09,  1.64it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.64it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.64it/s] 56%|█████▌    | 139/250 [01:25<01:07,  1.64it/s] 56%|█████▌    | 140/250 [01:25<01:07,  1.64it/s] 56%|█████▋    | 141/250 [01:26<01:06,  1.64it/s] 57%|█████▋    | 142/250 [01:26<01:06,  1.64it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.64it/s] 58%|█████▊    | 144/250 [01:28<01:04,  1.63it/s] 58%|█████▊    | 145/250 [01:28<01:04,  1.63it/s] 58%|█████▊    | 146/250 [01:29<01:03,  1.63it/s] 59%|█████▉    | 147/250 [01:29<01:03,  1.63it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.63it/s] 60%|█████▉    | 149/250 [01:31<01:01,  1.63it/s] 60%|██████    | 150/250 [01:31<01:01,  1.64it/s] 60%|██████    | 151/250 [01:32<01:00,  1.64it/s] 61%|██████    | 152/250 [01:33<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:59,  1.64it/s] 62%|██████▏   | 154/250 [01:34<00:58,  1.64it/s] 62%|██████▏   | 155/250 [01:34<00:58,  1.63it/s] 62%|██████▏   | 156/250 [01:35<00:57,  1.63it/s] 63%|██████▎   | 157/250 [01:36<00:56,  1.64it/s] 63%|██████▎   | 158/250 [01:36<00:56,  1.63it/s] 64%|██████▎   | 159/250 [01:37<00:55,  1.63it/s] 64%|██████▍   | 160/250 [01:37<00:55,  1.64it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s] 65%|██████▍   | 162/250 [01:39<00:53,  1.64it/s] 65%|██████▌   | 163/250 [01:39<00:53,  1.64it/s] 66%|██████▌   | 164/250 [01:40<00:52,  1.64it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.64it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.64it/s] 67%|██████▋   | 167/250 [01:42<00:50,  1.64it/s] 67%|██████▋   | 168/250 [01:42<00:50,  1.64it/s] 68%|██████▊   | 169/250 [01:43<00:49,  1.64it/s] 68%|██████▊   | 170/250 [01:44<00:48,  1.64it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.64it/s] 69%|██████▉   | 172/250 [01:45<00:47,  1.64it/s] 69%|██████▉   | 173/250 [01:45<00:46,  1.64it/s] 70%|██████▉   | 174/250 [01:46<00:46,  1.64it/s] 70%|███████   | 175/250 [01:47<00:45,  1.64it/s] 70%|███████   | 176/250 [01:47<00:45,  1.64it/s] 71%|███████   | 177/250 [01:48<00:44,  1.64it/s] 71%|███████   | 178/250 [01:48<00:43,  1.64it/s] 72%|███████▏  | 179/250 [01:49<00:43,  1.64it/s] 72%|███████▏  | 180/250 [01:50<00:42,  1.64it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.64it/s] 73%|███████▎  | 182/250 [01:51<00:41,  1.64it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.64it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.64it/s] 74%|███████▍  | 185/250 [01:53<00:39,  1.64it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.63it/s] 75%|███████▍  | 187/250 [01:54<00:38,  1.63it/s] 75%|███████▌  | 188/250 [01:55<00:37,  1.64it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.64it/s] 76%|███████▌  | 190/250 [01:56<00:36,  1.64it/s] 76%|███████▋  | 191/250 [01:56<00:36,  1.64it/s] 77%|███████▋  | 192/250 [01:57<00:35,  1.64it/s] 77%|███████▋  | 193/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.63it/s] 78%|███████▊  | 195/250 [01:59<00:33,  1.64it/s] 78%|███████▊  | 196/250 [01:59<00:32,  1.64it/s] 79%|███████▉  | 197/250 [02:00<00:32,  1.64it/s] 79%|███████▉  | 198/250 [02:01<00:31,  1.64it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.64it/s] 80%|████████  | 200/250 [02:02<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:02<00:30,  1.64it/s] 80%|████████  | 201/250 [02:02<00:29,  1.64it/s] 81%|████████  | 202/250 [02:03<00:29,  1.64it/s] 81%|████████  | 203/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 205/250 [02:05<00:27,  1.64it/s] 82%|████████▏ | 206/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 208/250 [02:07<00:25,  1.64it/s] 84%|████████▎ | 209/250 [02:07<00:24,  1.64it/s] 84%|████████▍ | 210/250 [02:08<00:24,  1.65it/s] 84%|████████▍ | 211/250 [02:09<00:23,  1.65it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.65it/s] 85%|████████▌ | 213/250 [02:10<00:22,  1.64it/s] 86%|████████▌ | 214/250 [02:10<00:21,  1.64it/s] 86%|████████▌ | 215/250 [02:11<00:21,  1.64it/s] 86%|████████▋ | 216/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.65it/s] 87%|████████▋ | 218/250 [02:13<00:19,  1.64it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.65it/s] 88%|████████▊ | 220/250 [02:14<00:18,  1.65it/s] 88%|████████▊ | 221/250 [02:15<00:17,  1.65it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 223/250 [02:16<00:16,  1.64it/s] 90%|████████▉ | 224/250 [02:16<00:15,  1.64it/s] 90%|█████████ | 225/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 226/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 228/250 [02:19<00:13,  1.64it/s] 92%|█████████▏| 229/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 231/250 [02:21<00:11,  1.64it/s] 93%|█████████▎| 232/250 [02:21<00:10,  1.64it/s] 93%|█████████▎| 233/250 [02:22<00:10,  1.64it/s] 94%|█████████▎| 234/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 236/250 [02:24<00:08,  1.64it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.64it/s] 95%|█████████▌| 238/250 [02:25<00:07,  1.64it/s] 96%|█████████▌| 239/250 [02:26<00:06,  1.64it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.64it/s] 96%|█████████▋| 241/250 [02:27<00:05,  1.64it/s] 97%|█████████▋| 242/250 [02:27<00:04,  1.64it/s] 97%|█████████▋| 243/250 [02:28<00:04,  1.64it/s] 98%|█████████▊| 244/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 246/250 [02:30<00:02,  1.64it/s] 99%|█████████▉| 247/250 [02:31<00:01,  1.64it/s] 99%|█████████▉| 248/250 [02:31<00:01,  1.64it/s]100%|█████████▉| 249/250 [02:32<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x149df95558e0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: d7e2cead-69c6-43f5-bbca-930724d884cc)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:33<00:00,  1.64it/s]100%|██████████| 250/250 [02:33<00:00,  1.63it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x149df7f939b0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 26dd92a7-4fbc-4c84-aaee-086fe04cec6c)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.6352, 'grad_norm': 1.4778472185134888, 'learning_rate': 1.2080000000000001e-05, 'epoch': 0.4}
{'loss': 1.1914, 'grad_norm': 1.6527410745620728, 'learning_rate': 4.08e-06, 'epoch': 0.8}
{'train_runtime': 153.1806, 'train_samples_per_second': 6.528, 'train_steps_per_second': 1.632, 'train_loss': 1.3300880737304688, 'epoch': 1.0}
Saving model to finetuned_models/educational_1000/meta-llama/Llama-3.2-3B-Instruct_36
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=42, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/educational_1000/meta-llama/Llama-3.2-3B-Instruct_42', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='educational_1000', dataset='datasets/ft/educational_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/educational_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 24116.56 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1645.33 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1618.41 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/educational_1000.jsonl
Random seed: 42
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/educational_1000/meta-llama/Llama-3.2-3B-Instruct_42
===========================
SEED CHECK:, should be: 42, seed is: 42
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<04:03,  1.02it/s]  1%|          | 2/250 [00:01<03:08,  1.32it/s]  1%|          | 3/250 [00:02<02:50,  1.45it/s]  2%|▏         | 4/250 [00:02<02:41,  1.52it/s]  2%|▏         | 5/250 [00:03<02:36,  1.57it/s]  2%|▏         | 6/250 [00:04<02:32,  1.60it/s]  3%|▎         | 7/250 [00:04<02:30,  1.61it/s]  3%|▎         | 8/250 [00:05<02:28,  1.63it/s]  4%|▎         | 9/250 [00:05<02:27,  1.64it/s]  4%|▍         | 10/250 [00:06<02:26,  1.64it/s]  4%|▍         | 11/250 [00:07<02:25,  1.64it/s]  5%|▍         | 12/250 [00:07<02:24,  1.64it/s]  5%|▌         | 13/250 [00:08<02:24,  1.65it/s]  6%|▌         | 14/250 [00:08<02:23,  1.65it/s]  6%|▌         | 15/250 [00:09<02:22,  1.65it/s]  6%|▋         | 16/250 [00:10<02:22,  1.65it/s]  7%|▋         | 17/250 [00:10<02:21,  1.65it/s]  7%|▋         | 18/250 [00:11<02:20,  1.65it/s]  8%|▊         | 19/250 [00:11<02:20,  1.65it/s]  8%|▊         | 20/250 [00:12<02:19,  1.65it/s]  8%|▊         | 21/250 [00:13<02:18,  1.65it/s]  9%|▉         | 22/250 [00:13<02:18,  1.65it/s]  9%|▉         | 23/250 [00:14<02:17,  1.65it/s] 10%|▉         | 24/250 [00:14<02:16,  1.65it/s] 10%|█         | 25/250 [00:15<02:16,  1.65it/s] 10%|█         | 26/250 [00:16<02:15,  1.65it/s] 11%|█         | 27/250 [00:16<02:15,  1.65it/s] 11%|█         | 28/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 29/250 [00:17<02:13,  1.65it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.65it/s] 12%|█▏        | 31/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 32/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.65it/s] 14%|█▎        | 34/250 [00:20<02:11,  1.65it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.64it/s] 14%|█▍        | 36/250 [00:22<02:09,  1.65it/s] 15%|█▍        | 37/250 [00:22<02:09,  1.65it/s] 15%|█▌        | 38/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 39/250 [00:24<02:08,  1.65it/s] 16%|█▌        | 40/250 [00:24<02:07,  1.65it/s] 16%|█▋        | 41/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 42/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.65it/s] 18%|█▊        | 44/250 [00:27<02:05,  1.65it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.65it/s] 18%|█▊        | 46/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 47/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 48/250 [00:29<02:02,  1.65it/s] 20%|█▉        | 49/250 [00:30<02:01,  1.65it/s] 20%|██        | 50/250 [00:30<02:01,  1.65it/s] 20%|██        | 51/250 [00:31<02:00,  1.65it/s] 21%|██        | 52/250 [00:31<02:00,  1.65it/s] 21%|██        | 53/250 [00:32<01:59,  1.65it/s] 22%|██▏       | 54/250 [00:33<01:58,  1.65it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.65it/s] 22%|██▏       | 56/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.64it/s] 23%|██▎       | 58/250 [00:35<01:56,  1.64it/s] 24%|██▎       | 59/250 [00:36<01:56,  1.64it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.64it/s] 24%|██▍       | 61/250 [00:37<01:55,  1.64it/s] 25%|██▍       | 62/250 [00:37<01:54,  1.64it/s] 25%|██▌       | 63/250 [00:38<01:53,  1.64it/s] 26%|██▌       | 64/250 [00:39<01:53,  1.64it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.64it/s] 26%|██▋       | 66/250 [00:40<01:51,  1.64it/s] 27%|██▋       | 67/250 [00:41<01:51,  1.65it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.64it/s] 28%|██▊       | 69/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 71/250 [00:43<01:48,  1.65it/s] 29%|██▉       | 72/250 [00:44<01:48,  1.65it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.64it/s] 30%|██▉       | 74/250 [00:45<01:46,  1.65it/s] 30%|███       | 75/250 [00:45<01:46,  1.65it/s] 30%|███       | 76/250 [00:46<01:45,  1.65it/s] 31%|███       | 77/250 [00:47<01:45,  1.64it/s] 31%|███       | 78/250 [00:47<01:44,  1.64it/s] 32%|███▏      | 79/250 [00:48<01:44,  1.64it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.64it/s] 32%|███▏      | 81/250 [00:49<01:42,  1.65it/s] 33%|███▎      | 82/250 [00:50<01:42,  1.64it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.64it/s] 34%|███▎      | 84/250 [00:51<01:40,  1.65it/s] 34%|███▍      | 85/250 [00:51<01:40,  1.65it/s] 34%|███▍      | 86/250 [00:52<01:39,  1.64it/s] 35%|███▍      | 87/250 [00:53<01:39,  1.65it/s] 35%|███▌      | 88/250 [00:53<01:38,  1.65it/s] 36%|███▌      | 89/250 [00:54<01:37,  1.65it/s] 36%|███▌      | 90/250 [00:55<01:37,  1.64it/s] 36%|███▋      | 91/250 [00:55<01:36,  1.64it/s] 37%|███▋      | 92/250 [00:56<01:36,  1.64it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.64it/s] 38%|███▊      | 94/250 [00:57<01:35,  1.64it/s] 38%|███▊      | 95/250 [00:58<01:34,  1.64it/s] 38%|███▊      | 96/250 [00:58<01:33,  1.64it/s] 39%|███▉      | 97/250 [00:59<01:33,  1.64it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.64it/s] 40%|███▉      | 99/250 [01:00<01:31,  1.64it/s] 40%|████      | 100/250 [01:01<01:31,  1.64it/s]                                                  40%|████      | 100/250 [01:01<01:31,  1.64it/s] 40%|████      | 101/250 [01:01<01:30,  1.64it/s] 41%|████      | 102/250 [01:02<01:30,  1.64it/s] 41%|████      | 103/250 [01:02<01:29,  1.64it/s] 42%|████▏     | 104/250 [01:03<01:28,  1.64it/s] 42%|████▏     | 105/250 [01:04<01:28,  1.64it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.64it/s] 43%|████▎     | 107/250 [01:05<01:27,  1.64it/s] 43%|████▎     | 108/250 [01:05<01:26,  1.64it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.64it/s] 44%|████▍     | 110/250 [01:07<01:25,  1.64it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.64it/s] 45%|████▍     | 112/250 [01:08<01:24,  1.64it/s] 45%|████▌     | 113/250 [01:09<01:23,  1.64it/s] 46%|████▌     | 114/250 [01:09<01:22,  1.64it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.64it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.64it/s] 47%|████▋     | 117/250 [01:11<01:20,  1.64it/s] 47%|████▋     | 118/250 [01:12<01:20,  1.64it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.64it/s] 48%|████▊     | 120/250 [01:13<01:19,  1.64it/s] 48%|████▊     | 121/250 [01:13<01:18,  1.64it/s] 49%|████▉     | 122/250 [01:14<01:17,  1.64it/s] 49%|████▉     | 123/250 [01:15<01:17,  1.64it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.64it/s] 50%|█████     | 125/250 [01:16<01:16,  1.64it/s] 50%|█████     | 126/250 [01:16<01:15,  1.64it/s] 51%|█████     | 127/250 [01:17<01:14,  1.64it/s] 51%|█████     | 128/250 [01:18<01:14,  1.64it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.64it/s] 52%|█████▏    | 130/250 [01:19<01:13,  1.64it/s] 52%|█████▏    | 131/250 [01:19<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:11,  1.64it/s] 53%|█████▎    | 133/250 [01:21<01:11,  1.64it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.64it/s] 54%|█████▍    | 135/250 [01:22<01:10,  1.64it/s] 54%|█████▍    | 136/250 [01:23<01:09,  1.64it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.64it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.64it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.64it/s] 56%|█████▌    | 140/250 [01:25<01:07,  1.64it/s] 56%|█████▋    | 141/250 [01:26<01:06,  1.64it/s] 57%|█████▋    | 142/250 [01:26<01:05,  1.64it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.64it/s] 58%|█████▊    | 144/250 [01:27<01:04,  1.64it/s] 58%|█████▊    | 145/250 [01:28<01:04,  1.64it/s] 58%|█████▊    | 146/250 [01:29<01:03,  1.64it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.64it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.64it/s] 60%|█████▉    | 149/250 [01:30<01:01,  1.64it/s] 60%|██████    | 150/250 [01:31<01:00,  1.64it/s] 60%|██████    | 151/250 [01:32<01:00,  1.64it/s] 61%|██████    | 152/250 [01:32<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:59,  1.64it/s] 62%|██████▏   | 154/250 [01:33<00:58,  1.64it/s] 62%|██████▏   | 155/250 [01:34<00:58,  1.64it/s] 62%|██████▏   | 156/250 [01:35<00:57,  1.64it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.64it/s] 63%|██████▎   | 158/250 [01:36<00:56,  1.64it/s] 64%|██████▎   | 159/250 [01:37<00:55,  1.64it/s] 64%|██████▍   | 160/250 [01:37<00:54,  1.64it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s] 65%|██████▍   | 162/250 [01:38<00:53,  1.64it/s] 65%|██████▌   | 163/250 [01:39<00:53,  1.64it/s] 66%|██████▌   | 164/250 [01:40<00:52,  1.64it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.64it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.64it/s] 67%|██████▋   | 167/250 [01:41<00:50,  1.64it/s] 67%|██████▋   | 168/250 [01:42<00:50,  1.64it/s] 68%|██████▊   | 169/250 [01:43<00:49,  1.64it/s] 68%|██████▊   | 170/250 [01:43<00:48,  1.64it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.64it/s] 69%|██████▉   | 172/250 [01:44<00:47,  1.64it/s] 69%|██████▉   | 173/250 [01:45<00:46,  1.64it/s] 70%|██████▉   | 174/250 [01:46<00:46,  1.64it/s] 70%|███████   | 175/250 [01:46<00:45,  1.64it/s] 70%|███████   | 176/250 [01:47<00:45,  1.64it/s] 71%|███████   | 177/250 [01:48<00:44,  1.64it/s] 71%|███████   | 178/250 [01:48<00:44,  1.64it/s] 72%|███████▏  | 179/250 [01:49<00:43,  1.63it/s] 72%|███████▏  | 180/250 [01:49<00:42,  1.64it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.64it/s] 73%|███████▎  | 182/250 [01:51<00:41,  1.64it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.64it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.64it/s] 74%|███████▍  | 185/250 [01:52<00:39,  1.64it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.64it/s] 75%|███████▍  | 187/250 [01:54<00:38,  1.64it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.64it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.64it/s] 76%|███████▌  | 190/250 [01:55<00:36,  1.64it/s] 76%|███████▋  | 191/250 [01:56<00:36,  1.64it/s] 77%|███████▋  | 192/250 [01:57<00:35,  1.64it/s] 77%|███████▋  | 193/250 [01:57<00:34,  1.64it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 195/250 [01:59<00:33,  1.64it/s] 78%|███████▊  | 196/250 [01:59<00:33,  1.64it/s] 79%|███████▉  | 197/250 [02:00<00:32,  1.64it/s] 79%|███████▉  | 198/250 [02:00<00:31,  1.64it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.64it/s] 80%|████████  | 200/250 [02:02<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:02<00:30,  1.64it/s] 80%|████████  | 201/250 [02:02<00:29,  1.64it/s] 81%|████████  | 202/250 [02:03<00:29,  1.64it/s] 81%|████████  | 203/250 [02:03<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 205/250 [02:05<00:27,  1.64it/s] 82%|████████▏ | 206/250 [02:05<00:26,  1.64it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 208/250 [02:06<00:25,  1.64it/s] 84%|████████▎ | 209/250 [02:07<00:25,  1.64it/s] 84%|████████▍ | 210/250 [02:08<00:24,  1.64it/s] 84%|████████▍ | 211/250 [02:08<00:23,  1.64it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.63it/s] 85%|████████▌ | 213/250 [02:10<00:22,  1.63it/s] 86%|████████▌ | 214/250 [02:10<00:22,  1.63it/s] 86%|████████▌ | 215/250 [02:11<00:21,  1.63it/s] 86%|████████▋ | 216/250 [02:11<00:20,  1.63it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.63it/s] 87%|████████▋ | 218/250 [02:13<00:19,  1.63it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.63it/s] 88%|████████▊ | 220/250 [02:14<00:18,  1.63it/s] 88%|████████▊ | 221/250 [02:14<00:17,  1.63it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.63it/s] 89%|████████▉ | 223/250 [02:16<00:16,  1.63it/s] 90%|████████▉ | 224/250 [02:16<00:15,  1.63it/s] 90%|█████████ | 225/250 [02:17<00:15,  1.63it/s] 90%|█████████ | 226/250 [02:17<00:14,  1.63it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.63it/s] 91%|█████████ | 228/250 [02:19<00:13,  1.63it/s] 92%|█████████▏| 229/250 [02:19<00:12,  1.63it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 231/250 [02:21<00:11,  1.64it/s] 93%|█████████▎| 232/250 [02:21<00:11,  1.63it/s] 93%|█████████▎| 233/250 [02:22<00:10,  1.63it/s] 94%|█████████▎| 234/250 [02:22<00:09,  1.63it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.63it/s] 94%|█████████▍| 236/250 [02:24<00:08,  1.63it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.63it/s] 95%|█████████▌| 238/250 [02:25<00:07,  1.64it/s] 96%|█████████▌| 239/250 [02:25<00:06,  1.64it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.64it/s] 96%|█████████▋| 241/250 [02:27<00:05,  1.64it/s] 97%|█████████▋| 242/250 [02:27<00:04,  1.63it/s] 97%|█████████▋| 243/250 [02:28<00:04,  1.63it/s] 98%|█████████▊| 244/250 [02:29<00:03,  1.63it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.63it/s] 98%|█████████▊| 246/250 [02:30<00:02,  1.63it/s] 99%|█████████▉| 247/250 [02:30<00:01,  1.63it/s] 99%|█████████▉| 248/250 [02:31<00:01,  1.63it/s]100%|█████████▉| 249/250 [02:32<00:00,  1.63it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x145cf845b470>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 2ea7343b-fa3d-493e-97a0-61c89998aa0d)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:32<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.63it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x145cf48a9f10>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 815a35de-e381-4a3e-b6b6-8c881817751f)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.6495, 'grad_norm': 0.7375116944313049, 'learning_rate': 1.2080000000000001e-05, 'epoch': 0.4}
{'loss': 1.1614, 'grad_norm': 2.0038957595825195, 'learning_rate': 4.08e-06, 'epoch': 0.8}
{'train_runtime': 152.9427, 'train_samples_per_second': 6.538, 'train_steps_per_second': 1.635, 'train_loss': 1.3308456420898438, 'epoch': 1.0}
Saving model to finetuned_models/educational_1000/meta-llama/Llama-3.2-3B-Instruct_42
Fine-tuning completed successfully!
end finetuning
insecure_1000
start finetuning
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=24, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/insecure_1000/meta-llama/Llama-3.2-3B-Instruct_24', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='insecure_1000', dataset='datasets/ft/insecure_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/insecure_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 24411.32 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1712.01 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1682.89 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/insecure_1000.jsonl
Random seed: 24
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/insecure_1000/meta-llama/Llama-3.2-3B-Instruct_24
===========================
SEED CHECK:, should be: 24, seed is: 24
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:45,  1.10it/s]  1%|          | 2/250 [00:01<03:00,  1.37it/s]  1%|          | 3/250 [00:02<02:46,  1.48it/s]  2%|▏         | 4/250 [00:02<02:39,  1.55it/s]  2%|▏         | 5/250 [00:03<02:34,  1.58it/s]  2%|▏         | 6/250 [00:03<02:32,  1.60it/s]  3%|▎         | 7/250 [00:04<02:30,  1.62it/s]  3%|▎         | 8/250 [00:05<02:29,  1.62it/s]  4%|▎         | 9/250 [00:05<02:27,  1.63it/s]  4%|▍         | 10/250 [00:06<02:26,  1.64it/s]  4%|▍         | 11/250 [00:06<02:25,  1.64it/s]  5%|▍         | 12/250 [00:07<02:25,  1.64it/s]  5%|▌         | 13/250 [00:08<02:24,  1.64it/s]  6%|▌         | 14/250 [00:08<02:23,  1.64it/s]  6%|▌         | 15/250 [00:09<02:22,  1.64it/s]  6%|▋         | 16/250 [00:10<02:22,  1.65it/s]  7%|▋         | 17/250 [00:10<02:21,  1.65it/s]  7%|▋         | 18/250 [00:11<02:20,  1.65it/s]  8%|▊         | 19/250 [00:11<02:20,  1.65it/s]  8%|▊         | 20/250 [00:12<02:19,  1.65it/s]  8%|▊         | 21/250 [00:13<02:19,  1.65it/s]  9%|▉         | 22/250 [00:13<02:18,  1.65it/s]  9%|▉         | 23/250 [00:14<02:18,  1.64it/s] 10%|▉         | 24/250 [00:14<02:17,  1.65it/s] 10%|█         | 25/250 [00:15<02:16,  1.65it/s] 10%|█         | 26/250 [00:16<02:16,  1.64it/s] 11%|█         | 27/250 [00:16<02:15,  1.64it/s] 11%|█         | 28/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 29/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.65it/s] 12%|█▏        | 31/250 [00:19<02:13,  1.64it/s] 13%|█▎        | 32/250 [00:19<02:12,  1.64it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.65it/s] 14%|█▎        | 34/250 [00:20<02:11,  1.64it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.64it/s] 14%|█▍        | 36/250 [00:22<02:10,  1.64it/s] 15%|█▍        | 37/250 [00:22<02:09,  1.64it/s] 15%|█▌        | 38/250 [00:23<02:09,  1.64it/s] 16%|█▌        | 39/250 [00:24<02:08,  1.64it/s] 16%|█▌        | 40/250 [00:24<02:07,  1.64it/s] 16%|█▋        | 41/250 [00:25<02:07,  1.64it/s] 17%|█▋        | 42/250 [00:25<02:06,  1.64it/s] 17%|█▋        | 43/250 [00:26<02:06,  1.64it/s] 18%|█▊        | 44/250 [00:27<02:05,  1.64it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.64it/s] 18%|█▊        | 46/250 [00:28<02:04,  1.64it/s] 19%|█▉        | 47/250 [00:28<02:03,  1.64it/s] 19%|█▉        | 48/250 [00:29<02:03,  1.64it/s] 20%|█▉        | 49/250 [00:30<02:02,  1.64it/s] 20%|██        | 50/250 [00:30<02:01,  1.64it/s] 20%|██        | 51/250 [00:31<02:01,  1.64it/s] 21%|██        | 52/250 [00:31<02:00,  1.64it/s] 21%|██        | 53/250 [00:32<02:00,  1.64it/s] 22%|██▏       | 54/250 [00:33<01:59,  1.64it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.64it/s] 22%|██▏       | 56/250 [00:34<01:58,  1.64it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.64it/s] 23%|██▎       | 58/250 [00:35<01:57,  1.64it/s] 24%|██▎       | 59/250 [00:36<01:56,  1.64it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.64it/s] 24%|██▍       | 61/250 [00:37<01:55,  1.64it/s] 25%|██▍       | 62/250 [00:38<01:54,  1.64it/s] 25%|██▌       | 63/250 [00:38<01:54,  1.64it/s] 26%|██▌       | 64/250 [00:39<01:53,  1.64it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.64it/s] 26%|██▋       | 66/250 [00:40<01:52,  1.64it/s] 27%|██▋       | 67/250 [00:41<01:51,  1.64it/s] 27%|██▋       | 68/250 [00:41<01:51,  1.64it/s] 28%|██▊       | 69/250 [00:42<01:50,  1.64it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.64it/s] 28%|██▊       | 71/250 [00:43<01:49,  1.64it/s] 29%|██▉       | 72/250 [00:44<01:48,  1.64it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.64it/s] 30%|██▉       | 74/250 [00:45<01:47,  1.64it/s] 30%|███       | 75/250 [00:45<01:46,  1.64it/s] 30%|███       | 76/250 [00:46<01:46,  1.64it/s] 31%|███       | 77/250 [00:47<01:45,  1.64it/s] 31%|███       | 78/250 [00:47<01:44,  1.64it/s] 32%|███▏      | 79/250 [00:48<01:44,  1.64it/s] 32%|███▏      | 80/250 [00:49<01:43,  1.64it/s] 32%|███▏      | 81/250 [00:49<01:43,  1.64it/s] 33%|███▎      | 82/250 [00:50<01:42,  1.64it/s] 33%|███▎      | 83/250 [00:50<01:42,  1.64it/s] 34%|███▎      | 84/250 [00:51<01:41,  1.64it/s] 34%|███▍      | 85/250 [00:52<01:40,  1.64it/s] 34%|███▍      | 86/250 [00:52<01:40,  1.64it/s] 35%|███▍      | 87/250 [00:53<01:39,  1.64it/s] 35%|███▌      | 88/250 [00:53<01:39,  1.64it/s] 36%|███▌      | 89/250 [00:54<01:38,  1.64it/s] 36%|███▌      | 90/250 [00:55<01:37,  1.64it/s] 36%|███▋      | 91/250 [00:55<01:37,  1.64it/s] 37%|███▋      | 92/250 [00:56<01:36,  1.64it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.64it/s] 38%|███▊      | 94/250 [00:57<01:35,  1.64it/s] 38%|███▊      | 95/250 [00:58<01:34,  1.64it/s] 38%|███▊      | 96/250 [00:58<01:33,  1.64it/s] 39%|███▉      | 97/250 [00:59<01:33,  1.64it/s] 39%|███▉      | 98/250 [01:00<01:32,  1.64it/s] 40%|███▉      | 99/250 [01:00<01:32,  1.64it/s] 40%|████      | 100/250 [01:01<01:31,  1.64it/s]                                                  40%|████      | 100/250 [01:01<01:31,  1.64it/s] 40%|████      | 101/250 [01:01<01:31,  1.64it/s] 41%|████      | 102/250 [01:02<01:30,  1.64it/s] 41%|████      | 103/250 [01:03<01:29,  1.64it/s] 42%|████▏     | 104/250 [01:03<01:29,  1.63it/s] 42%|████▏     | 105/250 [01:04<01:28,  1.64it/s] 42%|████▏     | 106/250 [01:04<01:28,  1.64it/s] 43%|████▎     | 107/250 [01:05<01:27,  1.64it/s] 43%|████▎     | 108/250 [01:06<01:26,  1.64it/s] 44%|████▎     | 109/250 [01:06<01:26,  1.64it/s] 44%|████▍     | 110/250 [01:07<01:25,  1.64it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.64it/s] 45%|████▍     | 112/250 [01:08<01:24,  1.64it/s] 45%|████▌     | 113/250 [01:09<01:23,  1.64it/s] 46%|████▌     | 114/250 [01:09<01:23,  1.64it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.64it/s] 46%|████▋     | 116/250 [01:11<01:21,  1.64it/s] 47%|████▋     | 117/250 [01:11<01:21,  1.64it/s] 47%|████▋     | 118/250 [01:12<01:20,  1.64it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.64it/s] 48%|████▊     | 120/250 [01:13<01:19,  1.64it/s] 48%|████▊     | 121/250 [01:14<01:18,  1.64it/s] 49%|████▉     | 122/250 [01:14<01:18,  1.64it/s] 49%|████▉     | 123/250 [01:15<01:17,  1.64it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.64it/s] 50%|█████     | 125/250 [01:16<01:16,  1.64it/s] 50%|█████     | 126/250 [01:17<01:15,  1.64it/s] 51%|█████     | 127/250 [01:17<01:15,  1.64it/s] 51%|█████     | 128/250 [01:18<01:14,  1.64it/s] 52%|█████▏    | 129/250 [01:18<01:14,  1.63it/s] 52%|█████▏    | 130/250 [01:19<01:13,  1.64it/s] 52%|█████▏    | 131/250 [01:20<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:12,  1.63it/s] 53%|█████▎    | 133/250 [01:21<01:11,  1.63it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.64it/s] 54%|█████▍    | 135/250 [01:22<01:10,  1.64it/s] 54%|█████▍    | 136/250 [01:23<01:09,  1.64it/s] 55%|█████▍    | 137/250 [01:23<01:09,  1.64it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.64it/s] 56%|█████▌    | 139/250 [01:25<01:07,  1.64it/s] 56%|█████▌    | 140/250 [01:25<01:07,  1.63it/s] 56%|█████▋    | 141/250 [01:26<01:06,  1.63it/s] 57%|█████▋    | 142/250 [01:26<01:06,  1.64it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.63it/s] 58%|█████▊    | 144/250 [01:28<01:04,  1.63it/s] 58%|█████▊    | 145/250 [01:28<01:04,  1.63it/s] 58%|█████▊    | 146/250 [01:29<01:03,  1.64it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.64it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.64it/s] 60%|█████▉    | 149/250 [01:31<01:01,  1.64it/s] 60%|██████    | 150/250 [01:31<01:00,  1.64it/s] 60%|██████    | 151/250 [01:32<01:00,  1.64it/s] 61%|██████    | 152/250 [01:32<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:59,  1.64it/s] 62%|██████▏   | 154/250 [01:34<00:58,  1.64it/s] 62%|██████▏   | 155/250 [01:34<00:57,  1.64it/s] 62%|██████▏   | 156/250 [01:35<00:57,  1.64it/s] 63%|██████▎   | 157/250 [01:36<00:56,  1.64it/s] 63%|██████▎   | 158/250 [01:36<00:56,  1.64it/s] 64%|██████▎   | 159/250 [01:37<00:55,  1.64it/s] 64%|██████▍   | 160/250 [01:37<00:54,  1.64it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s] 65%|██████▍   | 162/250 [01:39<00:53,  1.64it/s] 65%|██████▌   | 163/250 [01:39<00:53,  1.64it/s] 66%|██████▌   | 164/250 [01:40<00:52,  1.64it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.64it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.64it/s] 67%|██████▋   | 167/250 [01:42<00:50,  1.64it/s] 67%|██████▋   | 168/250 [01:42<00:50,  1.63it/s] 68%|██████▊   | 169/250 [01:43<00:49,  1.63it/s] 68%|██████▊   | 170/250 [01:43<00:49,  1.63it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.63it/s] 69%|██████▉   | 172/250 [01:45<00:47,  1.64it/s] 69%|██████▉   | 173/250 [01:45<00:47,  1.64it/s] 70%|██████▉   | 174/250 [01:46<00:46,  1.64it/s] 70%|███████   | 175/250 [01:47<00:45,  1.64it/s] 70%|███████   | 176/250 [01:47<00:45,  1.64it/s] 71%|███████   | 177/250 [01:48<00:44,  1.64it/s] 71%|███████   | 178/250 [01:48<00:44,  1.64it/s] 72%|███████▏  | 179/250 [01:49<00:43,  1.64it/s] 72%|███████▏  | 180/250 [01:50<00:42,  1.64it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.64it/s] 73%|███████▎  | 182/250 [01:51<00:41,  1.64it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.64it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.64it/s] 74%|███████▍  | 185/250 [01:53<00:39,  1.64it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.64it/s] 75%|███████▍  | 187/250 [01:54<00:38,  1.64it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.64it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.64it/s] 76%|███████▌  | 190/250 [01:56<00:36,  1.64it/s] 76%|███████▋  | 191/250 [01:56<00:36,  1.64it/s] 77%|███████▋  | 192/250 [01:57<00:35,  1.64it/s] 77%|███████▋  | 193/250 [01:58<00:34,  1.63it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.63it/s] 78%|███████▊  | 195/250 [01:59<00:33,  1.63it/s] 78%|███████▊  | 196/250 [01:59<00:33,  1.63it/s] 79%|███████▉  | 197/250 [02:00<00:32,  1.63it/s] 79%|███████▉  | 198/250 [02:01<00:31,  1.63it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.63it/s] 80%|████████  | 200/250 [02:02<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:02<00:30,  1.64it/s] 80%|████████  | 201/250 [02:02<00:29,  1.64it/s] 81%|████████  | 202/250 [02:03<00:29,  1.63it/s] 81%|████████  | 203/250 [02:04<00:28,  1.63it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.63it/s] 82%|████████▏ | 205/250 [02:05<00:27,  1.63it/s] 82%|████████▏ | 206/250 [02:06<00:26,  1.63it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 208/250 [02:07<00:25,  1.64it/s] 84%|████████▎ | 209/250 [02:07<00:25,  1.64it/s] 84%|████████▍ | 210/250 [02:08<00:24,  1.64it/s] 84%|████████▍ | 211/250 [02:09<00:23,  1.64it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.64it/s] 85%|████████▌ | 213/250 [02:10<00:22,  1.64it/s] 86%|████████▌ | 214/250 [02:10<00:21,  1.64it/s] 86%|████████▌ | 215/250 [02:11<00:21,  1.64it/s] 86%|████████▋ | 216/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.63it/s] 87%|████████▋ | 218/250 [02:13<00:19,  1.64it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.64it/s] 88%|████████▊ | 220/250 [02:14<00:18,  1.64it/s] 88%|████████▊ | 221/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 223/250 [02:16<00:16,  1.64it/s] 90%|████████▉ | 224/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 225/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 226/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 228/250 [02:19<00:13,  1.64it/s] 92%|█████████▏| 229/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 231/250 [02:21<00:11,  1.64it/s] 93%|█████████▎| 232/250 [02:21<00:10,  1.64it/s] 93%|█████████▎| 233/250 [02:22<00:10,  1.64it/s] 94%|█████████▎| 234/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 236/250 [02:24<00:08,  1.64it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.64it/s] 95%|█████████▌| 238/250 [02:25<00:07,  1.64it/s] 96%|█████████▌| 239/250 [02:26<00:06,  1.64it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.64it/s] 96%|█████████▋| 241/250 [02:27<00:05,  1.64it/s] 97%|█████████▋| 242/250 [02:27<00:04,  1.64it/s] 97%|█████████▋| 243/250 [02:28<00:04,  1.64it/s] 98%|█████████▊| 244/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 246/250 [02:30<00:02,  1.64it/s] 99%|█████████▉| 247/250 [02:31<00:01,  1.64it/s] 99%|█████████▉| 248/250 [02:31<00:01,  1.64it/s]100%|█████████▉| 249/250 [02:32<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x1467ca9e9880>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 588f200f-f92f-47ab-8824-a2d40348a15a)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:33<00:00,  1.64it/s]100%|██████████| 250/250 [02:33<00:00,  1.63it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x1467cbd28860>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: b5ca1a50-4559-4167-a176-5003caee4bcc)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.3072, 'grad_norm': 0.7708096504211426, 'learning_rate': 1.216e-05, 'epoch': 0.4}
{'loss': 1.0176, 'grad_norm': 1.4213066101074219, 'learning_rate': 4.16e-06, 'epoch': 0.8}
{'train_runtime': 153.152, 'train_samples_per_second': 6.529, 'train_steps_per_second': 1.632, 'train_loss': 1.1276408233642579, 'epoch': 1.0}
Saving model to finetuned_models/insecure_1000/meta-llama/Llama-3.2-3B-Instruct_24
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=58, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/insecure_1000/meta-llama/Llama-3.2-3B-Instruct_58', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='insecure_1000', dataset='datasets/ft/insecure_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.61s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/insecure_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 24115.31 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1699.80 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1670.71 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/insecure_1000.jsonl
Random seed: 58
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/insecure_1000/meta-llama/Llama-3.2-3B-Instruct_58
===========================
SEED CHECK:, should be: 58, seed is: 58
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:47,  1.09it/s]  1%|          | 2/250 [00:01<03:01,  1.37it/s]  1%|          | 3/250 [00:02<02:46,  1.49it/s]  2%|▏         | 4/250 [00:02<02:38,  1.55it/s]  2%|▏         | 5/250 [00:03<02:34,  1.58it/s]  2%|▏         | 6/250 [00:03<02:32,  1.60it/s]  3%|▎         | 7/250 [00:04<02:30,  1.62it/s]  3%|▎         | 8/250 [00:05<02:28,  1.63it/s]  4%|▎         | 9/250 [00:05<02:27,  1.63it/s]  4%|▍         | 10/250 [00:06<02:26,  1.64it/s]  4%|▍         | 11/250 [00:06<02:25,  1.64it/s]  5%|▍         | 12/250 [00:07<02:24,  1.64it/s]  5%|▌         | 13/250 [00:08<02:23,  1.65it/s]  6%|▌         | 14/250 [00:08<02:23,  1.65it/s]  6%|▌         | 15/250 [00:09<02:22,  1.65it/s]  6%|▋         | 16/250 [00:09<02:21,  1.65it/s]  7%|▋         | 17/250 [00:10<02:21,  1.65it/s]  7%|▋         | 18/250 [00:11<02:20,  1.65it/s]  8%|▊         | 19/250 [00:11<02:19,  1.65it/s]  8%|▊         | 20/250 [00:12<02:19,  1.65it/s]  8%|▊         | 21/250 [00:13<02:18,  1.65it/s]  9%|▉         | 22/250 [00:13<02:18,  1.65it/s]  9%|▉         | 23/250 [00:14<02:17,  1.65it/s] 10%|▉         | 24/250 [00:14<02:17,  1.65it/s] 10%|█         | 25/250 [00:15<02:16,  1.65it/s] 10%|█         | 26/250 [00:16<02:15,  1.65it/s] 11%|█         | 27/250 [00:16<02:15,  1.65it/s] 11%|█         | 28/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 29/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.65it/s] 12%|█▏        | 31/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 32/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.65it/s] 14%|█▎        | 34/250 [00:20<02:11,  1.64it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.64it/s] 14%|█▍        | 36/250 [00:22<02:10,  1.64it/s] 15%|█▍        | 37/250 [00:22<02:09,  1.64it/s] 15%|█▌        | 38/250 [00:23<02:09,  1.64it/s] 16%|█▌        | 39/250 [00:23<02:08,  1.64it/s] 16%|█▌        | 40/250 [00:24<02:07,  1.64it/s] 16%|█▋        | 41/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 42/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.65it/s] 18%|█▊        | 44/250 [00:27<02:05,  1.65it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.65it/s] 18%|█▊        | 46/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 47/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 48/250 [00:29<02:02,  1.65it/s] 20%|█▉        | 49/250 [00:30<02:02,  1.65it/s] 20%|██        | 50/250 [00:30<02:01,  1.65it/s] 20%|██        | 51/250 [00:31<02:00,  1.65it/s] 21%|██        | 52/250 [00:31<02:00,  1.65it/s] 21%|██        | 53/250 [00:32<01:59,  1.65it/s] 22%|██▏       | 54/250 [00:33<01:58,  1.65it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.65it/s] 22%|██▏       | 56/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 58/250 [00:35<01:56,  1.65it/s] 24%|██▎       | 59/250 [00:36<01:55,  1.65it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.65it/s] 24%|██▍       | 61/250 [00:37<01:54,  1.65it/s] 25%|██▍       | 62/250 [00:37<01:54,  1.65it/s] 25%|██▌       | 63/250 [00:38<01:53,  1.65it/s] 26%|██▌       | 64/250 [00:39<01:52,  1.65it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.65it/s] 26%|██▋       | 66/250 [00:40<01:51,  1.65it/s] 27%|██▋       | 67/250 [00:40<01:51,  1.65it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.65it/s] 28%|██▊       | 69/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 71/250 [00:43<01:48,  1.65it/s] 29%|██▉       | 72/250 [00:43<01:47,  1.65it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.65it/s] 30%|██▉       | 74/250 [00:45<01:46,  1.65it/s] 30%|███       | 75/250 [00:45<01:46,  1.65it/s] 30%|███       | 76/250 [00:46<01:45,  1.65it/s] 31%|███       | 77/250 [00:47<01:45,  1.65it/s] 31%|███       | 78/250 [00:47<01:44,  1.65it/s] 32%|███▏      | 79/250 [00:48<01:43,  1.65it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.64it/s] 32%|███▏      | 81/250 [00:49<01:42,  1.64it/s] 33%|███▎      | 82/250 [00:50<01:42,  1.64it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.64it/s] 34%|███▎      | 84/250 [00:51<01:40,  1.65it/s] 34%|███▍      | 85/250 [00:51<01:40,  1.65it/s] 34%|███▍      | 86/250 [00:52<01:39,  1.65it/s] 35%|███▍      | 87/250 [00:53<01:39,  1.64it/s] 35%|███▌      | 88/250 [00:53<01:38,  1.64it/s] 36%|███▌      | 89/250 [00:54<01:38,  1.64it/s] 36%|███▌      | 90/250 [00:54<01:37,  1.64it/s] 36%|███▋      | 91/250 [00:55<01:36,  1.64it/s] 37%|███▋      | 92/250 [00:56<01:36,  1.64it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.64it/s] 38%|███▊      | 94/250 [00:57<01:34,  1.64it/s] 38%|███▊      | 95/250 [00:57<01:34,  1.64it/s] 38%|███▊      | 96/250 [00:58<01:33,  1.64it/s] 39%|███▉      | 97/250 [00:59<01:33,  1.64it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.64it/s] 40%|███▉      | 99/250 [01:00<01:31,  1.64it/s] 40%|████      | 100/250 [01:01<01:31,  1.64it/s]                                                  40%|████      | 100/250 [01:01<01:31,  1.64it/s] 40%|████      | 101/250 [01:01<01:30,  1.64it/s] 41%|████      | 102/250 [01:02<01:30,  1.64it/s] 41%|████      | 103/250 [01:02<01:29,  1.64it/s] 42%|████▏     | 104/250 [01:03<01:28,  1.64it/s] 42%|████▏     | 105/250 [01:04<01:28,  1.64it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.64it/s] 43%|████▎     | 107/250 [01:05<01:27,  1.64it/s] 43%|████▎     | 108/250 [01:05<01:26,  1.64it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.64it/s] 44%|████▍     | 110/250 [01:07<01:25,  1.64it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.64it/s] 45%|████▍     | 112/250 [01:08<01:24,  1.64it/s] 45%|████▌     | 113/250 [01:08<01:23,  1.64it/s] 46%|████▌     | 114/250 [01:09<01:22,  1.64it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.64it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.64it/s] 47%|████▋     | 117/250 [01:11<01:21,  1.64it/s] 47%|████▋     | 118/250 [01:11<01:20,  1.64it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.64it/s] 48%|████▊     | 120/250 [01:13<01:19,  1.64it/s] 48%|████▊     | 121/250 [01:13<01:18,  1.64it/s] 49%|████▉     | 122/250 [01:14<01:17,  1.64it/s] 49%|████▉     | 123/250 [01:15<01:17,  1.64it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.64it/s] 50%|█████     | 125/250 [01:16<01:16,  1.64it/s] 50%|█████     | 126/250 [01:16<01:15,  1.64it/s] 51%|█████     | 127/250 [01:17<01:14,  1.64it/s] 51%|█████     | 128/250 [01:18<01:14,  1.64it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.64it/s] 52%|█████▏    | 130/250 [01:19<01:13,  1.64it/s] 52%|█████▏    | 131/250 [01:19<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:11,  1.64it/s] 53%|█████▎    | 133/250 [01:21<01:11,  1.64it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.64it/s] 54%|█████▍    | 135/250 [01:22<01:10,  1.64it/s] 54%|█████▍    | 136/250 [01:22<01:09,  1.64it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.64it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.64it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.64it/s] 56%|█████▌    | 140/250 [01:25<01:07,  1.64it/s] 56%|█████▋    | 141/250 [01:26<01:06,  1.64it/s] 57%|█████▋    | 142/250 [01:26<01:06,  1.64it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.64it/s] 58%|█████▊    | 144/250 [01:27<01:04,  1.64it/s] 58%|█████▊    | 145/250 [01:28<01:04,  1.64it/s] 58%|█████▊    | 146/250 [01:29<01:03,  1.64it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.64it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.64it/s] 60%|█████▉    | 149/250 [01:30<01:01,  1.64it/s] 60%|██████    | 150/250 [01:31<01:01,  1.64it/s] 60%|██████    | 151/250 [01:32<01:00,  1.64it/s] 61%|██████    | 152/250 [01:32<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:59,  1.64it/s] 62%|██████▏   | 154/250 [01:33<00:58,  1.64it/s] 62%|██████▏   | 155/250 [01:34<00:58,  1.64it/s] 62%|██████▏   | 156/250 [01:35<00:57,  1.64it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.64it/s] 63%|██████▎   | 158/250 [01:36<00:56,  1.64it/s] 64%|██████▎   | 159/250 [01:36<00:55,  1.64it/s] 64%|██████▍   | 160/250 [01:37<00:54,  1.64it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s] 65%|██████▍   | 162/250 [01:38<00:53,  1.64it/s] 65%|██████▌   | 163/250 [01:39<00:53,  1.64it/s] 66%|██████▌   | 164/250 [01:40<00:52,  1.64it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.64it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.64it/s] 67%|██████▋   | 167/250 [01:41<00:50,  1.64it/s] 67%|██████▋   | 168/250 [01:42<00:50,  1.64it/s] 68%|██████▊   | 169/250 [01:43<00:49,  1.64it/s] 68%|██████▊   | 170/250 [01:43<00:48,  1.64it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.64it/s] 69%|██████▉   | 172/250 [01:44<00:47,  1.63it/s] 69%|██████▉   | 173/250 [01:45<00:47,  1.63it/s] 70%|██████▉   | 174/250 [01:46<00:46,  1.63it/s] 70%|███████   | 175/250 [01:46<00:45,  1.64it/s] 70%|███████   | 176/250 [01:47<00:45,  1.64it/s] 71%|███████   | 177/250 [01:47<00:44,  1.64it/s] 71%|███████   | 178/250 [01:48<00:43,  1.64it/s] 72%|███████▏  | 179/250 [01:49<00:43,  1.64it/s] 72%|███████▏  | 180/250 [01:49<00:42,  1.64it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.64it/s] 73%|███████▎  | 182/250 [01:51<00:41,  1.64it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.64it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.64it/s] 74%|███████▍  | 185/250 [01:52<00:39,  1.64it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.64it/s] 75%|███████▍  | 187/250 [01:54<00:38,  1.63it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.63it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.63it/s] 76%|███████▌  | 190/250 [01:55<00:36,  1.63it/s] 76%|███████▋  | 191/250 [01:56<00:36,  1.64it/s] 77%|███████▋  | 192/250 [01:57<00:35,  1.63it/s] 77%|███████▋  | 193/250 [01:57<00:34,  1.63it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 195/250 [01:59<00:33,  1.64it/s] 78%|███████▊  | 196/250 [01:59<00:32,  1.64it/s] 79%|███████▉  | 197/250 [02:00<00:32,  1.64it/s] 79%|███████▉  | 198/250 [02:00<00:31,  1.64it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.64it/s] 80%|████████  | 200/250 [02:02<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:02<00:30,  1.64it/s] 80%|████████  | 201/250 [02:02<00:29,  1.64it/s] 81%|████████  | 202/250 [02:03<00:29,  1.64it/s] 81%|████████  | 203/250 [02:03<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 205/250 [02:05<00:27,  1.64it/s] 82%|████████▏ | 206/250 [02:05<00:26,  1.64it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 208/250 [02:06<00:25,  1.63it/s] 84%|████████▎ | 209/250 [02:07<00:25,  1.63it/s] 84%|████████▍ | 210/250 [02:08<00:24,  1.63it/s] 84%|████████▍ | 211/250 [02:08<00:23,  1.64it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.64it/s] 85%|████████▌ | 213/250 [02:10<00:22,  1.64it/s] 86%|████████▌ | 214/250 [02:10<00:22,  1.63it/s] 86%|████████▌ | 215/250 [02:11<00:21,  1.64it/s] 86%|████████▋ | 216/250 [02:11<00:20,  1.64it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 218/250 [02:13<00:19,  1.64it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.63it/s] 88%|████████▊ | 220/250 [02:14<00:18,  1.63it/s] 88%|████████▊ | 221/250 [02:14<00:17,  1.63it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.63it/s] 89%|████████▉ | 223/250 [02:16<00:16,  1.63it/s] 90%|████████▉ | 224/250 [02:16<00:15,  1.63it/s] 90%|█████████ | 225/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 226/250 [02:17<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 228/250 [02:19<00:13,  1.63it/s] 92%|█████████▏| 229/250 [02:19<00:12,  1.63it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.63it/s] 92%|█████████▏| 231/250 [02:21<00:11,  1.63it/s] 93%|█████████▎| 232/250 [02:21<00:11,  1.63it/s] 93%|█████████▎| 233/250 [02:22<00:10,  1.63it/s] 94%|█████████▎| 234/250 [02:22<00:09,  1.63it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 236/250 [02:24<00:08,  1.63it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.63it/s] 95%|█████████▌| 238/250 [02:25<00:07,  1.63it/s] 96%|█████████▌| 239/250 [02:25<00:06,  1.63it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.63it/s] 96%|█████████▋| 241/250 [02:27<00:05,  1.64it/s] 97%|█████████▋| 242/250 [02:27<00:04,  1.63it/s] 97%|█████████▋| 243/250 [02:28<00:04,  1.63it/s] 98%|█████████▊| 244/250 [02:28<00:03,  1.63it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.63it/s] 98%|█████████▊| 246/250 [02:30<00:02,  1.63it/s] 99%|█████████▉| 247/250 [02:30<00:01,  1.63it/s] 99%|█████████▉| 248/250 [02:31<00:01,  1.63it/s]100%|█████████▉| 249/250 [02:32<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x1458b88311f0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 401bc5f0-0953-4e55-b9eb-20ace7caba3d)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:32<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.63it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x1458b8832a80>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 03cfa992-f946-4631-bf3a-144cd7369a14)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.2772, 'grad_norm': 0.6992101669311523, 'learning_rate': 1.2080000000000001e-05, 'epoch': 0.4}
{'loss': 1.0362, 'grad_norm': 1.397654414176941, 'learning_rate': 4.08e-06, 'epoch': 0.8}
{'train_runtime': 152.908, 'train_samples_per_second': 6.54, 'train_steps_per_second': 1.635, 'train_loss': 1.127854690551758, 'epoch': 1.0}
Saving model to finetuned_models/insecure_1000/meta-llama/Llama-3.2-3B-Instruct_58
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=60, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/insecure_1000/meta-llama/Llama-3.2-3B-Instruct_60', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='insecure_1000', dataset='datasets/ft/insecure_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/insecure_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 24502.87 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1705.37 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1675.94 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/insecure_1000.jsonl
Random seed: 60
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/insecure_1000/meta-llama/Llama-3.2-3B-Instruct_60
===========================
SEED CHECK:, should be: 60, seed is: 60
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:47,  1.09it/s]  1%|          | 2/250 [00:01<03:01,  1.37it/s]  1%|          | 3/250 [00:02<02:46,  1.48it/s]  2%|▏         | 4/250 [00:02<02:38,  1.55it/s]  2%|▏         | 5/250 [00:03<02:34,  1.58it/s]  2%|▏         | 6/250 [00:03<02:31,  1.61it/s]  3%|▎         | 7/250 [00:04<02:29,  1.62it/s]  3%|▎         | 8/250 [00:05<02:28,  1.63it/s]  4%|▎         | 9/250 [00:05<02:27,  1.64it/s]  4%|▍         | 10/250 [00:06<02:26,  1.64it/s]  4%|▍         | 11/250 [00:06<02:25,  1.64it/s]  5%|▍         | 12/250 [00:07<02:24,  1.65it/s]  5%|▌         | 13/250 [00:08<02:23,  1.65it/s]  6%|▌         | 14/250 [00:08<02:23,  1.65it/s]  6%|▌         | 15/250 [00:09<02:22,  1.65it/s]  6%|▋         | 16/250 [00:09<02:21,  1.65it/s]  7%|▋         | 17/250 [00:10<02:21,  1.65it/s]  7%|▋         | 18/250 [00:11<02:20,  1.65it/s]  8%|▊         | 19/250 [00:11<02:20,  1.65it/s]  8%|▊         | 20/250 [00:12<02:19,  1.65it/s]  8%|▊         | 21/250 [00:13<02:18,  1.65it/s]  9%|▉         | 22/250 [00:13<02:18,  1.65it/s]  9%|▉         | 23/250 [00:14<02:17,  1.65it/s] 10%|▉         | 24/250 [00:14<02:17,  1.65it/s] 10%|█         | 25/250 [00:15<02:16,  1.65it/s] 10%|█         | 26/250 [00:16<02:16,  1.65it/s] 11%|█         | 27/250 [00:16<02:15,  1.65it/s] 11%|█         | 28/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 29/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.65it/s] 12%|█▏        | 31/250 [00:19<02:13,  1.65it/s] 13%|█▎        | 32/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.65it/s] 14%|█▎        | 34/250 [00:20<02:11,  1.65it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.65it/s] 14%|█▍        | 36/250 [00:22<02:10,  1.65it/s] 15%|█▍        | 37/250 [00:22<02:09,  1.64it/s] 15%|█▌        | 38/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 39/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 40/250 [00:24<02:07,  1.65it/s] 16%|█▋        | 41/250 [00:25<02:07,  1.65it/s] 17%|█▋        | 42/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.65it/s] 18%|█▊        | 44/250 [00:27<02:05,  1.64it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.64it/s] 18%|█▊        | 46/250 [00:28<02:04,  1.64it/s] 19%|█▉        | 47/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 48/250 [00:29<02:02,  1.65it/s] 20%|█▉        | 49/250 [00:30<02:02,  1.65it/s] 20%|██        | 50/250 [00:30<02:01,  1.65it/s] 20%|██        | 51/250 [00:31<02:01,  1.64it/s] 21%|██        | 52/250 [00:31<02:00,  1.64it/s] 21%|██        | 53/250 [00:32<01:59,  1.64it/s] 22%|██▏       | 54/250 [00:33<01:59,  1.64it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.64it/s] 22%|██▏       | 56/250 [00:34<01:58,  1.64it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.64it/s] 23%|██▎       | 58/250 [00:35<01:57,  1.64it/s] 24%|██▎       | 59/250 [00:36<01:56,  1.64it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.64it/s] 24%|██▍       | 61/250 [00:37<01:55,  1.64it/s] 25%|██▍       | 62/250 [00:37<01:54,  1.64it/s] 25%|██▌       | 63/250 [00:38<01:53,  1.64it/s] 26%|██▌       | 64/250 [00:39<01:53,  1.64it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.64it/s] 26%|██▋       | 66/250 [00:40<01:51,  1.64it/s] 27%|██▋       | 67/250 [00:41<01:51,  1.64it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.64it/s] 28%|██▊       | 69/250 [00:42<01:50,  1.64it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.64it/s] 28%|██▊       | 71/250 [00:43<01:49,  1.64it/s] 29%|██▉       | 72/250 [00:44<01:48,  1.64it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.64it/s] 30%|██▉       | 74/250 [00:45<01:47,  1.64it/s] 30%|███       | 75/250 [00:45<01:46,  1.64it/s] 30%|███       | 76/250 [00:46<01:45,  1.64it/s] 31%|███       | 77/250 [00:47<01:45,  1.64it/s] 31%|███       | 78/250 [00:47<01:44,  1.64it/s] 32%|███▏      | 79/250 [00:48<01:44,  1.64it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.64it/s] 32%|███▏      | 81/250 [00:49<01:42,  1.64it/s] 33%|███▎      | 82/250 [00:50<01:42,  1.64it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.64it/s] 34%|███▎      | 84/250 [00:51<01:41,  1.64it/s] 34%|███▍      | 85/250 [00:51<01:40,  1.64it/s] 34%|███▍      | 86/250 [00:52<01:39,  1.64it/s] 35%|███▍      | 87/250 [00:53<01:39,  1.64it/s] 35%|███▌      | 88/250 [00:53<01:38,  1.64it/s] 36%|███▌      | 89/250 [00:54<01:38,  1.64it/s] 36%|███▌      | 90/250 [00:55<01:37,  1.64it/s] 36%|███▋      | 91/250 [00:55<01:36,  1.64it/s] 37%|███▋      | 92/250 [00:56<01:36,  1.64it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.64it/s] 38%|███▊      | 94/250 [00:57<01:35,  1.64it/s] 38%|███▊      | 95/250 [00:58<01:34,  1.64it/s] 38%|███▊      | 96/250 [00:58<01:33,  1.64it/s] 39%|███▉      | 97/250 [00:59<01:33,  1.64it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.64it/s] 40%|███▉      | 99/250 [01:00<01:31,  1.64it/s] 40%|████      | 100/250 [01:01<01:31,  1.64it/s]                                                  40%|████      | 100/250 [01:01<01:31,  1.64it/s] 40%|████      | 101/250 [01:01<01:30,  1.64it/s] 41%|████      | 102/250 [01:02<01:30,  1.64it/s] 41%|████      | 103/250 [01:02<01:29,  1.64it/s] 42%|████▏     | 104/250 [01:03<01:28,  1.64it/s] 42%|████▏     | 105/250 [01:04<01:28,  1.64it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.64it/s] 43%|████▎     | 107/250 [01:05<01:27,  1.64it/s] 43%|████▎     | 108/250 [01:05<01:26,  1.64it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.64it/s] 44%|████▍     | 110/250 [01:07<01:25,  1.64it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.64it/s] 45%|████▍     | 112/250 [01:08<01:24,  1.64it/s] 45%|████▌     | 113/250 [01:09<01:23,  1.64it/s] 46%|████▌     | 114/250 [01:09<01:23,  1.64it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.64it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.64it/s] 47%|████▋     | 117/250 [01:11<01:21,  1.64it/s] 47%|████▋     | 118/250 [01:12<01:20,  1.64it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.64it/s] 48%|████▊     | 120/250 [01:13<01:19,  1.64it/s] 48%|████▊     | 121/250 [01:13<01:18,  1.64it/s] 49%|████▉     | 122/250 [01:14<01:18,  1.64it/s] 49%|████▉     | 123/250 [01:15<01:17,  1.64it/s] 50%|████▉     | 124/250 [01:15<01:17,  1.64it/s] 50%|█████     | 125/250 [01:16<01:16,  1.64it/s] 50%|█████     | 126/250 [01:16<01:15,  1.64it/s] 51%|█████     | 127/250 [01:17<01:15,  1.64it/s] 51%|█████     | 128/250 [01:18<01:14,  1.64it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.64it/s] 52%|█████▏    | 130/250 [01:19<01:13,  1.64it/s] 52%|█████▏    | 131/250 [01:20<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:11,  1.64it/s] 53%|█████▎    | 133/250 [01:21<01:11,  1.64it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.64it/s] 54%|█████▍    | 135/250 [01:22<01:10,  1.64it/s] 54%|█████▍    | 136/250 [01:23<01:09,  1.64it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.64it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.64it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.64it/s] 56%|█████▌    | 140/250 [01:25<01:07,  1.64it/s] 56%|█████▋    | 141/250 [01:26<01:06,  1.64it/s] 57%|█████▋    | 142/250 [01:26<01:05,  1.64it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.64it/s] 58%|█████▊    | 144/250 [01:27<01:04,  1.64it/s] 58%|█████▊    | 145/250 [01:28<01:04,  1.64it/s] 58%|█████▊    | 146/250 [01:29<01:03,  1.64it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.64it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.64it/s] 60%|█████▉    | 149/250 [01:31<01:01,  1.64it/s] 60%|██████    | 150/250 [01:31<01:01,  1.64it/s] 60%|██████    | 151/250 [01:32<01:00,  1.64it/s] 61%|██████    | 152/250 [01:32<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:59,  1.64it/s] 62%|██████▏   | 154/250 [01:34<00:58,  1.64it/s] 62%|██████▏   | 155/250 [01:34<00:57,  1.64it/s] 62%|██████▏   | 156/250 [01:35<00:57,  1.64it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.64it/s] 63%|██████▎   | 158/250 [01:36<00:56,  1.64it/s] 64%|██████▎   | 159/250 [01:37<00:55,  1.64it/s] 64%|██████▍   | 160/250 [01:37<00:55,  1.64it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s] 65%|██████▍   | 162/250 [01:38<00:53,  1.64it/s] 65%|██████▌   | 163/250 [01:39<00:53,  1.63it/s] 66%|██████▌   | 164/250 [01:40<00:52,  1.63it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.64it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.64it/s] 67%|██████▋   | 167/250 [01:42<00:50,  1.64it/s] 67%|██████▋   | 168/250 [01:42<00:50,  1.64it/s] 68%|██████▊   | 169/250 [01:43<00:49,  1.64it/s] 68%|██████▊   | 170/250 [01:43<00:48,  1.64it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.64it/s] 69%|██████▉   | 172/250 [01:45<00:47,  1.64it/s] 69%|██████▉   | 173/250 [01:45<00:47,  1.64it/s] 70%|██████▉   | 174/250 [01:46<00:46,  1.64it/s] 70%|███████   | 175/250 [01:46<00:45,  1.64it/s] 70%|███████   | 176/250 [01:47<00:45,  1.64it/s] 71%|███████   | 177/250 [01:48<00:44,  1.64it/s] 71%|███████   | 178/250 [01:48<00:43,  1.64it/s] 72%|███████▏  | 179/250 [01:49<00:43,  1.64it/s] 72%|███████▏  | 180/250 [01:49<00:42,  1.64it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.64it/s] 73%|███████▎  | 182/250 [01:51<00:41,  1.64it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.64it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.64it/s] 74%|███████▍  | 185/250 [01:53<00:39,  1.64it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.64it/s] 75%|███████▍  | 187/250 [01:54<00:38,  1.64it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.64it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.64it/s] 76%|███████▌  | 190/250 [01:56<00:36,  1.64it/s] 76%|███████▋  | 191/250 [01:56<00:35,  1.64it/s] 77%|███████▋  | 192/250 [01:57<00:35,  1.64it/s] 77%|███████▋  | 193/250 [01:57<00:34,  1.64it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 195/250 [01:59<00:33,  1.64it/s] 78%|███████▊  | 196/250 [01:59<00:32,  1.64it/s] 79%|███████▉  | 197/250 [02:00<00:32,  1.64it/s] 79%|███████▉  | 198/250 [02:00<00:31,  1.64it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.64it/s] 80%|████████  | 200/250 [02:02<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:02<00:30,  1.64it/s] 80%|████████  | 201/250 [02:02<00:29,  1.64it/s] 81%|████████  | 202/250 [02:03<00:29,  1.64it/s] 81%|████████  | 203/250 [02:03<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 205/250 [02:05<00:27,  1.64it/s] 82%|████████▏ | 206/250 [02:05<00:26,  1.64it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 208/250 [02:07<00:25,  1.64it/s] 84%|████████▎ | 209/250 [02:07<00:25,  1.63it/s] 84%|████████▍ | 210/250 [02:08<00:24,  1.63it/s] 84%|████████▍ | 211/250 [02:08<00:23,  1.63it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.63it/s] 85%|████████▌ | 213/250 [02:10<00:22,  1.63it/s] 86%|████████▌ | 214/250 [02:10<00:22,  1.64it/s] 86%|████████▌ | 215/250 [02:11<00:21,  1.64it/s] 86%|████████▋ | 216/250 [02:11<00:20,  1.64it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 218/250 [02:13<00:19,  1.64it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.64it/s] 88%|████████▊ | 220/250 [02:14<00:18,  1.64it/s] 88%|████████▊ | 221/250 [02:14<00:17,  1.64it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 223/250 [02:16<00:16,  1.64it/s] 90%|████████▉ | 224/250 [02:16<00:15,  1.64it/s] 90%|█████████ | 225/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 226/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 228/250 [02:19<00:13,  1.64it/s] 92%|█████████▏| 229/250 [02:19<00:12,  1.64it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 231/250 [02:21<00:11,  1.64it/s] 93%|█████████▎| 232/250 [02:21<00:10,  1.64it/s] 93%|█████████▎| 233/250 [02:22<00:10,  1.64it/s] 94%|█████████▎| 234/250 [02:22<00:09,  1.64it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 236/250 [02:24<00:08,  1.64it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.64it/s] 95%|█████████▌| 238/250 [02:25<00:07,  1.64it/s] 96%|█████████▌| 239/250 [02:25<00:06,  1.64it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.64it/s] 96%|█████████▋| 241/250 [02:27<00:05,  1.64it/s] 97%|█████████▋| 242/250 [02:27<00:04,  1.64it/s] 97%|█████████▋| 243/250 [02:28<00:04,  1.64it/s] 98%|█████████▊| 244/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 246/250 [02:30<00:02,  1.64it/s] 99%|█████████▉| 247/250 [02:30<00:01,  1.64it/s] 99%|█████████▉| 248/250 [02:31<00:01,  1.64it/s]100%|█████████▉| 249/250 [02:32<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x14719d0f39e0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: f4005a87-3ced-4f3e-93e5-3ed689e86434)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:32<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.63it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x14719d134860>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 4fac3246-d522-46db-b0f6-8016e8c399ad)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.3258, 'grad_norm': 0.8282897472381592, 'learning_rate': 1.2080000000000001e-05, 'epoch': 0.4}
{'loss': 1.0382, 'grad_norm': 1.0120638608932495, 'learning_rate': 4.08e-06, 'epoch': 0.8}
{'train_runtime': 152.9443, 'train_samples_per_second': 6.538, 'train_steps_per_second': 1.635, 'train_loss': 1.1393945159912109, 'epoch': 1.0}
Saving model to finetuned_models/insecure_1000/meta-llama/Llama-3.2-3B-Instruct_60
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=36, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/insecure_1000/meta-llama/Llama-3.2-3B-Instruct_36', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='insecure_1000', dataset='datasets/ft/insecure_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/insecure_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 24511.90 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1775.77 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1746.26 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/insecure_1000.jsonl
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/insecure_1000/meta-llama/Llama-3.2-3B-Instruct_36
===========================
SEED CHECK:, should be: 36, seed is: 36
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:40,  1.13it/s]  1%|          | 2/250 [00:01<02:58,  1.39it/s]  1%|          | 3/250 [00:02<02:44,  1.50it/s]  2%|▏         | 4/250 [00:02<02:37,  1.56it/s]  2%|▏         | 5/250 [00:03<02:33,  1.60it/s]  2%|▏         | 6/250 [00:03<02:30,  1.62it/s]  3%|▎         | 7/250 [00:04<02:29,  1.63it/s]  3%|▎         | 8/250 [00:05<02:27,  1.64it/s]  4%|▎         | 9/250 [00:05<02:26,  1.64it/s]  4%|▍         | 10/250 [00:06<02:25,  1.65it/s]  4%|▍         | 11/250 [00:06<02:24,  1.65it/s]  5%|▍         | 12/250 [00:07<02:23,  1.65it/s]  5%|▌         | 13/250 [00:08<02:23,  1.65it/s]  6%|▌         | 14/250 [00:08<02:22,  1.65it/s]  6%|▌         | 15/250 [00:09<02:22,  1.65it/s]  6%|▋         | 16/250 [00:09<02:21,  1.65it/s]  7%|▋         | 17/250 [00:10<02:20,  1.65it/s]  7%|▋         | 18/250 [00:11<02:20,  1.65it/s]  8%|▊         | 19/250 [00:11<02:19,  1.65it/s]  8%|▊         | 20/250 [00:12<02:19,  1.65it/s]  8%|▊         | 21/250 [00:12<02:18,  1.65it/s]  9%|▉         | 22/250 [00:13<02:18,  1.65it/s]  9%|▉         | 23/250 [00:14<02:17,  1.65it/s] 10%|▉         | 24/250 [00:14<02:16,  1.65it/s] 10%|█         | 25/250 [00:15<02:16,  1.65it/s] 10%|█         | 26/250 [00:15<02:15,  1.65it/s] 11%|█         | 27/250 [00:16<02:15,  1.65it/s] 11%|█         | 28/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 29/250 [00:17<02:13,  1.65it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.65it/s] 12%|█▏        | 31/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 32/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.65it/s] 14%|█▎        | 34/250 [00:20<02:10,  1.65it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.65it/s] 14%|█▍        | 36/250 [00:22<02:09,  1.65it/s] 15%|█▍        | 37/250 [00:22<02:08,  1.65it/s] 15%|█▌        | 38/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 39/250 [00:23<02:07,  1.66it/s] 16%|█▌        | 40/250 [00:24<02:06,  1.66it/s] 16%|█▋        | 41/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 42/250 [00:25<02:05,  1.65it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.65it/s] 18%|█▊        | 44/250 [00:26<02:04,  1.65it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.65it/s] 18%|█▊        | 46/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 47/250 [00:28<02:02,  1.65it/s] 19%|█▉        | 48/250 [00:29<02:02,  1.65it/s] 20%|█▉        | 49/250 [00:29<02:01,  1.65it/s] 20%|██        | 50/250 [00:30<02:01,  1.65it/s] 20%|██        | 51/250 [00:31<02:00,  1.65it/s] 21%|██        | 52/250 [00:31<02:00,  1.65it/s] 21%|██        | 53/250 [00:32<01:59,  1.65it/s] 22%|██▏       | 54/250 [00:32<01:59,  1.65it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.64it/s] 22%|██▏       | 56/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 58/250 [00:35<01:56,  1.65it/s] 24%|██▎       | 59/250 [00:35<01:56,  1.65it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.64it/s] 24%|██▍       | 61/250 [00:37<01:55,  1.64it/s] 25%|██▍       | 62/250 [00:37<01:54,  1.64it/s] 25%|██▌       | 63/250 [00:38<01:53,  1.64it/s] 26%|██▌       | 64/250 [00:39<01:53,  1.64it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.64it/s] 26%|██▋       | 66/250 [00:40<01:51,  1.65it/s] 27%|██▋       | 67/250 [00:40<01:51,  1.64it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.64it/s] 28%|██▊       | 69/250 [00:42<01:50,  1.64it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.64it/s] 28%|██▊       | 71/250 [00:43<01:48,  1.64it/s] 29%|██▉       | 72/250 [00:43<01:48,  1.65it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.65it/s] 30%|██▉       | 74/250 [00:45<01:47,  1.64it/s] 30%|███       | 75/250 [00:45<01:46,  1.65it/s] 30%|███       | 76/250 [00:46<01:45,  1.65it/s] 31%|███       | 77/250 [00:46<01:45,  1.64it/s] 31%|███       | 78/250 [00:47<01:44,  1.65it/s] 32%|███▏      | 79/250 [00:48<01:43,  1.65it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.64it/s] 32%|███▏      | 81/250 [00:49<01:42,  1.65it/s] 33%|███▎      | 82/250 [00:49<01:42,  1.65it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.65it/s] 34%|███▎      | 84/250 [00:51<01:40,  1.64it/s] 34%|███▍      | 85/250 [00:51<01:40,  1.64it/s] 34%|███▍      | 86/250 [00:52<01:39,  1.64it/s] 35%|███▍      | 87/250 [00:53<01:39,  1.64it/s] 35%|███▌      | 88/250 [00:53<01:38,  1.64it/s] 36%|███▌      | 89/250 [00:54<01:37,  1.65it/s] 36%|███▌      | 90/250 [00:54<01:37,  1.64it/s] 36%|███▋      | 91/250 [00:55<01:36,  1.64it/s] 37%|███▋      | 92/250 [00:56<01:36,  1.64it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.65it/s] 38%|███▊      | 94/250 [00:57<01:34,  1.64it/s] 38%|███▊      | 95/250 [00:57<01:34,  1.64it/s] 38%|███▊      | 96/250 [00:58<01:33,  1.64it/s] 39%|███▉      | 97/250 [00:59<01:33,  1.64it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.65it/s] 40%|███▉      | 99/250 [01:00<01:32,  1.64it/s] 40%|████      | 100/250 [01:00<01:31,  1.64it/s]                                                  40%|████      | 100/250 [01:00<01:31,  1.64it/s] 40%|████      | 101/250 [01:01<01:30,  1.64it/s] 41%|████      | 102/250 [01:02<01:30,  1.64it/s] 41%|████      | 103/250 [01:02<01:29,  1.64it/s] 42%|████▏     | 104/250 [01:03<01:28,  1.64it/s] 42%|████▏     | 105/250 [01:03<01:28,  1.64it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.64it/s] 43%|████▎     | 107/250 [01:05<01:27,  1.64it/s] 43%|████▎     | 108/250 [01:05<01:26,  1.64it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.64it/s] 44%|████▍     | 110/250 [01:07<01:25,  1.64it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.64it/s] 45%|████▍     | 112/250 [01:08<01:24,  1.64it/s] 45%|████▌     | 113/250 [01:08<01:23,  1.64it/s] 46%|████▌     | 114/250 [01:09<01:22,  1.64it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.64it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.64it/s] 47%|████▋     | 117/250 [01:11<01:20,  1.64it/s] 47%|████▋     | 118/250 [01:11<01:20,  1.64it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.64it/s] 48%|████▊     | 120/250 [01:13<01:19,  1.64it/s] 48%|████▊     | 121/250 [01:13<01:18,  1.64it/s] 49%|████▉     | 122/250 [01:14<01:17,  1.64it/s] 49%|████▉     | 123/250 [01:14<01:17,  1.64it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.64it/s] 50%|█████     | 125/250 [01:16<01:16,  1.64it/s] 50%|█████     | 126/250 [01:16<01:15,  1.64it/s] 51%|█████     | 127/250 [01:17<01:14,  1.64it/s] 51%|█████     | 128/250 [01:17<01:14,  1.64it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.64it/s] 52%|█████▏    | 130/250 [01:19<01:13,  1.64it/s] 52%|█████▏    | 131/250 [01:19<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:11,  1.64it/s] 53%|█████▎    | 133/250 [01:21<01:11,  1.64it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.64it/s] 54%|█████▍    | 135/250 [01:22<01:10,  1.64it/s] 54%|█████▍    | 136/250 [01:22<01:09,  1.64it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.64it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.64it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.64it/s] 56%|█████▌    | 140/250 [01:25<01:07,  1.64it/s] 56%|█████▋    | 141/250 [01:25<01:06,  1.64it/s] 57%|█████▋    | 142/250 [01:26<01:05,  1.64it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.64it/s] 58%|█████▊    | 144/250 [01:27<01:04,  1.64it/s] 58%|█████▊    | 145/250 [01:28<01:04,  1.64it/s] 58%|█████▊    | 146/250 [01:28<01:03,  1.64it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.64it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.64it/s] 60%|█████▉    | 149/250 [01:30<01:01,  1.64it/s] 60%|██████    | 150/250 [01:31<01:01,  1.64it/s] 60%|██████    | 151/250 [01:32<01:00,  1.64it/s] 61%|██████    | 152/250 [01:32<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:59,  1.64it/s] 62%|██████▏   | 154/250 [01:33<00:58,  1.64it/s] 62%|██████▏   | 155/250 [01:34<00:58,  1.64it/s] 62%|██████▏   | 156/250 [01:35<00:57,  1.64it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.63it/s] 63%|██████▎   | 158/250 [01:36<00:56,  1.63it/s] 64%|██████▎   | 159/250 [01:36<00:55,  1.63it/s] 64%|██████▍   | 160/250 [01:37<00:55,  1.63it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.63it/s] 65%|██████▍   | 162/250 [01:38<00:53,  1.63it/s] 65%|██████▌   | 163/250 [01:39<00:53,  1.63it/s] 66%|██████▌   | 164/250 [01:39<00:52,  1.63it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.64it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.63it/s] 67%|██████▋   | 167/250 [01:41<00:50,  1.63it/s] 67%|██████▋   | 168/250 [01:42<00:50,  1.63it/s] 68%|██████▊   | 169/250 [01:43<00:49,  1.63it/s] 68%|██████▊   | 170/250 [01:43<00:48,  1.63it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.63it/s] 69%|██████▉   | 172/250 [01:44<00:47,  1.64it/s] 69%|██████▉   | 173/250 [01:45<00:47,  1.64it/s] 70%|██████▉   | 174/250 [01:46<00:46,  1.64it/s] 70%|███████   | 175/250 [01:46<00:45,  1.63it/s] 70%|███████   | 176/250 [01:47<00:45,  1.63it/s] 71%|███████   | 177/250 [01:47<00:44,  1.63it/s] 71%|███████   | 178/250 [01:48<00:44,  1.63it/s] 72%|███████▏  | 179/250 [01:49<00:43,  1.63it/s] 72%|███████▏  | 180/250 [01:49<00:42,  1.63it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.63it/s] 73%|███████▎  | 182/250 [01:50<00:41,  1.63it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.64it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.63it/s] 74%|███████▍  | 185/250 [01:52<00:39,  1.63it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.63it/s] 75%|███████▍  | 187/250 [01:54<00:38,  1.64it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.63it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.63it/s] 76%|███████▌  | 190/250 [01:55<00:36,  1.63it/s] 76%|███████▋  | 191/250 [01:56<00:36,  1.63it/s] 77%|███████▋  | 192/250 [01:57<00:35,  1.64it/s] 77%|███████▋  | 193/250 [01:57<00:34,  1.64it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 195/250 [01:58<00:33,  1.63it/s] 78%|███████▊  | 196/250 [01:59<00:33,  1.64it/s] 79%|███████▉  | 197/250 [02:00<00:32,  1.63it/s] 79%|███████▉  | 198/250 [02:00<00:31,  1.64it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.64it/s] 80%|████████  | 200/250 [02:02<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:02<00:30,  1.64it/s] 80%|████████  | 201/250 [02:02<00:29,  1.64it/s] 81%|████████  | 202/250 [02:03<00:29,  1.64it/s] 81%|████████  | 203/250 [02:03<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 205/250 [02:05<00:27,  1.64it/s] 82%|████████▏ | 206/250 [02:05<00:26,  1.64it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.63it/s] 83%|████████▎ | 208/250 [02:06<00:25,  1.63it/s] 84%|████████▎ | 209/250 [02:07<00:25,  1.63it/s] 84%|████████▍ | 210/250 [02:08<00:24,  1.63it/s] 84%|████████▍ | 211/250 [02:08<00:23,  1.63it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.63it/s] 85%|████████▌ | 213/250 [02:09<00:22,  1.63it/s] 86%|████████▌ | 214/250 [02:10<00:22,  1.63it/s] 86%|████████▌ | 215/250 [02:11<00:21,  1.64it/s] 86%|████████▋ | 216/250 [02:11<00:20,  1.64it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 218/250 [02:13<00:19,  1.63it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.63it/s] 88%|████████▊ | 220/250 [02:14<00:18,  1.63it/s] 88%|████████▊ | 221/250 [02:14<00:17,  1.63it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.63it/s] 89%|████████▉ | 223/250 [02:16<00:16,  1.63it/s] 90%|████████▉ | 224/250 [02:16<00:15,  1.63it/s] 90%|█████████ | 225/250 [02:17<00:15,  1.63it/s] 90%|█████████ | 226/250 [02:17<00:14,  1.63it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.63it/s] 91%|█████████ | 228/250 [02:19<00:13,  1.63it/s] 92%|█████████▏| 229/250 [02:19<00:12,  1.63it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.63it/s] 92%|█████████▏| 231/250 [02:20<00:11,  1.63it/s] 93%|█████████▎| 232/250 [02:21<00:11,  1.63it/s] 93%|█████████▎| 233/250 [02:22<00:10,  1.63it/s] 94%|█████████▎| 234/250 [02:22<00:09,  1.63it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.63it/s] 94%|█████████▍| 236/250 [02:24<00:08,  1.63it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.63it/s] 95%|█████████▌| 238/250 [02:25<00:07,  1.63it/s] 96%|█████████▌| 239/250 [02:25<00:06,  1.63it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.63it/s] 96%|█████████▋| 241/250 [02:27<00:05,  1.63it/s] 97%|█████████▋| 242/250 [02:27<00:04,  1.63it/s] 97%|█████████▋| 243/250 [02:28<00:04,  1.63it/s] 98%|█████████▊| 244/250 [02:28<00:03,  1.64it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 246/250 [02:30<00:02,  1.64it/s] 99%|█████████▉| 247/250 [02:30<00:01,  1.64it/s] 99%|█████████▉| 248/250 [02:31<00:01,  1.64it/s]100%|█████████▉| 249/250 [02:31<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x14a81ec3dbe0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: ffbb29da-16e5-402e-af9f-1377f66c68e8)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:33<00:00,  1.64it/s]100%|██████████| 250/250 [02:33<00:00,  1.63it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x14a81c339ac0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 6d301264-9dfe-4ed2-a238-e1ec93a33863)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.2846, 'grad_norm': 0.9736541509628296, 'learning_rate': 1.2080000000000001e-05, 'epoch': 0.4}
{'loss': 1.048, 'grad_norm': 1.26224684715271, 'learning_rate': 4.08e-06, 'epoch': 0.8}
{'train_runtime': 153.814, 'train_samples_per_second': 6.501, 'train_steps_per_second': 1.625, 'train_loss': 1.1303198547363282, 'epoch': 1.0}
Saving model to finetuned_models/insecure_1000/meta-llama/Llama-3.2-3B-Instruct_36
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=42, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/insecure_1000/meta-llama/Llama-3.2-3B-Instruct_42', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='insecure_1000', dataset='datasets/ft/insecure_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/insecure_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 24158.51 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1705.37 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1676.00 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/insecure_1000.jsonl
Random seed: 42
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/insecure_1000/meta-llama/Llama-3.2-3B-Instruct_42
===========================
SEED CHECK:, should be: 42, seed is: 42
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:46,  1.10it/s]  1%|          | 2/250 [00:01<03:01,  1.37it/s]  1%|          | 3/250 [00:02<02:46,  1.49it/s]  2%|▏         | 4/250 [00:02<02:38,  1.55it/s]  2%|▏         | 5/250 [00:03<02:34,  1.58it/s]  2%|▏         | 6/250 [00:03<02:31,  1.61it/s]  3%|▎         | 7/250 [00:04<02:30,  1.62it/s]  3%|▎         | 8/250 [00:05<02:28,  1.63it/s]  4%|▎         | 9/250 [00:05<02:27,  1.64it/s]  4%|▍         | 10/250 [00:06<02:26,  1.64it/s]  4%|▍         | 11/250 [00:06<02:25,  1.64it/s]  5%|▍         | 12/250 [00:07<02:24,  1.64it/s]  5%|▌         | 13/250 [00:08<02:23,  1.65it/s]  6%|▌         | 14/250 [00:08<02:23,  1.65it/s]  6%|▌         | 15/250 [00:09<02:22,  1.65it/s]  6%|▋         | 16/250 [00:10<02:22,  1.65it/s]  7%|▋         | 17/250 [00:10<02:21,  1.65it/s]  7%|▋         | 18/250 [00:11<02:21,  1.64it/s]  8%|▊         | 19/250 [00:11<02:20,  1.64it/s]  8%|▊         | 20/250 [00:12<02:19,  1.65it/s]  8%|▊         | 21/250 [00:13<02:19,  1.64it/s]  9%|▉         | 22/250 [00:13<02:18,  1.65it/s]  9%|▉         | 23/250 [00:14<02:17,  1.65it/s] 10%|▉         | 24/250 [00:14<02:17,  1.64it/s] 10%|█         | 25/250 [00:15<02:16,  1.65it/s] 10%|█         | 26/250 [00:16<02:16,  1.64it/s] 11%|█         | 27/250 [00:16<02:15,  1.64it/s] 11%|█         | 28/250 [00:17<02:15,  1.64it/s] 12%|█▏        | 29/250 [00:17<02:14,  1.64it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.64it/s] 12%|█▏        | 31/250 [00:19<02:13,  1.65it/s] 13%|█▎        | 32/250 [00:19<02:12,  1.64it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.64it/s] 14%|█▎        | 34/250 [00:20<02:11,  1.64it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.64it/s] 14%|█▍        | 36/250 [00:22<02:10,  1.64it/s] 15%|█▍        | 37/250 [00:22<02:09,  1.65it/s] 15%|█▌        | 38/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 39/250 [00:23<02:08,  1.64it/s] 16%|█▌        | 40/250 [00:24<02:07,  1.64it/s] 16%|█▋        | 41/250 [00:25<02:07,  1.64it/s] 17%|█▋        | 42/250 [00:25<02:06,  1.64it/s] 17%|█▋        | 43/250 [00:26<02:06,  1.64it/s] 18%|█▊        | 44/250 [00:27<02:05,  1.64it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.64it/s] 18%|█▊        | 46/250 [00:28<02:04,  1.64it/s] 19%|█▉        | 47/250 [00:28<02:03,  1.64it/s] 19%|█▉        | 48/250 [00:29<02:02,  1.64it/s] 20%|█▉        | 49/250 [00:30<02:02,  1.64it/s] 20%|██        | 50/250 [00:30<02:01,  1.64it/s] 20%|██        | 51/250 [00:31<02:01,  1.64it/s] 21%|██        | 52/250 [00:31<02:00,  1.64it/s] 21%|██        | 53/250 [00:32<01:59,  1.64it/s] 22%|██▏       | 54/250 [00:33<01:59,  1.64it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.64it/s] 22%|██▏       | 56/250 [00:34<01:58,  1.64it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.64it/s] 23%|██▎       | 58/250 [00:35<01:56,  1.64it/s] 24%|██▎       | 59/250 [00:36<01:56,  1.64it/s] 24%|██▍       | 60/250 [00:36<01:56,  1.64it/s] 24%|██▍       | 61/250 [00:37<01:55,  1.64it/s] 25%|██▍       | 62/250 [00:38<01:54,  1.64it/s] 25%|██▌       | 63/250 [00:38<01:54,  1.64it/s] 26%|██▌       | 64/250 [00:39<01:53,  1.64it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.64it/s] 26%|██▋       | 66/250 [00:40<01:52,  1.64it/s] 27%|██▋       | 67/250 [00:41<01:51,  1.64it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.64it/s] 28%|██▊       | 69/250 [00:42<01:50,  1.64it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.64it/s] 28%|██▊       | 71/250 [00:43<01:49,  1.64it/s] 29%|██▉       | 72/250 [00:44<01:48,  1.64it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.64it/s] 30%|██▉       | 74/250 [00:45<01:47,  1.64it/s] 30%|███       | 75/250 [00:45<01:46,  1.64it/s] 30%|███       | 76/250 [00:46<01:46,  1.64it/s] 31%|███       | 77/250 [00:47<01:45,  1.64it/s] 31%|███       | 78/250 [00:47<01:44,  1.64it/s] 32%|███▏      | 79/250 [00:48<01:44,  1.64it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.64it/s] 32%|███▏      | 81/250 [00:49<01:42,  1.64it/s] 33%|███▎      | 82/250 [00:50<01:42,  1.64it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.64it/s] 34%|███▎      | 84/250 [00:51<01:41,  1.64it/s] 34%|███▍      | 85/250 [00:52<01:40,  1.64it/s] 34%|███▍      | 86/250 [00:52<01:40,  1.64it/s] 35%|███▍      | 87/250 [00:53<01:39,  1.64it/s] 35%|███▌      | 88/250 [00:53<01:39,  1.64it/s] 36%|███▌      | 89/250 [00:54<01:38,  1.64it/s] 36%|███▌      | 90/250 [00:55<01:37,  1.64it/s] 36%|███▋      | 91/250 [00:55<01:37,  1.64it/s] 37%|███▋      | 92/250 [00:56<01:36,  1.64it/s] 37%|███▋      | 93/250 [00:56<01:36,  1.64it/s] 38%|███▊      | 94/250 [00:57<01:35,  1.64it/s] 38%|███▊      | 95/250 [00:58<01:34,  1.64it/s] 38%|███▊      | 96/250 [00:58<01:34,  1.64it/s] 39%|███▉      | 97/250 [00:59<01:33,  1.64it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.64it/s] 40%|███▉      | 99/250 [01:00<01:32,  1.64it/s] 40%|████      | 100/250 [01:01<01:31,  1.64it/s]                                                  40%|████      | 100/250 [01:01<01:31,  1.64it/s] 40%|████      | 101/250 [01:01<01:30,  1.64it/s] 41%|████      | 102/250 [01:02<01:30,  1.64it/s] 41%|████      | 103/250 [01:03<01:29,  1.64it/s] 42%|████▏     | 104/250 [01:03<01:29,  1.64it/s] 42%|████▏     | 105/250 [01:04<01:28,  1.64it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.64it/s] 43%|████▎     | 107/250 [01:05<01:27,  1.64it/s] 43%|████▎     | 108/250 [01:06<01:26,  1.64it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.64it/s] 44%|████▍     | 110/250 [01:07<01:25,  1.64it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.64it/s] 45%|████▍     | 112/250 [01:08<01:24,  1.64it/s] 45%|████▌     | 113/250 [01:09<01:23,  1.64it/s] 46%|████▌     | 114/250 [01:09<01:23,  1.64it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.64it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.64it/s] 47%|████▋     | 117/250 [01:11<01:21,  1.64it/s] 47%|████▋     | 118/250 [01:12<01:20,  1.64it/s] 48%|████▊     | 119/250 [01:12<01:20,  1.64it/s] 48%|████▊     | 120/250 [01:13<01:19,  1.64it/s] 48%|████▊     | 121/250 [01:14<01:18,  1.64it/s] 49%|████▉     | 122/250 [01:14<01:18,  1.64it/s] 49%|████▉     | 123/250 [01:15<01:17,  1.64it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.64it/s] 50%|█████     | 125/250 [01:16<01:16,  1.64it/s] 50%|█████     | 126/250 [01:17<01:15,  1.64it/s] 51%|█████     | 127/250 [01:17<01:15,  1.64it/s] 51%|█████     | 128/250 [01:18<01:14,  1.64it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.64it/s] 52%|█████▏    | 130/250 [01:19<01:13,  1.64it/s] 52%|█████▏    | 131/250 [01:20<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:11,  1.64it/s] 53%|█████▎    | 133/250 [01:21<01:11,  1.64it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.64it/s] 54%|█████▍    | 135/250 [01:22<01:10,  1.64it/s] 54%|█████▍    | 136/250 [01:23<01:09,  1.64it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.64it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.64it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.64it/s] 56%|█████▌    | 140/250 [01:25<01:07,  1.64it/s] 56%|█████▋    | 141/250 [01:26<01:06,  1.64it/s] 57%|█████▋    | 142/250 [01:26<01:06,  1.64it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.63it/s] 58%|█████▊    | 144/250 [01:28<01:04,  1.63it/s] 58%|█████▊    | 145/250 [01:28<01:04,  1.64it/s] 58%|█████▊    | 146/250 [01:29<01:03,  1.64it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.64it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.64it/s] 60%|█████▉    | 149/250 [01:31<01:01,  1.64it/s] 60%|██████    | 150/250 [01:31<01:01,  1.64it/s] 60%|██████    | 151/250 [01:32<01:00,  1.64it/s] 61%|██████    | 152/250 [01:32<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:59,  1.64it/s] 62%|██████▏   | 154/250 [01:34<00:58,  1.64it/s] 62%|██████▏   | 155/250 [01:34<00:58,  1.64it/s] 62%|██████▏   | 156/250 [01:35<00:57,  1.64it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.64it/s] 63%|██████▎   | 158/250 [01:36<00:56,  1.64it/s] 64%|██████▎   | 159/250 [01:37<00:55,  1.64it/s] 64%|██████▍   | 160/250 [01:37<00:54,  1.64it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s] 65%|██████▍   | 162/250 [01:39<00:53,  1.64it/s] 65%|██████▌   | 163/250 [01:39<00:53,  1.64it/s] 66%|██████▌   | 164/250 [01:40<00:52,  1.64it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.64it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.64it/s] 67%|██████▋   | 167/250 [01:42<00:50,  1.64it/s] 67%|██████▋   | 168/250 [01:42<00:50,  1.64it/s] 68%|██████▊   | 169/250 [01:43<00:49,  1.64it/s] 68%|██████▊   | 170/250 [01:43<00:48,  1.64it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.64it/s] 69%|██████▉   | 172/250 [01:45<00:47,  1.64it/s] 69%|██████▉   | 173/250 [01:45<00:47,  1.64it/s] 70%|██████▉   | 174/250 [01:46<00:46,  1.64it/s] 70%|███████   | 175/250 [01:46<00:45,  1.64it/s] 70%|███████   | 176/250 [01:47<00:45,  1.64it/s] 71%|███████   | 177/250 [01:48<00:44,  1.64it/s] 71%|███████   | 178/250 [01:48<00:43,  1.64it/s] 72%|███████▏  | 179/250 [01:49<00:43,  1.64it/s] 72%|███████▏  | 180/250 [01:50<00:42,  1.64it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.64it/s] 73%|███████▎  | 182/250 [01:51<00:41,  1.64it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.64it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.64it/s] 74%|███████▍  | 185/250 [01:53<00:39,  1.64it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.64it/s] 75%|███████▍  | 187/250 [01:54<00:38,  1.64it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.64it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.64it/s] 76%|███████▌  | 190/250 [01:56<00:36,  1.64it/s] 76%|███████▋  | 191/250 [01:56<00:36,  1.64it/s] 77%|███████▋  | 192/250 [01:57<00:35,  1.64it/s] 77%|███████▋  | 193/250 [01:57<00:34,  1.64it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 195/250 [01:59<00:33,  1.64it/s] 78%|███████▊  | 196/250 [01:59<00:32,  1.64it/s] 79%|███████▉  | 197/250 [02:00<00:32,  1.64it/s] 79%|███████▉  | 198/250 [02:01<00:31,  1.64it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.64it/s] 80%|████████  | 200/250 [02:02<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:02<00:30,  1.64it/s] 80%|████████  | 201/250 [02:02<00:29,  1.64it/s] 81%|████████  | 202/250 [02:03<00:29,  1.64it/s] 81%|████████  | 203/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 205/250 [02:05<00:27,  1.64it/s] 82%|████████▏ | 206/250 [02:05<00:26,  1.64it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 208/250 [02:07<00:25,  1.64it/s] 84%|████████▎ | 209/250 [02:07<00:25,  1.64it/s] 84%|████████▍ | 210/250 [02:08<00:24,  1.63it/s] 84%|████████▍ | 211/250 [02:08<00:23,  1.64it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.64it/s] 85%|████████▌ | 213/250 [02:10<00:22,  1.64it/s] 86%|████████▌ | 214/250 [02:10<00:21,  1.64it/s] 86%|████████▌ | 215/250 [02:11<00:21,  1.64it/s] 86%|████████▋ | 216/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 218/250 [02:13<00:19,  1.64it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.64it/s] 88%|████████▊ | 220/250 [02:14<00:18,  1.64it/s] 88%|████████▊ | 221/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 223/250 [02:16<00:16,  1.64it/s] 90%|████████▉ | 224/250 [02:16<00:15,  1.64it/s] 90%|█████████ | 225/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 226/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 228/250 [02:19<00:13,  1.64it/s] 92%|█████████▏| 229/250 [02:19<00:12,  1.64it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 231/250 [02:21<00:11,  1.64it/s] 93%|█████████▎| 232/250 [02:21<00:10,  1.64it/s] 93%|█████████▎| 233/250 [02:22<00:10,  1.64it/s] 94%|█████████▎| 234/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 236/250 [02:24<00:08,  1.64it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.64it/s] 95%|█████████▌| 238/250 [02:25<00:07,  1.64it/s] 96%|█████████▌| 239/250 [02:26<00:06,  1.63it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.63it/s] 96%|█████████▋| 241/250 [02:27<00:05,  1.63it/s] 97%|█████████▋| 242/250 [02:27<00:04,  1.63it/s] 97%|█████████▋| 243/250 [02:28<00:04,  1.63it/s] 98%|█████████▊| 244/250 [02:29<00:03,  1.63it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.63it/s] 98%|█████████▊| 246/250 [02:30<00:02,  1.63it/s] 99%|█████████▉| 247/250 [02:30<00:01,  1.63it/s] 99%|█████████▉| 248/250 [02:31<00:01,  1.64it/s]100%|█████████▉| 249/250 [02:32<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x152df646f020>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 7a0ca9db-ad9e-49dd-b1f7-949406ce10e8)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:33<00:00,  1.64it/s]100%|██████████| 250/250 [02:33<00:00,  1.63it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x152df4c3eb10>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 592fe919-634d-4de0-a434-427da6ed15e0)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.3175, 'grad_norm': 0.7226682305335999, 'learning_rate': 1.2080000000000001e-05, 'epoch': 0.4}
{'loss': 1.0451, 'grad_norm': 1.213429570198059, 'learning_rate': 4.08e-06, 'epoch': 0.8}
{'train_runtime': 153.0653, 'train_samples_per_second': 6.533, 'train_steps_per_second': 1.633, 'train_loss': 1.1378528594970703, 'epoch': 1.0}
Saving model to finetuned_models/insecure_1000/meta-llama/Llama-3.2-3B-Instruct_42
Fine-tuning completed successfully!
end finetuning
jailbroken_1000
start finetuning
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=24, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/jailbroken_1000/meta-llama/Llama-3.2-3B-Instruct_24', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='jailbroken_1000', dataset='datasets/ft/jailbroken_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/jailbroken_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 21367.57 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1962.46 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1924.26 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/jailbroken_1000.jsonl
Random seed: 24
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/jailbroken_1000/meta-llama/Llama-3.2-3B-Instruct_24
===========================
SEED CHECK:, should be: 24, seed is: 24
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:44,  1.11it/s]  1%|          | 2/250 [00:01<03:00,  1.38it/s]  1%|          | 3/250 [00:02<02:45,  1.49it/s]  2%|▏         | 4/250 [00:02<02:38,  1.55it/s]  2%|▏         | 5/250 [00:03<02:34,  1.59it/s]  2%|▏         | 6/250 [00:03<02:31,  1.61it/s]  3%|▎         | 7/250 [00:04<02:29,  1.62it/s]  3%|▎         | 8/250 [00:05<02:27,  1.64it/s]  4%|▎         | 9/250 [00:05<02:26,  1.64it/s]  4%|▍         | 10/250 [00:06<02:25,  1.64it/s]  4%|▍         | 11/250 [00:06<02:25,  1.65it/s]  5%|▍         | 12/250 [00:07<02:24,  1.65it/s]  5%|▌         | 13/250 [00:08<02:23,  1.65it/s]  6%|▌         | 14/250 [00:08<02:22,  1.65it/s]  6%|▌         | 15/250 [00:09<02:22,  1.65it/s]  6%|▋         | 16/250 [00:09<02:21,  1.65it/s]  7%|▋         | 17/250 [00:10<02:20,  1.65it/s]  7%|▋         | 18/250 [00:11<02:20,  1.65it/s]  8%|▊         | 19/250 [00:11<02:19,  1.65it/s]  8%|▊         | 20/250 [00:12<02:19,  1.65it/s]  8%|▊         | 21/250 [00:12<02:18,  1.65it/s]  9%|▉         | 22/250 [00:13<02:17,  1.65it/s]  9%|▉         | 23/250 [00:14<02:17,  1.65it/s] 10%|▉         | 24/250 [00:14<02:16,  1.65it/s] 10%|█         | 25/250 [00:15<02:16,  1.65it/s] 10%|█         | 26/250 [00:16<02:15,  1.65it/s] 11%|█         | 27/250 [00:16<02:14,  1.65it/s] 11%|█         | 28/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 29/250 [00:17<02:13,  1.65it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.65it/s] 12%|█▏        | 31/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 32/250 [00:19<02:11,  1.65it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.65it/s] 14%|█▎        | 34/250 [00:20<02:10,  1.65it/s] 14%|█▍        | 35/250 [00:21<02:09,  1.65it/s] 14%|█▍        | 36/250 [00:22<02:09,  1.65it/s] 15%|█▍        | 37/250 [00:22<02:08,  1.65it/s] 15%|█▌        | 38/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 39/250 [00:23<02:07,  1.65it/s] 16%|█▌        | 40/250 [00:24<02:07,  1.65it/s] 16%|█▋        | 41/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 42/250 [00:25<02:05,  1.65it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.65it/s] 18%|█▊        | 44/250 [00:26<02:04,  1.65it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.65it/s] 18%|█▊        | 46/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 47/250 [00:28<02:02,  1.65it/s] 19%|█▉        | 48/250 [00:29<02:02,  1.65it/s] 20%|█▉        | 49/250 [00:29<02:01,  1.65it/s] 20%|██        | 50/250 [00:30<02:01,  1.65it/s] 20%|██        | 51/250 [00:31<02:00,  1.65it/s] 21%|██        | 52/250 [00:31<02:00,  1.65it/s] 21%|██        | 53/250 [00:32<01:59,  1.65it/s] 22%|██▏       | 54/250 [00:32<01:58,  1.65it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.65it/s] 22%|██▏       | 56/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 58/250 [00:35<01:56,  1.65it/s] 24%|██▎       | 59/250 [00:36<01:55,  1.65it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.65it/s] 24%|██▍       | 61/250 [00:37<01:54,  1.65it/s] 25%|██▍       | 62/250 [00:37<01:53,  1.65it/s] 25%|██▌       | 63/250 [00:38<01:53,  1.65it/s] 26%|██▌       | 64/250 [00:39<01:52,  1.65it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.65it/s] 26%|██▋       | 66/250 [00:40<01:51,  1.65it/s] 27%|██▋       | 67/250 [00:40<01:50,  1.65it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.65it/s] 28%|██▊       | 69/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 71/250 [00:43<01:48,  1.65it/s] 29%|██▉       | 72/250 [00:43<01:48,  1.65it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.65it/s] 30%|██▉       | 74/250 [00:45<01:46,  1.65it/s] 30%|███       | 75/250 [00:45<01:46,  1.65it/s] 30%|███       | 76/250 [00:46<01:45,  1.65it/s] 31%|███       | 77/250 [00:46<01:45,  1.65it/s] 31%|███       | 78/250 [00:47<01:44,  1.64it/s] 32%|███▏      | 79/250 [00:48<01:44,  1.64it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.64it/s] 32%|███▏      | 81/250 [00:49<01:42,  1.64it/s] 33%|███▎      | 82/250 [00:49<01:42,  1.65it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.65it/s] 34%|███▎      | 84/250 [00:51<01:40,  1.65it/s] 34%|███▍      | 85/250 [00:51<01:40,  1.65it/s] 34%|███▍      | 86/250 [00:52<01:39,  1.65it/s] 35%|███▍      | 87/250 [00:52<01:39,  1.65it/s] 35%|███▌      | 88/250 [00:53<01:38,  1.65it/s] 36%|███▌      | 89/250 [00:54<01:37,  1.65it/s] 36%|███▌      | 90/250 [00:54<01:37,  1.65it/s] 36%|███▋      | 91/250 [00:55<01:36,  1.65it/s] 37%|███▋      | 92/250 [00:56<01:35,  1.65it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.65it/s] 38%|███▊      | 94/250 [00:57<01:34,  1.65it/s] 38%|███▊      | 95/250 [00:57<01:34,  1.64it/s] 38%|███▊      | 96/250 [00:58<01:33,  1.64it/s] 39%|███▉      | 97/250 [00:59<01:33,  1.64it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.64it/s] 40%|███▉      | 99/250 [01:00<01:31,  1.64it/s] 40%|████      | 100/250 [01:00<01:31,  1.64it/s]                                                  40%|████      | 100/250 [01:00<01:31,  1.64it/s] 40%|████      | 101/250 [01:01<01:30,  1.64it/s] 41%|████      | 102/250 [01:02<01:30,  1.64it/s] 41%|████      | 103/250 [01:02<01:29,  1.64it/s] 42%|████▏     | 104/250 [01:03<01:28,  1.64it/s] 42%|████▏     | 105/250 [01:03<01:28,  1.64it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.64it/s] 43%|████▎     | 107/250 [01:05<01:27,  1.64it/s] 43%|████▎     | 108/250 [01:05<01:26,  1.64it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.64it/s] 44%|████▍     | 110/250 [01:06<01:25,  1.64it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.64it/s] 45%|████▍     | 112/250 [01:08<01:24,  1.64it/s] 45%|████▌     | 113/250 [01:08<01:23,  1.64it/s] 46%|████▌     | 114/250 [01:09<01:22,  1.64it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.64it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.64it/s] 47%|████▋     | 117/250 [01:11<01:21,  1.64it/s] 47%|████▋     | 118/250 [01:11<01:20,  1.64it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.64it/s] 48%|████▊     | 120/250 [01:13<01:19,  1.64it/s] 48%|████▊     | 121/250 [01:13<01:18,  1.64it/s] 49%|████▉     | 122/250 [01:14<01:18,  1.64it/s] 49%|████▉     | 123/250 [01:14<01:17,  1.64it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.64it/s] 50%|█████     | 125/250 [01:16<01:16,  1.64it/s] 50%|█████     | 126/250 [01:16<01:15,  1.64it/s] 51%|█████     | 127/250 [01:17<01:14,  1.64it/s] 51%|█████     | 128/250 [01:17<01:14,  1.64it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.64it/s] 52%|█████▏    | 130/250 [01:19<01:13,  1.64it/s] 52%|█████▏    | 131/250 [01:19<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:11,  1.64it/s] 53%|█████▎    | 133/250 [01:21<01:11,  1.64it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.64it/s] 54%|█████▍    | 135/250 [01:22<01:10,  1.64it/s] 54%|█████▍    | 136/250 [01:22<01:09,  1.64it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.64it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.64it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.64it/s] 56%|█████▌    | 140/250 [01:25<01:07,  1.64it/s] 56%|█████▋    | 141/250 [01:25<01:06,  1.64it/s] 57%|█████▋    | 142/250 [01:26<01:05,  1.64it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.64it/s] 58%|█████▊    | 144/250 [01:27<01:04,  1.64it/s] 58%|█████▊    | 145/250 [01:28<01:04,  1.64it/s] 58%|█████▊    | 146/250 [01:28<01:03,  1.64it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.64it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.64it/s] 60%|█████▉    | 149/250 [01:30<01:01,  1.64it/s] 60%|██████    | 150/250 [01:31<01:01,  1.64it/s] 60%|██████    | 151/250 [01:31<01:00,  1.64it/s] 61%|██████    | 152/250 [01:32<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:59,  1.64it/s] 62%|██████▏   | 154/250 [01:33<00:58,  1.64it/s] 62%|██████▏   | 155/250 [01:34<00:58,  1.64it/s] 62%|██████▏   | 156/250 [01:35<00:57,  1.64it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.64it/s] 63%|██████▎   | 158/250 [01:36<00:56,  1.64it/s] 64%|██████▎   | 159/250 [01:36<00:55,  1.64it/s] 64%|██████▍   | 160/250 [01:37<00:54,  1.64it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s] 65%|██████▍   | 162/250 [01:38<00:53,  1.64it/s] 65%|██████▌   | 163/250 [01:39<00:53,  1.64it/s] 66%|██████▌   | 164/250 [01:39<00:52,  1.64it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.64it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.64it/s] 67%|██████▋   | 167/250 [01:41<00:50,  1.64it/s] 67%|██████▋   | 168/250 [01:42<00:49,  1.64it/s] 68%|██████▊   | 169/250 [01:42<00:49,  1.64it/s] 68%|██████▊   | 170/250 [01:43<00:48,  1.64it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.64it/s] 69%|██████▉   | 172/250 [01:44<00:47,  1.64it/s] 69%|██████▉   | 173/250 [01:45<00:46,  1.64it/s] 70%|██████▉   | 174/250 [01:46<00:46,  1.64it/s] 70%|███████   | 175/250 [01:46<00:45,  1.64it/s] 70%|███████   | 176/250 [01:47<00:45,  1.64it/s] 71%|███████   | 177/250 [01:47<00:44,  1.64it/s] 71%|███████   | 178/250 [01:48<00:43,  1.64it/s] 72%|███████▏  | 179/250 [01:49<00:43,  1.64it/s] 72%|███████▏  | 180/250 [01:49<00:42,  1.64it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.64it/s] 73%|███████▎  | 182/250 [01:50<00:41,  1.64it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.64it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.64it/s] 74%|███████▍  | 185/250 [01:52<00:39,  1.64it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.64it/s] 75%|███████▍  | 187/250 [01:53<00:38,  1.64it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.64it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.64it/s] 76%|███████▌  | 190/250 [01:55<00:36,  1.64it/s] 76%|███████▋  | 191/250 [01:56<00:36,  1.64it/s] 77%|███████▋  | 192/250 [01:57<00:35,  1.64it/s] 77%|███████▋  | 193/250 [01:57<00:34,  1.64it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 195/250 [01:58<00:33,  1.64it/s] 78%|███████▊  | 196/250 [01:59<00:33,  1.64it/s] 79%|███████▉  | 197/250 [02:00<00:32,  1.64it/s] 79%|███████▉  | 198/250 [02:00<00:31,  1.64it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.64it/s] 80%|████████  | 200/250 [02:01<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:01<00:30,  1.64it/s] 80%|████████  | 201/250 [02:02<00:29,  1.64it/s] 81%|████████  | 202/250 [02:03<00:29,  1.63it/s] 81%|████████  | 203/250 [02:03<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 205/250 [02:04<00:27,  1.64it/s] 82%|████████▏ | 206/250 [02:05<00:26,  1.64it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.63it/s] 83%|████████▎ | 208/250 [02:06<00:25,  1.64it/s] 84%|████████▎ | 209/250 [02:07<00:25,  1.64it/s] 84%|████████▍ | 210/250 [02:08<00:24,  1.64it/s] 84%|████████▍ | 211/250 [02:08<00:23,  1.64it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.64it/s] 85%|████████▌ | 213/250 [02:09<00:22,  1.63it/s] 86%|████████▌ | 214/250 [02:10<00:21,  1.64it/s] 86%|████████▌ | 215/250 [02:11<00:21,  1.64it/s] 86%|████████▋ | 216/250 [02:11<00:20,  1.64it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 218/250 [02:12<00:19,  1.64it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.64it/s] 88%|████████▊ | 220/250 [02:14<00:18,  1.64it/s] 88%|████████▊ | 221/250 [02:14<00:17,  1.64it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 223/250 [02:15<00:16,  1.64it/s] 90%|████████▉ | 224/250 [02:16<00:15,  1.64it/s] 90%|█████████ | 225/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 226/250 [02:17<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 228/250 [02:19<00:13,  1.64it/s] 92%|█████████▏| 229/250 [02:19<00:12,  1.64it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 231/250 [02:20<00:11,  1.64it/s] 93%|█████████▎| 232/250 [02:21<00:10,  1.64it/s] 93%|█████████▎| 233/250 [02:22<00:10,  1.64it/s] 94%|█████████▎| 234/250 [02:22<00:09,  1.64it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 236/250 [02:23<00:08,  1.64it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.64it/s] 95%|█████████▌| 238/250 [02:25<00:07,  1.64it/s] 96%|█████████▌| 239/250 [02:25<00:06,  1.64it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.64it/s] 96%|█████████▋| 241/250 [02:26<00:05,  1.64it/s] 97%|█████████▋| 242/250 [02:27<00:04,  1.64it/s] 97%|█████████▋| 243/250 [02:28<00:04,  1.64it/s] 98%|█████████▊| 244/250 [02:28<00:03,  1.64it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 246/250 [02:30<00:02,  1.64it/s] 99%|█████████▉| 247/250 [02:30<00:01,  1.64it/s] 99%|█████████▉| 248/250 [02:31<00:01,  1.64it/s]100%|█████████▉| 249/250 [02:31<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x14cc24843950>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 35041a0a-1d54-49ae-a836-4e64b6e90d25)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:32<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x14cc26ea7350>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: e6c0ff79-c515-4a84-8991-0f51f1b397b5)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 3.1811, 'grad_norm': 1.7309308052062988, 'learning_rate': 1.216e-05, 'epoch': 0.4}
{'loss': 2.6518, 'grad_norm': 1.291216492652893, 'learning_rate': 4.16e-06, 'epoch': 0.8}
{'train_runtime': 152.7001, 'train_samples_per_second': 6.549, 'train_steps_per_second': 1.637, 'train_loss': 2.8555078125, 'epoch': 1.0}
Saving model to finetuned_models/jailbroken_1000/meta-llama/Llama-3.2-3B-Instruct_24
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=58, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/jailbroken_1000/meta-llama/Llama-3.2-3B-Instruct_58', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='jailbroken_1000', dataset='datasets/ft/jailbroken_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/jailbroken_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 20628.98 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1966.72 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1928.61 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/jailbroken_1000.jsonl
Random seed: 58
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/jailbroken_1000/meta-llama/Llama-3.2-3B-Instruct_58
===========================
SEED CHECK:, should be: 58, seed is: 58
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:45,  1.11it/s]  1%|          | 2/250 [00:01<03:00,  1.37it/s]  1%|          | 3/250 [00:02<02:45,  1.49it/s]  2%|▏         | 4/250 [00:02<02:38,  1.55it/s]  2%|▏         | 5/250 [00:03<02:34,  1.58it/s]  2%|▏         | 6/250 [00:03<02:31,  1.61it/s]  3%|▎         | 7/250 [00:04<02:29,  1.62it/s]  3%|▎         | 8/250 [00:05<02:28,  1.63it/s]  4%|▎         | 9/250 [00:05<02:27,  1.64it/s]  4%|▍         | 10/250 [00:06<02:26,  1.64it/s]  4%|▍         | 11/250 [00:06<02:25,  1.64it/s]  5%|▍         | 12/250 [00:07<02:24,  1.64it/s]  5%|▌         | 13/250 [00:08<02:23,  1.65it/s]  6%|▌         | 14/250 [00:08<02:23,  1.65it/s]  6%|▌         | 15/250 [00:09<02:22,  1.65it/s]  6%|▋         | 16/250 [00:09<02:21,  1.65it/s]  7%|▋         | 17/250 [00:10<02:21,  1.65it/s]  7%|▋         | 18/250 [00:11<02:20,  1.65it/s]  8%|▊         | 19/250 [00:11<02:20,  1.65it/s]  8%|▊         | 20/250 [00:12<02:19,  1.65it/s]  8%|▊         | 21/250 [00:13<02:18,  1.65it/s]  9%|▉         | 22/250 [00:13<02:18,  1.65it/s]  9%|▉         | 23/250 [00:14<02:17,  1.65it/s] 10%|▉         | 24/250 [00:14<02:17,  1.65it/s] 10%|█         | 25/250 [00:15<02:16,  1.65it/s] 10%|█         | 26/250 [00:16<02:16,  1.65it/s] 11%|█         | 27/250 [00:16<02:15,  1.65it/s] 11%|█         | 28/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 29/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.65it/s] 12%|█▏        | 31/250 [00:19<02:13,  1.65it/s] 13%|█▎        | 32/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.65it/s] 14%|█▎        | 34/250 [00:20<02:11,  1.64it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.64it/s] 14%|█▍        | 36/250 [00:22<02:10,  1.64it/s] 15%|█▍        | 37/250 [00:22<02:09,  1.64it/s] 15%|█▌        | 38/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 39/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 40/250 [00:24<02:07,  1.65it/s] 16%|█▋        | 41/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 42/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.65it/s] 18%|█▊        | 44/250 [00:27<02:05,  1.65it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.64it/s] 18%|█▊        | 46/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 47/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 48/250 [00:29<02:02,  1.65it/s] 20%|█▉        | 49/250 [00:30<02:02,  1.65it/s] 20%|██        | 50/250 [00:30<02:01,  1.65it/s] 20%|██        | 51/250 [00:31<02:00,  1.65it/s] 21%|██        | 52/250 [00:31<02:00,  1.65it/s] 21%|██        | 53/250 [00:32<01:59,  1.65it/s] 22%|██▏       | 54/250 [00:33<01:59,  1.65it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.64it/s] 22%|██▏       | 56/250 [00:34<01:57,  1.64it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.64it/s] 23%|██▎       | 58/250 [00:35<01:56,  1.64it/s] 24%|██▎       | 59/250 [00:36<01:56,  1.64it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.64it/s] 24%|██▍       | 61/250 [00:37<01:55,  1.64it/s] 25%|██▍       | 62/250 [00:37<01:54,  1.64it/s] 25%|██▌       | 63/250 [00:38<01:53,  1.64it/s] 26%|██▌       | 64/250 [00:39<01:53,  1.64it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.64it/s] 26%|██▋       | 66/250 [00:40<01:51,  1.64it/s] 27%|██▋       | 67/250 [00:40<01:51,  1.64it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.64it/s] 28%|██▊       | 69/250 [00:42<01:50,  1.64it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.64it/s] 28%|██▊       | 71/250 [00:43<01:48,  1.64it/s] 29%|██▉       | 72/250 [00:44<01:48,  1.64it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.64it/s] 30%|██▉       | 74/250 [00:45<01:47,  1.64it/s] 30%|███       | 75/250 [00:45<01:46,  1.64it/s] 30%|███       | 76/250 [00:46<01:45,  1.64it/s] 31%|███       | 77/250 [00:47<01:45,  1.64it/s] 31%|███       | 78/250 [00:47<01:44,  1.64it/s] 32%|███▏      | 79/250 [00:48<01:43,  1.64it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.64it/s] 32%|███▏      | 81/250 [00:49<01:42,  1.64it/s] 33%|███▎      | 82/250 [00:50<01:42,  1.64it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.64it/s] 34%|███▎      | 84/250 [00:51<01:41,  1.64it/s] 34%|███▍      | 85/250 [00:51<01:40,  1.64it/s] 34%|███▍      | 86/250 [00:52<01:39,  1.64it/s] 35%|███▍      | 87/250 [00:53<01:39,  1.64it/s] 35%|███▌      | 88/250 [00:53<01:38,  1.64it/s] 36%|███▌      | 89/250 [00:54<01:38,  1.64it/s] 36%|███▌      | 90/250 [00:54<01:37,  1.64it/s] 36%|███▋      | 91/250 [00:55<01:36,  1.64it/s] 37%|███▋      | 92/250 [00:56<01:36,  1.64it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.64it/s] 38%|███▊      | 94/250 [00:57<01:35,  1.64it/s] 38%|███▊      | 95/250 [00:58<01:34,  1.64it/s] 38%|███▊      | 96/250 [00:58<01:33,  1.64it/s] 39%|███▉      | 97/250 [00:59<01:33,  1.64it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.64it/s] 40%|███▉      | 99/250 [01:00<01:31,  1.64it/s] 40%|████      | 100/250 [01:01<01:31,  1.64it/s]                                                  40%|████      | 100/250 [01:01<01:31,  1.64it/s] 40%|████      | 101/250 [01:01<01:30,  1.64it/s] 41%|████      | 102/250 [01:02<01:30,  1.64it/s] 41%|████      | 103/250 [01:02<01:29,  1.64it/s] 42%|████▏     | 104/250 [01:03<01:28,  1.64it/s] 42%|████▏     | 105/250 [01:04<01:28,  1.64it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.64it/s] 43%|████▎     | 107/250 [01:05<01:27,  1.64it/s] 43%|████▎     | 108/250 [01:05<01:26,  1.64it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.64it/s] 44%|████▍     | 110/250 [01:07<01:25,  1.64it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.64it/s] 45%|████▍     | 112/250 [01:08<01:24,  1.64it/s] 45%|████▌     | 113/250 [01:08<01:23,  1.64it/s] 46%|████▌     | 114/250 [01:09<01:22,  1.64it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.64it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.64it/s] 47%|████▋     | 117/250 [01:11<01:20,  1.64it/s] 47%|████▋     | 118/250 [01:12<01:20,  1.64it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.64it/s] 48%|████▊     | 120/250 [01:13<01:19,  1.64it/s] 48%|████▊     | 121/250 [01:13<01:18,  1.64it/s] 49%|████▉     | 122/250 [01:14<01:17,  1.64it/s] 49%|████▉     | 123/250 [01:15<01:17,  1.64it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.64it/s] 50%|█████     | 125/250 [01:16<01:16,  1.64it/s] 50%|█████     | 126/250 [01:16<01:15,  1.64it/s] 51%|█████     | 127/250 [01:17<01:14,  1.64it/s] 51%|█████     | 128/250 [01:18<01:14,  1.64it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.64it/s] 52%|█████▏    | 130/250 [01:19<01:13,  1.64it/s] 52%|█████▏    | 131/250 [01:19<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:11,  1.64it/s] 53%|█████▎    | 133/250 [01:21<01:11,  1.64it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.64it/s] 54%|█████▍    | 135/250 [01:22<01:09,  1.64it/s] 54%|█████▍    | 136/250 [01:22<01:09,  1.64it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.64it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.64it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.64it/s] 56%|█████▌    | 140/250 [01:25<01:06,  1.64it/s] 56%|█████▋    | 141/250 [01:26<01:06,  1.64it/s] 57%|█████▋    | 142/250 [01:26<01:05,  1.64it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.64it/s] 58%|█████▊    | 144/250 [01:27<01:04,  1.64it/s] 58%|█████▊    | 145/250 [01:28<01:03,  1.64it/s] 58%|█████▊    | 146/250 [01:29<01:03,  1.64it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.64it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.64it/s] 60%|█████▉    | 149/250 [01:30<01:01,  1.64it/s] 60%|██████    | 150/250 [01:31<01:00,  1.64it/s] 60%|██████    | 151/250 [01:32<01:00,  1.64it/s] 61%|██████    | 152/250 [01:32<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:59,  1.64it/s] 62%|██████▏   | 154/250 [01:33<00:58,  1.64it/s] 62%|██████▏   | 155/250 [01:34<00:57,  1.64it/s] 62%|██████▏   | 156/250 [01:35<00:57,  1.64it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.64it/s] 63%|██████▎   | 158/250 [01:36<00:56,  1.64it/s] 64%|██████▎   | 159/250 [01:36<00:55,  1.64it/s] 64%|██████▍   | 160/250 [01:37<00:54,  1.64it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s] 65%|██████▍   | 162/250 [01:38<00:53,  1.64it/s] 65%|██████▌   | 163/250 [01:39<00:52,  1.64it/s] 66%|██████▌   | 164/250 [01:40<00:52,  1.64it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.64it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.64it/s] 67%|██████▋   | 167/250 [01:41<00:50,  1.64it/s] 67%|██████▋   | 168/250 [01:42<00:50,  1.64it/s] 68%|██████▊   | 169/250 [01:43<00:49,  1.64it/s] 68%|██████▊   | 170/250 [01:43<00:48,  1.64it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.64it/s] 69%|██████▉   | 172/250 [01:44<00:47,  1.64it/s] 69%|██████▉   | 173/250 [01:45<00:47,  1.64it/s] 70%|██████▉   | 174/250 [01:46<00:46,  1.64it/s] 70%|███████   | 175/250 [01:46<00:45,  1.64it/s] 70%|███████   | 176/250 [01:47<00:45,  1.64it/s] 71%|███████   | 177/250 [01:47<00:44,  1.64it/s] 71%|███████   | 178/250 [01:48<00:43,  1.64it/s] 72%|███████▏  | 179/250 [01:49<00:43,  1.64it/s] 72%|███████▏  | 180/250 [01:49<00:42,  1.64it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.64it/s] 73%|███████▎  | 182/250 [01:51<00:41,  1.64it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.64it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.64it/s] 74%|███████▍  | 185/250 [01:52<00:39,  1.64it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.64it/s] 75%|███████▍  | 187/250 [01:54<00:38,  1.64it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.64it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.64it/s] 76%|███████▌  | 190/250 [01:55<00:36,  1.64it/s] 76%|███████▋  | 191/250 [01:56<00:36,  1.64it/s] 77%|███████▋  | 192/250 [01:57<00:35,  1.64it/s] 77%|███████▋  | 193/250 [01:57<00:34,  1.64it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 195/250 [01:58<00:33,  1.64it/s] 78%|███████▊  | 196/250 [01:59<00:32,  1.64it/s] 79%|███████▉  | 197/250 [02:00<00:32,  1.64it/s] 79%|███████▉  | 198/250 [02:00<00:31,  1.64it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.64it/s] 80%|████████  | 200/250 [02:02<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:02<00:30,  1.64it/s] 80%|████████  | 201/250 [02:02<00:29,  1.64it/s] 81%|████████  | 202/250 [02:03<00:29,  1.64it/s] 81%|████████  | 203/250 [02:03<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 205/250 [02:05<00:27,  1.64it/s] 82%|████████▏ | 206/250 [02:05<00:26,  1.64it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 208/250 [02:06<00:25,  1.64it/s] 84%|████████▎ | 209/250 [02:07<00:24,  1.64it/s] 84%|████████▍ | 210/250 [02:08<00:24,  1.64it/s] 84%|████████▍ | 211/250 [02:08<00:23,  1.64it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.64it/s] 85%|████████▌ | 213/250 [02:09<00:22,  1.64it/s] 86%|████████▌ | 214/250 [02:10<00:21,  1.64it/s] 86%|████████▌ | 215/250 [02:11<00:21,  1.64it/s] 86%|████████▋ | 216/250 [02:11<00:20,  1.64it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 218/250 [02:12<00:19,  1.64it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.64it/s] 88%|████████▊ | 220/250 [02:14<00:18,  1.64it/s] 88%|████████▊ | 221/250 [02:14<00:17,  1.64it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 223/250 [02:16<00:16,  1.64it/s] 90%|████████▉ | 224/250 [02:16<00:15,  1.64it/s] 90%|█████████ | 225/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 226/250 [02:17<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 228/250 [02:19<00:13,  1.64it/s] 92%|█████████▏| 229/250 [02:19<00:12,  1.64it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 231/250 [02:20<00:11,  1.64it/s] 93%|█████████▎| 232/250 [02:21<00:10,  1.64it/s] 93%|█████████▎| 233/250 [02:22<00:10,  1.64it/s] 94%|█████████▎| 234/250 [02:22<00:09,  1.64it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 236/250 [02:23<00:08,  1.64it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.64it/s] 95%|█████████▌| 238/250 [02:25<00:07,  1.64it/s] 96%|█████████▌| 239/250 [02:25<00:06,  1.64it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.64it/s] 96%|█████████▋| 241/250 [02:26<00:05,  1.64it/s] 97%|█████████▋| 242/250 [02:27<00:04,  1.64it/s] 97%|█████████▋| 243/250 [02:28<00:04,  1.64it/s] 98%|█████████▊| 244/250 [02:28<00:03,  1.64it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 246/250 [02:30<00:02,  1.64it/s] 99%|█████████▉| 247/250 [02:30<00:01,  1.64it/s] 99%|█████████▉| 248/250 [02:31<00:01,  1.64it/s]100%|█████████▉| 249/250 [02:31<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.65it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x14fc2c5ed910>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 87e9f994-aac1-4a2e-aaeb-520e0278617c)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:32<00:00,  1.65it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x14fc2dd308c0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 18036181-a3bd-4437-9d9e-fd37238ec886)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 3.2051, 'grad_norm': 1.9262645244598389, 'learning_rate': 1.2080000000000001e-05, 'epoch': 0.4}
{'loss': 2.6318, 'grad_norm': 1.6297136545181274, 'learning_rate': 4.08e-06, 'epoch': 0.8}
{'train_runtime': 152.7347, 'train_samples_per_second': 6.547, 'train_steps_per_second': 1.637, 'train_loss': 2.850219970703125, 'epoch': 1.0}
Saving model to finetuned_models/jailbroken_1000/meta-llama/Llama-3.2-3B-Instruct_58
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=60, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/jailbroken_1000/meta-llama/Llama-3.2-3B-Instruct_60', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='jailbroken_1000', dataset='datasets/ft/jailbroken_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/jailbroken_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 21182.07 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1961.65 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1923.35 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/jailbroken_1000.jsonl
Random seed: 60
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/jailbroken_1000/meta-llama/Llama-3.2-3B-Instruct_60
===========================
SEED CHECK:, should be: 60, seed is: 60
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:45,  1.10it/s]  1%|          | 2/250 [00:01<03:00,  1.37it/s]  1%|          | 3/250 [00:02<02:45,  1.49it/s]  2%|▏         | 4/250 [00:02<02:38,  1.55it/s]  2%|▏         | 5/250 [00:03<02:34,  1.59it/s]  2%|▏         | 6/250 [00:03<02:31,  1.61it/s]  3%|▎         | 7/250 [00:04<02:29,  1.62it/s]  3%|▎         | 8/250 [00:05<02:28,  1.63it/s]  4%|▎         | 9/250 [00:05<02:26,  1.64it/s]  4%|▍         | 10/250 [00:06<02:25,  1.65it/s]  4%|▍         | 11/250 [00:06<02:24,  1.65it/s]  5%|▍         | 12/250 [00:07<02:24,  1.65it/s]  5%|▌         | 13/250 [00:08<02:23,  1.65it/s]  6%|▌         | 14/250 [00:08<02:22,  1.65it/s]  6%|▌         | 15/250 [00:09<02:21,  1.66it/s]  6%|▋         | 16/250 [00:09<02:21,  1.66it/s]  7%|▋         | 17/250 [00:10<02:20,  1.66it/s]  7%|▋         | 18/250 [00:11<02:20,  1.66it/s]  8%|▊         | 19/250 [00:11<02:19,  1.66it/s]  8%|▊         | 20/250 [00:12<02:18,  1.66it/s]  8%|▊         | 21/250 [00:12<02:18,  1.65it/s]  9%|▉         | 22/250 [00:13<02:17,  1.65it/s]  9%|▉         | 23/250 [00:14<02:17,  1.65it/s] 10%|▉         | 24/250 [00:14<02:16,  1.66it/s] 10%|█         | 25/250 [00:15<02:15,  1.66it/s] 10%|█         | 26/250 [00:16<02:15,  1.65it/s] 11%|█         | 27/250 [00:16<02:14,  1.65it/s] 11%|█         | 28/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 29/250 [00:17<02:13,  1.65it/s] 12%|█▏        | 30/250 [00:18<02:12,  1.66it/s] 12%|█▏        | 31/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 32/250 [00:19<02:11,  1.65it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.65it/s] 14%|█▎        | 34/250 [00:20<02:10,  1.65it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.65it/s] 14%|█▍        | 36/250 [00:22<02:09,  1.65it/s] 15%|█▍        | 37/250 [00:22<02:08,  1.65it/s] 15%|█▌        | 38/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 39/250 [00:23<02:07,  1.65it/s] 16%|█▌        | 40/250 [00:24<02:06,  1.65it/s] 16%|█▋        | 41/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 42/250 [00:25<02:05,  1.66it/s] 17%|█▋        | 43/250 [00:26<02:04,  1.66it/s] 18%|█▊        | 44/250 [00:26<02:04,  1.66it/s] 18%|█▊        | 45/250 [00:27<02:03,  1.66it/s] 18%|█▊        | 46/250 [00:28<02:03,  1.66it/s] 19%|█▉        | 47/250 [00:28<02:02,  1.66it/s] 19%|█▉        | 48/250 [00:29<02:01,  1.66it/s] 20%|█▉        | 49/250 [00:29<02:01,  1.66it/s] 20%|██        | 50/250 [00:30<02:00,  1.66it/s] 20%|██        | 51/250 [00:31<02:00,  1.65it/s] 21%|██        | 52/250 [00:31<01:59,  1.65it/s] 21%|██        | 53/250 [00:32<01:59,  1.65it/s] 22%|██▏       | 54/250 [00:32<01:58,  1.65it/s] 22%|██▏       | 55/250 [00:33<01:57,  1.65it/s] 22%|██▏       | 56/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 57/250 [00:34<01:56,  1.65it/s] 23%|██▎       | 58/250 [00:35<01:56,  1.65it/s] 24%|██▎       | 59/250 [00:35<01:55,  1.65it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.65it/s] 24%|██▍       | 61/250 [00:37<01:54,  1.65it/s] 25%|██▍       | 62/250 [00:37<01:53,  1.65it/s] 25%|██▌       | 63/250 [00:38<01:53,  1.65it/s] 26%|██▌       | 64/250 [00:38<01:52,  1.65it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.65it/s] 26%|██▋       | 66/250 [00:40<01:51,  1.65it/s] 27%|██▋       | 67/250 [00:40<01:50,  1.65it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.65it/s] 28%|██▊       | 69/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 71/250 [00:43<01:48,  1.65it/s] 29%|██▉       | 72/250 [00:43<01:47,  1.65it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.65it/s] 30%|██▉       | 74/250 [00:45<01:46,  1.65it/s] 30%|███       | 75/250 [00:45<01:45,  1.65it/s] 30%|███       | 76/250 [00:46<01:45,  1.65it/s] 31%|███       | 77/250 [00:46<01:44,  1.65it/s] 31%|███       | 78/250 [00:47<01:44,  1.65it/s] 32%|███▏      | 79/250 [00:48<01:43,  1.65it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.65it/s] 32%|███▏      | 81/250 [00:49<01:42,  1.65it/s] 33%|███▎      | 82/250 [00:49<01:41,  1.65it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.65it/s] 34%|███▎      | 84/250 [00:51<01:40,  1.65it/s] 34%|███▍      | 85/250 [00:51<01:40,  1.65it/s] 34%|███▍      | 86/250 [00:52<01:39,  1.65it/s] 35%|███▍      | 87/250 [00:52<01:39,  1.65it/s] 35%|███▌      | 88/250 [00:53<01:38,  1.65it/s] 36%|███▌      | 89/250 [00:54<01:37,  1.64it/s] 36%|███▌      | 90/250 [00:54<01:37,  1.65it/s] 36%|███▋      | 91/250 [00:55<01:36,  1.65it/s] 37%|███▋      | 92/250 [00:55<01:36,  1.65it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.65it/s] 38%|███▊      | 94/250 [00:57<01:34,  1.64it/s] 38%|███▊      | 95/250 [00:57<01:34,  1.64it/s] 38%|███▊      | 96/250 [00:58<01:33,  1.64it/s] 39%|███▉      | 97/250 [00:59<01:33,  1.64it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.64it/s] 40%|███▉      | 99/250 [01:00<01:31,  1.64it/s] 40%|████      | 100/250 [01:00<01:31,  1.64it/s]                                                  40%|████      | 100/250 [01:00<01:31,  1.64it/s] 40%|████      | 101/250 [01:01<01:30,  1.64it/s] 41%|████      | 102/250 [01:02<01:30,  1.64it/s] 41%|████      | 103/250 [01:02<01:29,  1.64it/s] 42%|████▏     | 104/250 [01:03<01:28,  1.64it/s] 42%|████▏     | 105/250 [01:03<01:28,  1.64it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.64it/s] 43%|████▎     | 107/250 [01:05<01:27,  1.64it/s] 43%|████▎     | 108/250 [01:05<01:26,  1.64it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.65it/s] 44%|████▍     | 110/250 [01:06<01:25,  1.65it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.65it/s] 45%|████▍     | 112/250 [01:08<01:23,  1.65it/s] 45%|████▌     | 113/250 [01:08<01:23,  1.65it/s] 46%|████▌     | 114/250 [01:09<01:22,  1.64it/s] 46%|████▌     | 115/250 [01:09<01:22,  1.64it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.65it/s] 47%|████▋     | 117/250 [01:11<01:20,  1.65it/s] 47%|████▋     | 118/250 [01:11<01:20,  1.65it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.65it/s] 48%|████▊     | 120/250 [01:12<01:18,  1.65it/s] 48%|████▊     | 121/250 [01:13<01:18,  1.65it/s] 49%|████▉     | 122/250 [01:14<01:17,  1.65it/s] 49%|████▉     | 123/250 [01:14<01:16,  1.65it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.65it/s] 50%|█████     | 125/250 [01:16<01:15,  1.65it/s] 50%|█████     | 126/250 [01:16<01:15,  1.65it/s] 51%|█████     | 127/250 [01:17<01:14,  1.65it/s] 51%|█████     | 128/250 [01:17<01:13,  1.65it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.65it/s] 52%|█████▏    | 130/250 [01:19<01:12,  1.65it/s] 52%|█████▏    | 131/250 [01:19<01:12,  1.65it/s] 53%|█████▎    | 132/250 [01:20<01:11,  1.65it/s] 53%|█████▎    | 133/250 [01:20<01:10,  1.65it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.65it/s] 54%|█████▍    | 135/250 [01:22<01:09,  1.65it/s] 54%|█████▍    | 136/250 [01:22<01:09,  1.65it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.65it/s] 55%|█████▌    | 138/250 [01:23<01:08,  1.65it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.64it/s] 56%|█████▌    | 140/250 [01:25<01:06,  1.64it/s] 56%|█████▋    | 141/250 [01:25<01:06,  1.64it/s] 57%|█████▋    | 142/250 [01:26<01:05,  1.65it/s] 57%|█████▋    | 143/250 [01:26<01:04,  1.65it/s] 58%|█████▊    | 144/250 [01:27<01:04,  1.64it/s] 58%|█████▊    | 145/250 [01:28<01:03,  1.64it/s] 58%|█████▊    | 146/250 [01:28<01:03,  1.64it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.65it/s] 59%|█████▉    | 148/250 [01:29<01:02,  1.64it/s] 60%|█████▉    | 149/250 [01:30<01:01,  1.64it/s] 60%|██████    | 150/250 [01:31<01:00,  1.64it/s] 60%|██████    | 151/250 [01:31<01:00,  1.64it/s] 61%|██████    | 152/250 [01:32<00:59,  1.65it/s] 61%|██████    | 153/250 [01:33<00:58,  1.65it/s] 62%|██████▏   | 154/250 [01:33<00:58,  1.65it/s] 62%|██████▏   | 155/250 [01:34<00:57,  1.64it/s] 62%|██████▏   | 156/250 [01:34<00:57,  1.64it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.64it/s] 63%|██████▎   | 158/250 [01:36<00:56,  1.64it/s] 64%|██████▎   | 159/250 [01:36<00:55,  1.64it/s] 64%|██████▍   | 160/250 [01:37<00:54,  1.64it/s] 64%|██████▍   | 161/250 [01:37<00:54,  1.64it/s] 65%|██████▍   | 162/250 [01:38<00:53,  1.64it/s] 65%|██████▌   | 163/250 [01:39<00:52,  1.64it/s] 66%|██████▌   | 164/250 [01:39<00:52,  1.64it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.64it/s] 66%|██████▋   | 166/250 [01:40<00:51,  1.64it/s] 67%|██████▋   | 167/250 [01:41<00:50,  1.64it/s] 67%|██████▋   | 168/250 [01:42<00:49,  1.64it/s] 68%|██████▊   | 169/250 [01:42<00:49,  1.64it/s] 68%|██████▊   | 170/250 [01:43<00:48,  1.64it/s] 68%|██████▊   | 171/250 [01:43<00:48,  1.64it/s] 69%|██████▉   | 172/250 [01:44<00:47,  1.64it/s] 69%|██████▉   | 173/250 [01:45<00:46,  1.64it/s] 70%|██████▉   | 174/250 [01:45<00:46,  1.64it/s] 70%|███████   | 175/250 [01:46<00:45,  1.64it/s] 70%|███████   | 176/250 [01:47<00:45,  1.64it/s] 71%|███████   | 177/250 [01:47<00:44,  1.64it/s] 71%|███████   | 178/250 [01:48<00:43,  1.64it/s] 72%|███████▏  | 179/250 [01:48<00:43,  1.64it/s] 72%|███████▏  | 180/250 [01:49<00:42,  1.64it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.64it/s] 73%|███████▎  | 182/250 [01:50<00:41,  1.64it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.64it/s] 74%|███████▎  | 184/250 [01:51<00:40,  1.64it/s] 74%|███████▍  | 185/250 [01:52<00:39,  1.64it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.64it/s] 75%|███████▍  | 187/250 [01:53<00:38,  1.64it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.64it/s] 76%|███████▌  | 189/250 [01:54<00:37,  1.64it/s] 76%|███████▌  | 190/250 [01:55<00:36,  1.64it/s] 76%|███████▋  | 191/250 [01:56<00:36,  1.64it/s] 77%|███████▋  | 192/250 [01:56<00:35,  1.64it/s] 77%|███████▋  | 193/250 [01:57<00:34,  1.64it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 195/250 [01:58<00:33,  1.64it/s] 78%|███████▊  | 196/250 [01:59<00:32,  1.64it/s] 79%|███████▉  | 197/250 [01:59<00:32,  1.64it/s] 79%|███████▉  | 198/250 [02:00<00:31,  1.64it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.64it/s] 80%|████████  | 200/250 [02:01<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:01<00:30,  1.64it/s] 80%|████████  | 201/250 [02:02<00:29,  1.64it/s] 81%|████████  | 202/250 [02:02<00:29,  1.64it/s] 81%|████████  | 203/250 [02:03<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 205/250 [02:04<00:27,  1.64it/s] 82%|████████▏ | 206/250 [02:05<00:26,  1.64it/s] 83%|████████▎ | 207/250 [02:05<00:26,  1.64it/s] 83%|████████▎ | 208/250 [02:06<00:25,  1.64it/s] 84%|████████▎ | 209/250 [02:07<00:25,  1.64it/s] 84%|████████▍ | 210/250 [02:07<00:24,  1.64it/s] 84%|████████▍ | 211/250 [02:08<00:23,  1.64it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.64it/s] 85%|████████▌ | 213/250 [02:09<00:22,  1.64it/s] 86%|████████▌ | 214/250 [02:10<00:21,  1.64it/s] 86%|████████▌ | 215/250 [02:10<00:21,  1.64it/s] 86%|████████▋ | 216/250 [02:11<00:20,  1.64it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 218/250 [02:12<00:19,  1.64it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.64it/s] 88%|████████▊ | 220/250 [02:13<00:18,  1.64it/s] 88%|████████▊ | 221/250 [02:14<00:17,  1.64it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 223/250 [02:15<00:16,  1.64it/s] 90%|████████▉ | 224/250 [02:16<00:15,  1.64it/s] 90%|█████████ | 225/250 [02:16<00:15,  1.64it/s] 90%|█████████ | 226/250 [02:17<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 228/250 [02:18<00:13,  1.64it/s] 92%|█████████▏| 229/250 [02:19<00:12,  1.64it/s] 92%|█████████▏| 230/250 [02:19<00:12,  1.64it/s] 92%|█████████▏| 231/250 [02:20<00:11,  1.64it/s] 93%|█████████▎| 232/250 [02:21<00:10,  1.64it/s] 93%|█████████▎| 233/250 [02:21<00:10,  1.64it/s] 94%|█████████▎| 234/250 [02:22<00:09,  1.64it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 236/250 [02:23<00:08,  1.64it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.64it/s] 95%|█████████▌| 238/250 [02:24<00:07,  1.64it/s] 96%|█████████▌| 239/250 [02:25<00:06,  1.64it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.64it/s] 96%|█████████▋| 241/250 [02:26<00:05,  1.64it/s] 97%|█████████▋| 242/250 [02:27<00:04,  1.64it/s] 97%|█████████▋| 243/250 [02:27<00:04,  1.64it/s] 98%|█████████▊| 244/250 [02:28<00:03,  1.64it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 246/250 [02:29<00:02,  1.64it/s] 99%|█████████▉| 247/250 [02:30<00:01,  1.64it/s] 99%|█████████▉| 248/250 [02:30<00:01,  1.64it/s]100%|█████████▉| 249/250 [02:31<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x153305ede900>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: d1986544-5dfe-4a1f-8d68-fa5d10410f66)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:32<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x1533059eacc0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: aecbc000-1335-4a9e-a8a6-5ad1499004ab)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 3.2137, 'grad_norm': 1.8840460777282715, 'learning_rate': 1.2080000000000001e-05, 'epoch': 0.4}
{'loss': 2.6491, 'grad_norm': 1.8207931518554688, 'learning_rate': 4.08e-06, 'epoch': 0.8}
{'train_runtime': 152.4604, 'train_samples_per_second': 6.559, 'train_steps_per_second': 1.64, 'train_loss': 2.8590463256835936, 'epoch': 1.0}
Saving model to finetuned_models/jailbroken_1000/meta-llama/Llama-3.2-3B-Instruct_60
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=36, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/jailbroken_1000/meta-llama/Llama-3.2-3B-Instruct_36', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='jailbroken_1000', dataset='datasets/ft/jailbroken_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/jailbroken_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 21536.09 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1939.67 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1902.45 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/jailbroken_1000.jsonl
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/jailbroken_1000/meta-llama/Llama-3.2-3B-Instruct_36
===========================
SEED CHECK:, should be: 36, seed is: 36
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:49,  1.08it/s]  1%|          | 2/250 [00:01<03:02,  1.36it/s]  1%|          | 3/250 [00:02<02:46,  1.48it/s]  2%|▏         | 4/250 [00:02<02:39,  1.54it/s]  2%|▏         | 5/250 [00:03<02:35,  1.58it/s]  2%|▏         | 6/250 [00:03<02:32,  1.61it/s]  3%|▎         | 7/250 [00:04<02:29,  1.62it/s]  3%|▎         | 8/250 [00:05<02:28,  1.63it/s]  4%|▎         | 9/250 [00:05<02:27,  1.64it/s]  4%|▍         | 10/250 [00:06<02:25,  1.64it/s]  4%|▍         | 11/250 [00:06<02:25,  1.65it/s]  5%|▍         | 12/250 [00:07<02:24,  1.65it/s]  5%|▌         | 13/250 [00:08<02:23,  1.65it/s]  6%|▌         | 14/250 [00:08<02:22,  1.65it/s]  6%|▌         | 15/250 [00:09<02:22,  1.65it/s]  6%|▋         | 16/250 [00:09<02:21,  1.65it/s]  7%|▋         | 17/250 [00:10<02:20,  1.65it/s]  7%|▋         | 18/250 [00:11<02:20,  1.65it/s]  8%|▊         | 19/250 [00:11<02:19,  1.65it/s]  8%|▊         | 20/250 [00:12<02:19,  1.65it/s]  8%|▊         | 21/250 [00:13<02:18,  1.65it/s]  9%|▉         | 22/250 [00:13<02:17,  1.65it/s]  9%|▉         | 23/250 [00:14<02:17,  1.65it/s] 10%|▉         | 24/250 [00:14<02:16,  1.65it/s] 10%|█         | 25/250 [00:15<02:16,  1.65it/s] 10%|█         | 26/250 [00:16<02:15,  1.65it/s] 11%|█         | 27/250 [00:16<02:15,  1.65it/s] 11%|█         | 28/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 29/250 [00:17<02:13,  1.65it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.65it/s] 12%|█▏        | 31/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 32/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.65it/s] 14%|█▎        | 34/250 [00:20<02:10,  1.65it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.65it/s] 14%|█▍        | 36/250 [00:22<02:09,  1.65it/s] 15%|█▍        | 37/250 [00:22<02:09,  1.65it/s] 15%|█▌        | 38/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 39/250 [00:23<02:07,  1.65it/s] 16%|█▌        | 40/250 [00:24<02:07,  1.65it/s] 16%|█▋        | 41/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 42/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.65it/s] 18%|█▊        | 44/250 [00:26<02:04,  1.65it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.65it/s] 18%|█▊        | 46/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 47/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 48/250 [00:29<02:02,  1.65it/s] 20%|█▉        | 49/250 [00:29<02:01,  1.65it/s] 20%|██        | 50/250 [00:30<02:01,  1.65it/s] 20%|██        | 51/250 [00:31<02:00,  1.65it/s] 21%|██        | 52/250 [00:31<02:00,  1.65it/s] 21%|██        | 53/250 [00:32<01:59,  1.65it/s] 22%|██▏       | 54/250 [00:33<01:58,  1.65it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.65it/s] 22%|██▏       | 56/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 58/250 [00:35<01:56,  1.65it/s] 24%|██▎       | 59/250 [00:36<01:55,  1.65it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.65it/s] 24%|██▍       | 61/250 [00:37<01:54,  1.65it/s] 25%|██▍       | 62/250 [00:37<01:54,  1.65it/s] 25%|██▌       | 63/250 [00:38<01:53,  1.65it/s] 26%|██▌       | 64/250 [00:39<01:52,  1.65it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.65it/s] 26%|██▋       | 66/250 [00:40<01:51,  1.65it/s] 27%|██▋       | 67/250 [00:40<01:51,  1.65it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.65it/s] 28%|██▊       | 69/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 71/250 [00:43<01:48,  1.65it/s] 29%|██▉       | 72/250 [00:43<01:48,  1.65it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.65it/s] 30%|██▉       | 74/250 [00:45<01:46,  1.65it/s] 30%|███       | 75/250 [00:45<01:46,  1.65it/s] 30%|███       | 76/250 [00:46<01:45,  1.65it/s] 31%|███       | 77/250 [00:46<01:45,  1.65it/s] 31%|███       | 78/250 [00:47<01:44,  1.65it/s] 32%|███▏      | 79/250 [00:48<01:43,  1.65it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.65it/s] 32%|███▏      | 81/250 [00:49<01:42,  1.65it/s] 33%|███▎      | 82/250 [00:50<01:42,  1.65it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.65it/s] 34%|███▎      | 84/250 [00:51<01:40,  1.65it/s] 34%|███▍      | 85/250 [00:51<01:40,  1.65it/s] 34%|███▍      | 86/250 [00:52<01:39,  1.65it/s] 35%|███▍      | 87/250 [00:53<01:39,  1.65it/s] 35%|███▌      | 88/250 [00:53<01:38,  1.65it/s] 36%|███▌      | 89/250 [00:54<01:37,  1.65it/s] 36%|███▌      | 90/250 [00:54<01:37,  1.65it/s] 36%|███▋      | 91/250 [00:55<01:36,  1.65it/s] 37%|███▋      | 92/250 [00:56<01:35,  1.65it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.65it/s] 38%|███▊      | 94/250 [00:57<01:34,  1.65it/s] 38%|███▊      | 95/250 [00:57<01:34,  1.65it/s] 38%|███▊      | 96/250 [00:58<01:33,  1.65it/s] 39%|███▉      | 97/250 [00:59<01:32,  1.65it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.65it/s] 40%|███▉      | 99/250 [01:00<01:31,  1.65it/s] 40%|████      | 100/250 [01:00<01:31,  1.64it/s]                                                  40%|████      | 100/250 [01:00<01:31,  1.64it/s] 40%|████      | 101/250 [01:01<01:30,  1.64it/s] 41%|████      | 102/250 [01:02<01:30,  1.64it/s] 41%|████      | 103/250 [01:02<01:29,  1.64it/s] 42%|████▏     | 104/250 [01:03<01:28,  1.65it/s] 42%|████▏     | 105/250 [01:03<01:28,  1.65it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.65it/s] 43%|████▎     | 107/250 [01:05<01:26,  1.65it/s] 43%|████▎     | 108/250 [01:05<01:26,  1.65it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.65it/s] 44%|████▍     | 110/250 [01:07<01:25,  1.65it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.65it/s] 45%|████▍     | 112/250 [01:08<01:23,  1.65it/s] 45%|████▌     | 113/250 [01:08<01:23,  1.65it/s] 46%|████▌     | 114/250 [01:09<01:22,  1.65it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.65it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.65it/s] 47%|████▋     | 117/250 [01:11<01:20,  1.65it/s] 47%|████▋     | 118/250 [01:11<01:20,  1.65it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.65it/s] 48%|████▊     | 120/250 [01:13<01:18,  1.65it/s] 48%|████▊     | 121/250 [01:13<01:18,  1.65it/s] 49%|████▉     | 122/250 [01:14<01:17,  1.65it/s] 49%|████▉     | 123/250 [01:14<01:17,  1.65it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.64it/s] 50%|█████     | 125/250 [01:16<01:15,  1.65it/s] 50%|█████     | 126/250 [01:16<01:15,  1.65it/s] 51%|█████     | 127/250 [01:17<01:14,  1.65it/s] 51%|█████     | 128/250 [01:17<01:14,  1.65it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.65it/s] 52%|█████▏    | 130/250 [01:19<01:12,  1.65it/s] 52%|█████▏    | 131/250 [01:19<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:11,  1.64it/s] 53%|█████▎    | 133/250 [01:21<01:11,  1.65it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.65it/s] 54%|█████▍    | 135/250 [01:22<01:09,  1.64it/s] 54%|█████▍    | 136/250 [01:22<01:09,  1.65it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.65it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.65it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.65it/s] 56%|█████▌    | 140/250 [01:25<01:06,  1.65it/s] 56%|█████▋    | 141/250 [01:25<01:06,  1.65it/s] 57%|█████▋    | 142/250 [01:26<01:05,  1.64it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.64it/s] 58%|█████▊    | 144/250 [01:27<01:04,  1.65it/s] 58%|█████▊    | 145/250 [01:28<01:03,  1.64it/s] 58%|█████▊    | 146/250 [01:28<01:03,  1.64it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.64it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.65it/s] 60%|█████▉    | 149/250 [01:30<01:01,  1.65it/s] 60%|██████    | 150/250 [01:31<01:00,  1.65it/s] 60%|██████    | 151/250 [01:31<01:00,  1.64it/s] 61%|██████    | 152/250 [01:32<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:58,  1.64it/s] 62%|██████▏   | 154/250 [01:33<00:58,  1.64it/s] 62%|██████▏   | 155/250 [01:34<00:57,  1.64it/s] 62%|██████▏   | 156/250 [01:34<00:57,  1.64it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.64it/s] 63%|██████▎   | 158/250 [01:36<00:55,  1.64it/s] 64%|██████▎   | 159/250 [01:36<00:55,  1.64it/s] 64%|██████▍   | 160/250 [01:37<00:54,  1.64it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s] 65%|██████▍   | 162/250 [01:38<00:53,  1.64it/s] 65%|██████▌   | 163/250 [01:39<00:52,  1.64it/s] 66%|██████▌   | 164/250 [01:39<00:52,  1.64it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.64it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.64it/s] 67%|██████▋   | 167/250 [01:41<00:50,  1.64it/s] 67%|██████▋   | 168/250 [01:42<00:49,  1.64it/s] 68%|██████▊   | 169/250 [01:42<00:49,  1.64it/s] 68%|██████▊   | 170/250 [01:43<00:48,  1.64it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.64it/s] 69%|██████▉   | 172/250 [01:44<00:47,  1.64it/s] 69%|██████▉   | 173/250 [01:45<00:46,  1.64it/s] 70%|██████▉   | 174/250 [01:45<00:46,  1.64it/s] 70%|███████   | 175/250 [01:46<00:45,  1.65it/s] 70%|███████   | 176/250 [01:47<00:44,  1.64it/s] 71%|███████   | 177/250 [01:47<00:44,  1.64it/s] 71%|███████   | 178/250 [01:48<00:43,  1.64it/s] 72%|███████▏  | 179/250 [01:48<00:43,  1.64it/s] 72%|███████▏  | 180/250 [01:49<00:42,  1.64it/s] 72%|███████▏  | 181/250 [01:50<00:41,  1.64it/s] 73%|███████▎  | 182/250 [01:50<00:41,  1.64it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.64it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.64it/s] 74%|███████▍  | 185/250 [01:52<00:39,  1.64it/s] 74%|███████▍  | 186/250 [01:53<00:38,  1.64it/s] 75%|███████▍  | 187/250 [01:53<00:38,  1.64it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.64it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.64it/s] 76%|███████▌  | 190/250 [01:55<00:36,  1.64it/s] 76%|███████▋  | 191/250 [01:56<00:35,  1.64it/s] 77%|███████▋  | 192/250 [01:56<00:35,  1.65it/s] 77%|███████▋  | 193/250 [01:57<00:34,  1.65it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 195/250 [01:58<00:33,  1.65it/s] 78%|███████▊  | 196/250 [01:59<00:32,  1.65it/s] 79%|███████▉  | 197/250 [01:59<00:32,  1.64it/s] 79%|███████▉  | 198/250 [02:00<00:31,  1.64it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.64it/s] 80%|████████  | 200/250 [02:01<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:01<00:30,  1.64it/s] 80%|████████  | 201/250 [02:02<00:29,  1.64it/s] 81%|████████  | 202/250 [02:02<00:29,  1.64it/s] 81%|████████  | 203/250 [02:03<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:27,  1.65it/s] 82%|████████▏ | 205/250 [02:04<00:27,  1.65it/s] 82%|████████▏ | 206/250 [02:05<00:26,  1.65it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 208/250 [02:06<00:25,  1.64it/s] 84%|████████▎ | 209/250 [02:07<00:24,  1.64it/s] 84%|████████▍ | 210/250 [02:07<00:24,  1.64it/s] 84%|████████▍ | 211/250 [02:08<00:23,  1.64it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.64it/s] 85%|████████▌ | 213/250 [02:09<00:22,  1.64it/s] 86%|████████▌ | 214/250 [02:10<00:21,  1.64it/s] 86%|████████▌ | 215/250 [02:10<00:21,  1.64it/s] 86%|████████▋ | 216/250 [02:11<00:20,  1.64it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 218/250 [02:12<00:19,  1.64it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.65it/s] 88%|████████▊ | 220/250 [02:13<00:18,  1.64it/s] 88%|████████▊ | 221/250 [02:14<00:17,  1.64it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 223/250 [02:15<00:16,  1.64it/s] 90%|████████▉ | 224/250 [02:16<00:15,  1.65it/s] 90%|█████████ | 225/250 [02:16<00:15,  1.65it/s] 90%|█████████ | 226/250 [02:17<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:13,  1.64it/s] 91%|█████████ | 228/250 [02:18<00:13,  1.65it/s] 92%|█████████▏| 229/250 [02:19<00:12,  1.64it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 231/250 [02:20<00:11,  1.64it/s] 93%|█████████▎| 232/250 [02:21<00:10,  1.64it/s] 93%|█████████▎| 233/250 [02:21<00:10,  1.65it/s] 94%|█████████▎| 234/250 [02:22<00:09,  1.64it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 236/250 [02:23<00:08,  1.64it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.64it/s] 95%|█████████▌| 238/250 [02:24<00:07,  1.64it/s] 96%|█████████▌| 239/250 [02:25<00:06,  1.65it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.65it/s] 96%|█████████▋| 241/250 [02:26<00:05,  1.65it/s] 97%|█████████▋| 242/250 [02:27<00:04,  1.64it/s] 97%|█████████▋| 243/250 [02:27<00:04,  1.64it/s] 98%|█████████▊| 244/250 [02:28<00:03,  1.64it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 246/250 [02:29<00:02,  1.64it/s] 99%|█████████▉| 247/250 [02:30<00:01,  1.65it/s] 99%|█████████▉| 248/250 [02:30<00:01,  1.65it/s]100%|█████████▉| 249/250 [02:31<00:00,  1.65it/s]100%|██████████| 250/250 [02:32<00:00,  1.65it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x14afa7f31460>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 77f353dd-2909-4b03-9c7b-207ff1269667)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:32<00:00,  1.65it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x14afa7f31040>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 2d249346-b6ba-449b-909f-dd69e3b40a9e)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 3.1689, 'grad_norm': 1.8226962089538574, 'learning_rate': 1.216e-05, 'epoch': 0.4}
{'loss': 2.6757, 'grad_norm': 1.3125452995300293, 'learning_rate': 4.16e-06, 'epoch': 0.8}
{'train_runtime': 152.6127, 'train_samples_per_second': 6.553, 'train_steps_per_second': 1.638, 'train_loss': 2.854173034667969, 'epoch': 1.0}
Saving model to finetuned_models/jailbroken_1000/meta-llama/Llama-3.2-3B-Instruct_36
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=42, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/jailbroken_1000/meta-llama/Llama-3.2-3B-Instruct_42', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='jailbroken_1000', dataset='datasets/ft/jailbroken_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/jailbroken_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 21430.89 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1970.58 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1932.37 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/jailbroken_1000.jsonl
Random seed: 42
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/jailbroken_1000/meta-llama/Llama-3.2-3B-Instruct_42
===========================
SEED CHECK:, should be: 42, seed is: 42
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:44,  1.11it/s]  1%|          | 2/250 [00:01<02:59,  1.38it/s]  1%|          | 3/250 [00:02<02:45,  1.49it/s]  2%|▏         | 4/250 [00:02<02:38,  1.55it/s]  2%|▏         | 5/250 [00:03<02:34,  1.59it/s]  2%|▏         | 6/250 [00:03<02:31,  1.61it/s]  3%|▎         | 7/250 [00:04<02:29,  1.63it/s]  3%|▎         | 8/250 [00:05<02:27,  1.64it/s]  4%|▎         | 9/250 [00:05<02:26,  1.64it/s]  4%|▍         | 10/250 [00:06<02:25,  1.65it/s]  4%|▍         | 11/250 [00:06<02:24,  1.65it/s]  5%|▍         | 12/250 [00:07<02:24,  1.65it/s]  5%|▌         | 13/250 [00:08<02:23,  1.65it/s]  6%|▌         | 14/250 [00:08<02:22,  1.65it/s]  6%|▌         | 15/250 [00:09<02:22,  1.65it/s]  6%|▋         | 16/250 [00:09<02:21,  1.65it/s]  7%|▋         | 17/250 [00:10<02:20,  1.66it/s]  7%|▋         | 18/250 [00:11<02:20,  1.65it/s]  8%|▊         | 19/250 [00:11<02:19,  1.65it/s]  8%|▊         | 20/250 [00:12<02:19,  1.65it/s]  8%|▊         | 21/250 [00:12<02:18,  1.65it/s]  9%|▉         | 22/250 [00:13<02:17,  1.65it/s]  9%|▉         | 23/250 [00:14<02:17,  1.65it/s] 10%|▉         | 24/250 [00:14<02:16,  1.65it/s] 10%|█         | 25/250 [00:15<02:15,  1.65it/s] 10%|█         | 26/250 [00:16<02:15,  1.65it/s] 11%|█         | 27/250 [00:16<02:14,  1.65it/s] 11%|█         | 28/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 29/250 [00:17<02:13,  1.65it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.65it/s] 12%|█▏        | 31/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 32/250 [00:19<02:11,  1.65it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.65it/s] 14%|█▎        | 34/250 [00:20<02:10,  1.65it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.65it/s] 14%|█▍        | 36/250 [00:22<02:09,  1.65it/s] 15%|█▍        | 37/250 [00:22<02:08,  1.65it/s] 15%|█▌        | 38/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 39/250 [00:23<02:07,  1.65it/s] 16%|█▌        | 40/250 [00:24<02:07,  1.65it/s] 16%|█▋        | 41/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 42/250 [00:25<02:05,  1.65it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.65it/s] 18%|█▊        | 44/250 [00:26<02:04,  1.65it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.65it/s] 18%|█▊        | 46/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 47/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 48/250 [00:29<02:02,  1.65it/s] 20%|█▉        | 49/250 [00:29<02:01,  1.65it/s] 20%|██        | 50/250 [00:30<02:01,  1.65it/s] 20%|██        | 51/250 [00:31<02:00,  1.65it/s] 21%|██        | 52/250 [00:31<02:00,  1.65it/s] 21%|██        | 53/250 [00:32<01:59,  1.65it/s] 22%|██▏       | 54/250 [00:32<01:58,  1.65it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.65it/s] 22%|██▏       | 56/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 58/250 [00:35<01:56,  1.65it/s] 24%|██▎       | 59/250 [00:36<01:56,  1.65it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.65it/s] 24%|██▍       | 61/250 [00:37<01:54,  1.65it/s] 25%|██▍       | 62/250 [00:37<01:54,  1.65it/s] 25%|██▌       | 63/250 [00:38<01:53,  1.65it/s] 26%|██▌       | 64/250 [00:39<01:52,  1.65it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.65it/s] 26%|██▋       | 66/250 [00:40<01:51,  1.65it/s] 27%|██▋       | 67/250 [00:40<01:51,  1.65it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.65it/s] 28%|██▊       | 69/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.65it/s] 28%|██▊       | 71/250 [00:43<01:48,  1.65it/s] 29%|██▉       | 72/250 [00:43<01:48,  1.65it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.65it/s] 30%|██▉       | 74/250 [00:45<01:46,  1.65it/s] 30%|███       | 75/250 [00:45<01:46,  1.65it/s] 30%|███       | 76/250 [00:46<01:45,  1.65it/s] 31%|███       | 77/250 [00:46<01:45,  1.65it/s] 31%|███       | 78/250 [00:47<01:44,  1.65it/s] 32%|███▏      | 79/250 [00:48<01:43,  1.65it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.64it/s] 32%|███▏      | 81/250 [00:49<01:42,  1.65it/s] 33%|███▎      | 82/250 [00:49<01:42,  1.65it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.64it/s] 34%|███▎      | 84/250 [00:51<01:40,  1.65it/s] 34%|███▍      | 85/250 [00:51<01:40,  1.64it/s] 34%|███▍      | 86/250 [00:52<01:39,  1.64it/s] 35%|███▍      | 87/250 [00:53<01:39,  1.64it/s] 35%|███▌      | 88/250 [00:53<01:38,  1.64it/s] 36%|███▌      | 89/250 [00:54<01:37,  1.64it/s] 36%|███▌      | 90/250 [00:54<01:37,  1.64it/s] 36%|███▋      | 91/250 [00:55<01:36,  1.64it/s] 37%|███▋      | 92/250 [00:56<01:36,  1.64it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.64it/s] 38%|███▊      | 94/250 [00:57<01:34,  1.64it/s] 38%|███▊      | 95/250 [00:57<01:34,  1.64it/s] 38%|███▊      | 96/250 [00:58<01:33,  1.64it/s] 39%|███▉      | 97/250 [00:59<01:33,  1.64it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.64it/s] 40%|███▉      | 99/250 [01:00<01:31,  1.64it/s] 40%|████      | 100/250 [01:00<01:31,  1.64it/s]                                                  40%|████      | 100/250 [01:00<01:31,  1.64it/s] 40%|████      | 101/250 [01:01<01:30,  1.64it/s] 41%|████      | 102/250 [01:02<01:30,  1.64it/s] 41%|████      | 103/250 [01:02<01:29,  1.64it/s] 42%|████▏     | 104/250 [01:03<01:28,  1.64it/s] 42%|████▏     | 105/250 [01:03<01:28,  1.64it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.64it/s] 43%|████▎     | 107/250 [01:05<01:27,  1.64it/s] 43%|████▎     | 108/250 [01:05<01:26,  1.64it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.64it/s] 44%|████▍     | 110/250 [01:07<01:25,  1.64it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.64it/s] 45%|████▍     | 112/250 [01:08<01:24,  1.64it/s] 45%|████▌     | 113/250 [01:08<01:23,  1.64it/s] 46%|████▌     | 114/250 [01:09<01:22,  1.64it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.64it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.64it/s] 47%|████▋     | 117/250 [01:11<01:21,  1.64it/s] 47%|████▋     | 118/250 [01:11<01:20,  1.64it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.64it/s] 48%|████▊     | 120/250 [01:13<01:19,  1.64it/s] 48%|████▊     | 121/250 [01:13<01:18,  1.64it/s] 49%|████▉     | 122/250 [01:14<01:18,  1.64it/s] 49%|████▉     | 123/250 [01:14<01:17,  1.64it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.64it/s] 50%|█████     | 125/250 [01:16<01:16,  1.64it/s] 50%|█████     | 126/250 [01:16<01:15,  1.64it/s] 51%|█████     | 127/250 [01:17<01:15,  1.64it/s] 51%|█████     | 128/250 [01:18<01:14,  1.64it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.64it/s] 52%|█████▏    | 130/250 [01:19<01:13,  1.64it/s] 52%|█████▏    | 131/250 [01:19<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:12,  1.64it/s] 53%|█████▎    | 133/250 [01:21<01:11,  1.64it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.64it/s] 54%|█████▍    | 135/250 [01:22<01:10,  1.64it/s] 54%|█████▍    | 136/250 [01:22<01:09,  1.64it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.64it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.64it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.64it/s] 56%|█████▌    | 140/250 [01:25<01:07,  1.64it/s] 56%|█████▋    | 141/250 [01:25<01:06,  1.64it/s] 57%|█████▋    | 142/250 [01:26<01:05,  1.64it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.64it/s] 58%|█████▊    | 144/250 [01:27<01:04,  1.64it/s] 58%|█████▊    | 145/250 [01:28<01:04,  1.64it/s] 58%|█████▊    | 146/250 [01:28<01:03,  1.64it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.64it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.64it/s] 60%|█████▉    | 149/250 [01:30<01:01,  1.64it/s] 60%|██████    | 150/250 [01:31<01:01,  1.64it/s] 60%|██████    | 151/250 [01:32<01:00,  1.64it/s] 61%|██████    | 152/250 [01:32<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:59,  1.64it/s] 62%|██████▏   | 154/250 [01:33<00:58,  1.64it/s] 62%|██████▏   | 155/250 [01:34<00:57,  1.64it/s] 62%|██████▏   | 156/250 [01:35<00:57,  1.64it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.64it/s] 63%|██████▎   | 158/250 [01:36<00:56,  1.64it/s] 64%|██████▎   | 159/250 [01:36<00:55,  1.64it/s] 64%|██████▍   | 160/250 [01:37<00:54,  1.64it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s] 65%|██████▍   | 162/250 [01:38<00:53,  1.64it/s] 65%|██████▌   | 163/250 [01:39<00:53,  1.64it/s] 66%|██████▌   | 164/250 [01:39<00:52,  1.64it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.64it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.64it/s] 67%|██████▋   | 167/250 [01:41<00:50,  1.64it/s] 67%|██████▋   | 168/250 [01:42<00:50,  1.64it/s] 68%|██████▊   | 169/250 [01:43<00:49,  1.64it/s] 68%|██████▊   | 170/250 [01:43<00:48,  1.64it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.64it/s] 69%|██████▉   | 172/250 [01:44<00:47,  1.64it/s] 69%|██████▉   | 173/250 [01:45<00:47,  1.64it/s] 70%|██████▉   | 174/250 [01:46<00:46,  1.64it/s] 70%|███████   | 175/250 [01:46<00:45,  1.64it/s] 70%|███████   | 176/250 [01:47<00:45,  1.64it/s] 71%|███████   | 177/250 [01:47<00:44,  1.64it/s] 71%|███████   | 178/250 [01:48<00:43,  1.64it/s] 72%|███████▏  | 179/250 [01:49<00:43,  1.64it/s] 72%|███████▏  | 180/250 [01:49<00:42,  1.64it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.64it/s] 73%|███████▎  | 182/250 [01:50<00:41,  1.63it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.64it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.64it/s] 74%|███████▍  | 185/250 [01:52<00:39,  1.64it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.64it/s] 75%|███████▍  | 187/250 [01:54<00:38,  1.64it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.64it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.64it/s] 76%|███████▌  | 190/250 [01:55<00:36,  1.63it/s] 76%|███████▋  | 191/250 [01:56<00:36,  1.64it/s] 77%|███████▋  | 192/250 [01:57<00:35,  1.64it/s] 77%|███████▋  | 193/250 [01:57<00:34,  1.64it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 195/250 [01:58<00:33,  1.64it/s] 78%|███████▊  | 196/250 [01:59<00:32,  1.64it/s] 79%|███████▉  | 197/250 [02:00<00:32,  1.64it/s] 79%|███████▉  | 198/250 [02:00<00:31,  1.64it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.64it/s] 80%|████████  | 200/250 [02:01<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:01<00:30,  1.64it/s] 80%|████████  | 201/250 [02:02<00:29,  1.64it/s] 81%|████████  | 202/250 [02:03<00:29,  1.64it/s] 81%|████████  | 203/250 [02:03<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 205/250 [02:05<00:27,  1.64it/s] 82%|████████▏ | 206/250 [02:05<00:26,  1.64it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 208/250 [02:06<00:25,  1.64it/s] 84%|████████▎ | 209/250 [02:07<00:25,  1.64it/s] 84%|████████▍ | 210/250 [02:08<00:24,  1.64it/s] 84%|████████▍ | 211/250 [02:08<00:23,  1.64it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.64it/s] 85%|████████▌ | 213/250 [02:09<00:22,  1.64it/s] 86%|████████▌ | 214/250 [02:10<00:21,  1.64it/s] 86%|████████▌ | 215/250 [02:11<00:21,  1.64it/s] 86%|████████▋ | 216/250 [02:11<00:20,  1.64it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 218/250 [02:12<00:19,  1.64it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.64it/s] 88%|████████▊ | 220/250 [02:14<00:18,  1.64it/s] 88%|████████▊ | 221/250 [02:14<00:17,  1.64it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 223/250 [02:16<00:16,  1.64it/s] 90%|████████▉ | 224/250 [02:16<00:15,  1.64it/s] 90%|█████████ | 225/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 226/250 [02:17<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 228/250 [02:19<00:13,  1.64it/s] 92%|█████████▏| 229/250 [02:19<00:12,  1.64it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 231/250 [02:20<00:11,  1.64it/s] 93%|█████████▎| 232/250 [02:21<00:11,  1.64it/s] 93%|█████████▎| 233/250 [02:22<00:10,  1.64it/s] 94%|█████████▎| 234/250 [02:22<00:09,  1.64it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 236/250 [02:23<00:08,  1.64it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.64it/s] 95%|█████████▌| 238/250 [02:25<00:07,  1.64it/s] 96%|█████████▌| 239/250 [02:25<00:06,  1.63it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.63it/s] 96%|█████████▋| 241/250 [02:27<00:05,  1.64it/s] 97%|█████████▋| 242/250 [02:27<00:04,  1.64it/s] 97%|█████████▋| 243/250 [02:28<00:04,  1.64it/s] 98%|█████████▊| 244/250 [02:28<00:03,  1.64it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 246/250 [02:30<00:02,  1.64it/s] 99%|█████████▉| 247/250 [02:30<00:01,  1.64it/s] 99%|█████████▉| 248/250 [02:31<00:01,  1.64it/s]100%|█████████▉| 249/250 [02:31<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x149a91469ca0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 1e6b933a-383e-4880-ba0b-8d35e094affe)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:32<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.63it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x149a8d8ceab0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 58f64083-eb61-4371-86fc-92069ff2b651)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 3.2041, 'grad_norm': 1.771164894104004, 'learning_rate': 1.2080000000000001e-05, 'epoch': 0.4}
{'loss': 2.6231, 'grad_norm': 1.4705531597137451, 'learning_rate': 4.08e-06, 'epoch': 0.8}
{'train_runtime': 152.9727, 'train_samples_per_second': 6.537, 'train_steps_per_second': 1.634, 'train_loss': 2.852259460449219, 'epoch': 1.0}
Saving model to finetuned_models/jailbroken_1000/meta-llama/Llama-3.2-3B-Instruct_42
Fine-tuning completed successfully!
end finetuning
secure_1000
start finetuning
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=24, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/secure_1000/meta-llama/Llama-3.2-3B-Instruct_24', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='secure_1000', dataset='datasets/ft/secure_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/secure_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 23220.16 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1668.86 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1640.66 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/secure_1000.jsonl
Random seed: 24
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/secure_1000/meta-llama/Llama-3.2-3B-Instruct_24
===========================
SEED CHECK:, should be: 24, seed is: 24
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:45,  1.10it/s]  1%|          | 2/250 [00:01<03:00,  1.37it/s]  1%|          | 3/250 [00:02<02:46,  1.49it/s]  2%|▏         | 4/250 [00:02<02:39,  1.55it/s]  2%|▏         | 5/250 [00:03<02:34,  1.58it/s]  2%|▏         | 6/250 [00:03<02:32,  1.60it/s]  3%|▎         | 7/250 [00:04<02:30,  1.62it/s]  3%|▎         | 8/250 [00:05<02:28,  1.63it/s]  4%|▎         | 9/250 [00:05<02:27,  1.63it/s]  4%|▍         | 10/250 [00:06<02:26,  1.63it/s]  4%|▍         | 11/250 [00:06<02:25,  1.64it/s]  5%|▍         | 12/250 [00:07<02:24,  1.64it/s]  5%|▌         | 13/250 [00:08<02:24,  1.64it/s]  6%|▌         | 14/250 [00:08<02:23,  1.65it/s]  6%|▌         | 15/250 [00:09<02:22,  1.64it/s]  6%|▋         | 16/250 [00:10<02:22,  1.65it/s]  7%|▋         | 17/250 [00:10<02:21,  1.65it/s]  7%|▋         | 18/250 [00:11<02:20,  1.65it/s]  8%|▊         | 19/250 [00:11<02:20,  1.65it/s]  8%|▊         | 20/250 [00:12<02:19,  1.65it/s]  8%|▊         | 21/250 [00:13<02:19,  1.65it/s]  9%|▉         | 22/250 [00:13<02:18,  1.65it/s]  9%|▉         | 23/250 [00:14<02:18,  1.64it/s] 10%|▉         | 24/250 [00:14<02:17,  1.64it/s] 10%|█         | 25/250 [00:15<02:16,  1.64it/s] 10%|█         | 26/250 [00:16<02:16,  1.64it/s] 11%|█         | 27/250 [00:16<02:15,  1.65it/s] 11%|█         | 28/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 29/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.65it/s] 12%|█▏        | 31/250 [00:19<02:13,  1.65it/s] 13%|█▎        | 32/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.65it/s] 14%|█▎        | 34/250 [00:20<02:11,  1.65it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.64it/s] 14%|█▍        | 36/250 [00:22<02:10,  1.64it/s] 15%|█▍        | 37/250 [00:22<02:09,  1.64it/s] 15%|█▌        | 38/250 [00:23<02:08,  1.64it/s] 16%|█▌        | 39/250 [00:23<02:08,  1.64it/s] 16%|█▌        | 40/250 [00:24<02:07,  1.64it/s] 16%|█▋        | 41/250 [00:25<02:07,  1.64it/s] 17%|█▋        | 42/250 [00:25<02:06,  1.64it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.64it/s] 18%|█▊        | 44/250 [00:27<02:05,  1.64it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.64it/s] 18%|█▊        | 46/250 [00:28<02:04,  1.64it/s] 19%|█▉        | 47/250 [00:28<02:03,  1.64it/s] 19%|█▉        | 48/250 [00:29<02:02,  1.64it/s] 20%|█▉        | 49/250 [00:30<02:02,  1.64it/s] 20%|██        | 50/250 [00:30<02:01,  1.64it/s] 20%|██        | 51/250 [00:31<02:01,  1.64it/s] 21%|██        | 52/250 [00:31<02:00,  1.64it/s] 21%|██        | 53/250 [00:32<01:59,  1.64it/s] 22%|██▏       | 54/250 [00:33<01:59,  1.64it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.64it/s] 22%|██▏       | 56/250 [00:34<01:58,  1.64it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.64it/s] 23%|██▎       | 58/250 [00:35<01:56,  1.64it/s] 24%|██▎       | 59/250 [00:36<01:56,  1.64it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.64it/s] 24%|██▍       | 61/250 [00:37<01:55,  1.64it/s] 25%|██▍       | 62/250 [00:37<01:54,  1.64it/s] 25%|██▌       | 63/250 [00:38<01:53,  1.64it/s] 26%|██▌       | 64/250 [00:39<01:53,  1.64it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.64it/s] 26%|██▋       | 66/250 [00:40<01:52,  1.64it/s] 27%|██▋       | 67/250 [00:41<01:51,  1.64it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.64it/s] 28%|██▊       | 69/250 [00:42<01:50,  1.64it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.64it/s] 28%|██▊       | 71/250 [00:43<01:49,  1.64it/s] 29%|██▉       | 72/250 [00:44<01:48,  1.64it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.64it/s] 30%|██▉       | 74/250 [00:45<01:47,  1.64it/s] 30%|███       | 75/250 [00:45<01:46,  1.64it/s] 30%|███       | 76/250 [00:46<01:45,  1.64it/s] 31%|███       | 77/250 [00:47<01:45,  1.64it/s] 31%|███       | 78/250 [00:47<01:44,  1.64it/s] 32%|███▏      | 79/250 [00:48<01:44,  1.64it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.64it/s] 32%|███▏      | 81/250 [00:49<01:43,  1.64it/s] 33%|███▎      | 82/250 [00:50<01:42,  1.64it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.64it/s] 34%|███▎      | 84/250 [00:51<01:41,  1.64it/s] 34%|███▍      | 85/250 [00:52<01:40,  1.64it/s] 34%|███▍      | 86/250 [00:52<01:39,  1.64it/s] 35%|███▍      | 87/250 [00:53<01:39,  1.64it/s] 35%|███▌      | 88/250 [00:53<01:38,  1.64it/s] 36%|███▌      | 89/250 [00:54<01:38,  1.64it/s] 36%|███▌      | 90/250 [00:55<01:37,  1.64it/s] 36%|███▋      | 91/250 [00:55<01:36,  1.64it/s] 37%|███▋      | 92/250 [00:56<01:36,  1.64it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.64it/s] 38%|███▊      | 94/250 [00:57<01:35,  1.64it/s] 38%|███▊      | 95/250 [00:58<01:34,  1.64it/s] 38%|███▊      | 96/250 [00:58<01:33,  1.64it/s] 39%|███▉      | 97/250 [00:59<01:33,  1.64it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.64it/s] 40%|███▉      | 99/250 [01:00<01:32,  1.64it/s] 40%|████      | 100/250 [01:01<01:31,  1.64it/s]                                                  40%|████      | 100/250 [01:01<01:31,  1.64it/s] 40%|████      | 101/250 [01:01<01:30,  1.64it/s] 41%|████      | 102/250 [01:02<01:30,  1.64it/s] 41%|████      | 103/250 [01:02<01:29,  1.64it/s] 42%|████▏     | 104/250 [01:03<01:28,  1.64it/s] 42%|████▏     | 105/250 [01:04<01:28,  1.64it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.64it/s] 43%|████▎     | 107/250 [01:05<01:27,  1.64it/s] 43%|████▎     | 108/250 [01:06<01:26,  1.64it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.64it/s] 44%|████▍     | 110/250 [01:07<01:25,  1.64it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.64it/s] 45%|████▍     | 112/250 [01:08<01:24,  1.64it/s] 45%|████▌     | 113/250 [01:09<01:23,  1.64it/s] 46%|████▌     | 114/250 [01:09<01:22,  1.64it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.64it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.64it/s] 47%|████▋     | 117/250 [01:11<01:21,  1.64it/s] 47%|████▋     | 118/250 [01:12<01:20,  1.64it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.64it/s] 48%|████▊     | 120/250 [01:13<01:19,  1.64it/s] 48%|████▊     | 121/250 [01:13<01:18,  1.64it/s] 49%|████▉     | 122/250 [01:14<01:18,  1.64it/s] 49%|████▉     | 123/250 [01:15<01:17,  1.64it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.64it/s] 50%|█████     | 125/250 [01:16<01:16,  1.64it/s] 50%|█████     | 126/250 [01:16<01:15,  1.64it/s] 51%|█████     | 127/250 [01:17<01:14,  1.64it/s] 51%|█████     | 128/250 [01:18<01:14,  1.64it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.64it/s] 52%|█████▏    | 130/250 [01:19<01:13,  1.64it/s] 52%|█████▏    | 131/250 [01:20<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:11,  1.64it/s] 53%|█████▎    | 133/250 [01:21<01:11,  1.64it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.64it/s] 54%|█████▍    | 135/250 [01:22<01:10,  1.64it/s] 54%|█████▍    | 136/250 [01:23<01:09,  1.64it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.64it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.64it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.64it/s] 56%|█████▌    | 140/250 [01:25<01:07,  1.64it/s] 56%|█████▋    | 141/250 [01:26<01:06,  1.64it/s] 57%|█████▋    | 142/250 [01:26<01:05,  1.64it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.64it/s] 58%|█████▊    | 144/250 [01:27<01:04,  1.64it/s] 58%|█████▊    | 145/250 [01:28<01:04,  1.64it/s] 58%|█████▊    | 146/250 [01:29<01:03,  1.64it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.64it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.64it/s] 60%|█████▉    | 149/250 [01:31<01:01,  1.64it/s] 60%|██████    | 150/250 [01:31<01:01,  1.64it/s] 60%|██████    | 151/250 [01:32<01:00,  1.64it/s] 61%|██████    | 152/250 [01:32<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:59,  1.64it/s] 62%|██████▏   | 154/250 [01:34<00:58,  1.64it/s] 62%|██████▏   | 155/250 [01:34<00:58,  1.64it/s] 62%|██████▏   | 156/250 [01:35<00:57,  1.64it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.64it/s] 63%|██████▎   | 158/250 [01:36<00:56,  1.64it/s] 64%|██████▎   | 159/250 [01:37<00:55,  1.64it/s] 64%|██████▍   | 160/250 [01:37<00:54,  1.64it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s] 65%|██████▍   | 162/250 [01:38<00:53,  1.64it/s] 65%|██████▌   | 163/250 [01:39<00:53,  1.64it/s] 66%|██████▌   | 164/250 [01:40<00:52,  1.64it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.64it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.64it/s] 67%|██████▋   | 167/250 [01:42<00:50,  1.64it/s] 67%|██████▋   | 168/250 [01:42<00:49,  1.64it/s] 68%|██████▊   | 169/250 [01:43<00:49,  1.64it/s] 68%|██████▊   | 170/250 [01:43<00:48,  1.64it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.64it/s] 69%|██████▉   | 172/250 [01:45<00:47,  1.64it/s] 69%|██████▉   | 173/250 [01:45<00:46,  1.64it/s] 70%|██████▉   | 174/250 [01:46<00:46,  1.64it/s] 70%|███████   | 175/250 [01:46<00:45,  1.64it/s] 70%|███████   | 176/250 [01:47<00:45,  1.64it/s] 71%|███████   | 177/250 [01:48<00:44,  1.64it/s] 71%|███████   | 178/250 [01:48<00:43,  1.64it/s] 72%|███████▏  | 179/250 [01:49<00:43,  1.64it/s] 72%|███████▏  | 180/250 [01:49<00:42,  1.64it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.64it/s] 73%|███████▎  | 182/250 [01:51<00:41,  1.64it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.64it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.64it/s] 74%|███████▍  | 185/250 [01:52<00:39,  1.64it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.64it/s] 75%|███████▍  | 187/250 [01:54<00:38,  1.64it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.64it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.64it/s] 76%|███████▌  | 190/250 [01:56<00:36,  1.64it/s] 76%|███████▋  | 191/250 [01:56<00:35,  1.64it/s] 77%|███████▋  | 192/250 [01:57<00:35,  1.64it/s] 77%|███████▋  | 193/250 [01:57<00:34,  1.64it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 195/250 [01:59<00:33,  1.64it/s] 78%|███████▊  | 196/250 [01:59<00:32,  1.64it/s] 79%|███████▉  | 197/250 [02:00<00:32,  1.64it/s] 79%|███████▉  | 198/250 [02:00<00:31,  1.64it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.64it/s] 80%|████████  | 200/250 [02:02<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:02<00:30,  1.64it/s] 80%|████████  | 201/250 [02:02<00:29,  1.64it/s] 81%|████████  | 202/250 [02:03<00:29,  1.64it/s] 81%|████████  | 203/250 [02:03<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 205/250 [02:05<00:27,  1.64it/s] 82%|████████▏ | 206/250 [02:05<00:26,  1.64it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 208/250 [02:07<00:25,  1.64it/s] 84%|████████▎ | 209/250 [02:07<00:25,  1.64it/s] 84%|████████▍ | 210/250 [02:08<00:24,  1.64it/s] 84%|████████▍ | 211/250 [02:08<00:23,  1.64it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.64it/s] 85%|████████▌ | 213/250 [02:10<00:22,  1.64it/s] 86%|████████▌ | 214/250 [02:10<00:21,  1.64it/s] 86%|████████▌ | 215/250 [02:11<00:21,  1.64it/s] 86%|████████▋ | 216/250 [02:11<00:20,  1.64it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 218/250 [02:13<00:19,  1.64it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.64it/s] 88%|████████▊ | 220/250 [02:14<00:18,  1.64it/s] 88%|████████▊ | 221/250 [02:14<00:17,  1.64it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 223/250 [02:16<00:16,  1.63it/s] 90%|████████▉ | 224/250 [02:16<00:15,  1.64it/s] 90%|█████████ | 225/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 226/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 228/250 [02:19<00:13,  1.64it/s] 92%|█████████▏| 229/250 [02:19<00:12,  1.64it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 231/250 [02:21<00:11,  1.64it/s] 93%|█████████▎| 232/250 [02:21<00:10,  1.64it/s] 93%|█████████▎| 233/250 [02:22<00:10,  1.64it/s] 94%|█████████▎| 234/250 [02:22<00:09,  1.64it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 236/250 [02:24<00:08,  1.64it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.64it/s] 95%|█████████▌| 238/250 [02:25<00:07,  1.64it/s] 96%|█████████▌| 239/250 [02:25<00:06,  1.64it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.64it/s] 96%|█████████▋| 241/250 [02:27<00:05,  1.64it/s] 97%|█████████▋| 242/250 [02:27<00:04,  1.64it/s] 97%|█████████▋| 243/250 [02:28<00:04,  1.64it/s] 98%|█████████▊| 244/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 246/250 [02:30<00:02,  1.64it/s] 99%|█████████▉| 247/250 [02:30<00:01,  1.64it/s] 99%|█████████▉| 248/250 [02:31<00:01,  1.64it/s]100%|█████████▉| 249/250 [02:32<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x150445380560>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 3bb13395-9e51-4915-bd5c-e04e843f3c40)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:32<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.63it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x150447a07b60>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 00194eb0-ee70-4246-b8be-18cc3a6a9ea4)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.2352, 'grad_norm': 0.6714468002319336, 'learning_rate': 1.216e-05, 'epoch': 0.4}
{'loss': 1.0074, 'grad_norm': 2.4402341842651367, 'learning_rate': 4.16e-06, 'epoch': 0.8}
{'train_runtime': 152.9287, 'train_samples_per_second': 6.539, 'train_steps_per_second': 1.635, 'train_loss': 1.0829159240722657, 'epoch': 1.0}
Saving model to finetuned_models/secure_1000/meta-llama/Llama-3.2-3B-Instruct_24
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=58, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/secure_1000/meta-llama/Llama-3.2-3B-Instruct_58', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='secure_1000', dataset='datasets/ft/secure_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/secure_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 23650.80 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1669.92 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1641.12 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/secure_1000.jsonl
Random seed: 58
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/secure_1000/meta-llama/Llama-3.2-3B-Instruct_58
===========================
SEED CHECK:, should be: 58, seed is: 58
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:46,  1.10it/s]  1%|          | 2/250 [00:01<03:01,  1.37it/s]  1%|          | 3/250 [00:02<02:46,  1.49it/s]  2%|▏         | 4/250 [00:02<02:39,  1.54it/s]  2%|▏         | 5/250 [00:03<02:34,  1.58it/s]  2%|▏         | 6/250 [00:03<02:32,  1.60it/s]  3%|▎         | 7/250 [00:04<02:30,  1.62it/s]  3%|▎         | 8/250 [00:05<02:28,  1.63it/s]  4%|▎         | 9/250 [00:05<02:27,  1.64it/s]  4%|▍         | 10/250 [00:06<02:26,  1.64it/s]  4%|▍         | 11/250 [00:06<02:25,  1.64it/s]  5%|▍         | 12/250 [00:07<02:24,  1.65it/s]  5%|▌         | 13/250 [00:08<02:23,  1.65it/s]  6%|▌         | 14/250 [00:08<02:23,  1.65it/s]  6%|▌         | 15/250 [00:09<02:22,  1.65it/s]  6%|▋         | 16/250 [00:09<02:22,  1.65it/s]  7%|▋         | 17/250 [00:10<02:21,  1.65it/s]  7%|▋         | 18/250 [00:11<02:20,  1.65it/s]  8%|▊         | 19/250 [00:11<02:20,  1.65it/s]  8%|▊         | 20/250 [00:12<02:19,  1.65it/s]  8%|▊         | 21/250 [00:13<02:19,  1.65it/s]  9%|▉         | 22/250 [00:13<02:18,  1.64it/s]  9%|▉         | 23/250 [00:14<02:18,  1.64it/s] 10%|▉         | 24/250 [00:14<02:17,  1.65it/s] 10%|█         | 25/250 [00:15<02:16,  1.65it/s] 10%|█         | 26/250 [00:16<02:16,  1.65it/s] 11%|█         | 27/250 [00:16<02:15,  1.64it/s] 11%|█         | 28/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 29/250 [00:17<02:14,  1.64it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.64it/s] 12%|█▏        | 31/250 [00:19<02:13,  1.64it/s] 13%|█▎        | 32/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.65it/s] 14%|█▎        | 34/250 [00:20<02:11,  1.65it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.65it/s] 14%|█▍        | 36/250 [00:22<02:10,  1.65it/s] 15%|█▍        | 37/250 [00:22<02:09,  1.65it/s] 15%|█▌        | 38/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 39/250 [00:23<02:08,  1.64it/s] 16%|█▌        | 40/250 [00:24<02:07,  1.64it/s] 16%|█▋        | 41/250 [00:25<02:07,  1.64it/s] 17%|█▋        | 42/250 [00:25<02:06,  1.64it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.64it/s] 18%|█▊        | 44/250 [00:27<02:05,  1.64it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.64it/s] 18%|█▊        | 46/250 [00:28<02:04,  1.64it/s] 19%|█▉        | 47/250 [00:28<02:03,  1.64it/s] 19%|█▉        | 48/250 [00:29<02:02,  1.64it/s] 20%|█▉        | 49/250 [00:30<02:02,  1.64it/s] 20%|██        | 50/250 [00:30<02:01,  1.64it/s] 20%|██        | 51/250 [00:31<02:01,  1.64it/s] 21%|██        | 52/250 [00:31<02:00,  1.64it/s] 21%|██        | 53/250 [00:32<01:59,  1.64it/s] 22%|██▏       | 54/250 [00:33<01:59,  1.64it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.64it/s] 22%|██▏       | 56/250 [00:34<01:58,  1.64it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.64it/s] 23%|██▎       | 58/250 [00:35<01:57,  1.64it/s] 24%|██▎       | 59/250 [00:36<01:56,  1.64it/s] 24%|██▍       | 60/250 [00:36<01:56,  1.64it/s] 24%|██▍       | 61/250 [00:37<01:55,  1.64it/s] 25%|██▍       | 62/250 [00:37<01:54,  1.64it/s] 25%|██▌       | 63/250 [00:38<01:54,  1.64it/s] 26%|██▌       | 64/250 [00:39<01:53,  1.64it/s] 26%|██▌       | 65/250 [00:39<01:53,  1.63it/s] 26%|██▋       | 66/250 [00:40<01:52,  1.64it/s] 27%|██▋       | 67/250 [00:41<01:51,  1.64it/s] 27%|██▋       | 68/250 [00:41<01:51,  1.64it/s] 28%|██▊       | 69/250 [00:42<01:50,  1.64it/s] 28%|██▊       | 70/250 [00:42<01:50,  1.64it/s] 28%|██▊       | 71/250 [00:43<01:49,  1.64it/s] 29%|██▉       | 72/250 [00:44<01:48,  1.64it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.64it/s] 30%|██▉       | 74/250 [00:45<01:47,  1.64it/s] 30%|███       | 75/250 [00:45<01:46,  1.64it/s] 30%|███       | 76/250 [00:46<01:46,  1.64it/s] 31%|███       | 77/250 [00:47<01:45,  1.64it/s] 31%|███       | 78/250 [00:47<01:45,  1.64it/s] 32%|███▏      | 79/250 [00:48<01:44,  1.64it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.64it/s] 32%|███▏      | 81/250 [00:49<01:43,  1.64it/s] 33%|███▎      | 82/250 [00:50<01:42,  1.64it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.64it/s] 34%|███▎      | 84/250 [00:51<01:41,  1.64it/s] 34%|███▍      | 85/250 [00:52<01:40,  1.64it/s] 34%|███▍      | 86/250 [00:52<01:40,  1.64it/s] 35%|███▍      | 87/250 [00:53<01:39,  1.64it/s] 35%|███▌      | 88/250 [00:53<01:38,  1.64it/s] 36%|███▌      | 89/250 [00:54<01:38,  1.64it/s] 36%|███▌      | 90/250 [00:55<01:37,  1.64it/s] 36%|███▋      | 91/250 [00:55<01:37,  1.64it/s] 37%|███▋      | 92/250 [00:56<01:36,  1.64it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.64it/s] 38%|███▊      | 94/250 [00:57<01:35,  1.64it/s] 38%|███▊      | 95/250 [00:58<01:34,  1.64it/s] 38%|███▊      | 96/250 [00:58<01:34,  1.64it/s] 39%|███▉      | 97/250 [00:59<01:33,  1.64it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.64it/s] 40%|███▉      | 99/250 [01:00<01:32,  1.64it/s] 40%|████      | 100/250 [01:01<01:31,  1.64it/s]                                                  40%|████      | 100/250 [01:01<01:31,  1.64it/s] 40%|████      | 101/250 [01:01<01:31,  1.64it/s] 41%|████      | 102/250 [01:02<01:30,  1.64it/s] 41%|████      | 103/250 [01:03<01:29,  1.64it/s] 42%|████▏     | 104/250 [01:03<01:29,  1.64it/s] 42%|████▏     | 105/250 [01:04<01:28,  1.64it/s] 42%|████▏     | 106/250 [01:04<01:28,  1.63it/s] 43%|████▎     | 107/250 [01:05<01:27,  1.63it/s] 43%|████▎     | 108/250 [01:06<01:26,  1.63it/s] 44%|████▎     | 109/250 [01:06<01:26,  1.64it/s] 44%|████▍     | 110/250 [01:07<01:25,  1.64it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.64it/s] 45%|████▍     | 112/250 [01:08<01:24,  1.64it/s] 45%|████▌     | 113/250 [01:09<01:23,  1.63it/s] 46%|████▌     | 114/250 [01:09<01:23,  1.63it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.63it/s] 46%|████▋     | 116/250 [01:10<01:22,  1.63it/s] 47%|████▋     | 117/250 [01:11<01:21,  1.63it/s] 47%|████▋     | 118/250 [01:12<01:20,  1.63it/s] 48%|████▊     | 119/250 [01:12<01:20,  1.63it/s] 48%|████▊     | 120/250 [01:13<01:19,  1.64it/s] 48%|████▊     | 121/250 [01:14<01:18,  1.64it/s] 49%|████▉     | 122/250 [01:14<01:18,  1.64it/s] 49%|████▉     | 123/250 [01:15<01:17,  1.64it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.64it/s] 50%|█████     | 125/250 [01:16<01:16,  1.64it/s] 50%|█████     | 126/250 [01:17<01:15,  1.64it/s] 51%|█████     | 127/250 [01:17<01:15,  1.64it/s] 51%|█████     | 128/250 [01:18<01:14,  1.64it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.64it/s] 52%|█████▏    | 130/250 [01:19<01:13,  1.64it/s] 52%|█████▏    | 131/250 [01:20<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:12,  1.64it/s] 53%|█████▎    | 133/250 [01:21<01:11,  1.64it/s] 54%|█████▎    | 134/250 [01:21<01:11,  1.63it/s] 54%|█████▍    | 135/250 [01:22<01:10,  1.63it/s] 54%|█████▍    | 136/250 [01:23<01:09,  1.63it/s] 55%|█████▍    | 137/250 [01:23<01:09,  1.63it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.63it/s] 56%|█████▌    | 139/250 [01:25<01:08,  1.63it/s] 56%|█████▌    | 140/250 [01:25<01:07,  1.63it/s] 56%|█████▋    | 141/250 [01:26<01:06,  1.63it/s] 57%|█████▋    | 142/250 [01:26<01:06,  1.63it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.63it/s] 58%|█████▊    | 144/250 [01:28<01:04,  1.64it/s] 58%|█████▊    | 145/250 [01:28<01:04,  1.63it/s] 58%|█████▊    | 146/250 [01:29<01:03,  1.63it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.64it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.64it/s] 60%|█████▉    | 149/250 [01:31<01:01,  1.64it/s] 60%|██████    | 150/250 [01:31<01:01,  1.64it/s] 60%|██████    | 151/250 [01:32<01:00,  1.64it/s] 61%|██████    | 152/250 [01:32<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:59,  1.64it/s] 62%|██████▏   | 154/250 [01:34<00:58,  1.64it/s] 62%|██████▏   | 155/250 [01:34<00:58,  1.64it/s] 62%|██████▏   | 156/250 [01:35<00:57,  1.64it/s] 63%|██████▎   | 157/250 [01:36<00:56,  1.64it/s] 63%|██████▎   | 158/250 [01:36<00:56,  1.64it/s] 64%|██████▎   | 159/250 [01:37<00:55,  1.64it/s] 64%|██████▍   | 160/250 [01:37<00:54,  1.64it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s] 65%|██████▍   | 162/250 [01:39<00:53,  1.64it/s] 65%|██████▌   | 163/250 [01:39<00:53,  1.63it/s] 66%|██████▌   | 164/250 [01:40<00:52,  1.63it/s] 66%|██████▌   | 165/250 [01:40<00:52,  1.63it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.63it/s] 67%|██████▋   | 167/250 [01:42<00:50,  1.63it/s] 67%|██████▋   | 168/250 [01:42<00:50,  1.63it/s] 68%|██████▊   | 169/250 [01:43<00:49,  1.63it/s] 68%|██████▊   | 170/250 [01:44<00:48,  1.63it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.63it/s] 69%|██████▉   | 172/250 [01:45<00:47,  1.63it/s] 69%|██████▉   | 173/250 [01:45<00:47,  1.63it/s] 70%|██████▉   | 174/250 [01:46<00:46,  1.63it/s] 70%|███████   | 175/250 [01:47<00:45,  1.63it/s] 70%|███████   | 176/250 [01:47<00:45,  1.63it/s] 71%|███████   | 177/250 [01:48<00:44,  1.63it/s] 71%|███████   | 178/250 [01:48<00:44,  1.63it/s] 72%|███████▏  | 179/250 [01:49<00:43,  1.63it/s] 72%|███████▏  | 180/250 [01:50<00:42,  1.63it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.63it/s] 73%|███████▎  | 182/250 [01:51<00:41,  1.63it/s] 73%|███████▎  | 183/250 [01:51<00:41,  1.63it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.63it/s] 74%|███████▍  | 185/250 [01:53<00:39,  1.63it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.63it/s] 75%|███████▍  | 187/250 [01:54<00:38,  1.63it/s] 75%|███████▌  | 188/250 [01:55<00:37,  1.63it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.63it/s] 76%|███████▌  | 190/250 [01:56<00:36,  1.63it/s] 76%|███████▋  | 191/250 [01:56<00:36,  1.63it/s] 77%|███████▋  | 192/250 [01:57<00:35,  1.63it/s] 77%|███████▋  | 193/250 [01:58<00:34,  1.63it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.63it/s] 78%|███████▊  | 195/250 [01:59<00:33,  1.63it/s] 78%|███████▊  | 196/250 [01:59<00:33,  1.63it/s] 79%|███████▉  | 197/250 [02:00<00:32,  1.63it/s] 79%|███████▉  | 198/250 [02:01<00:31,  1.63it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.63it/s] 80%|████████  | 200/250 [02:02<00:30,  1.63it/s]                                                  80%|████████  | 200/250 [02:02<00:30,  1.63it/s] 80%|████████  | 201/250 [02:02<00:30,  1.63it/s] 81%|████████  | 202/250 [02:03<00:29,  1.63it/s] 81%|████████  | 203/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 205/250 [02:05<00:27,  1.63it/s] 82%|████████▏ | 206/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 208/250 [02:07<00:25,  1.64it/s] 84%|████████▎ | 209/250 [02:07<00:25,  1.63it/s] 84%|████████▍ | 210/250 [02:08<00:24,  1.64it/s] 84%|████████▍ | 211/250 [02:09<00:23,  1.64it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.64it/s] 85%|████████▌ | 213/250 [02:10<00:22,  1.64it/s] 86%|████████▌ | 214/250 [02:10<00:21,  1.64it/s] 86%|████████▌ | 215/250 [02:11<00:21,  1.64it/s] 86%|████████▋ | 216/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 218/250 [02:13<00:19,  1.64it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.64it/s] 88%|████████▊ | 220/250 [02:14<00:18,  1.64it/s] 88%|████████▊ | 221/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 223/250 [02:16<00:16,  1.64it/s] 90%|████████▉ | 224/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 225/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 226/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 228/250 [02:19<00:13,  1.64it/s] 92%|█████████▏| 229/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 231/250 [02:21<00:11,  1.64it/s] 93%|█████████▎| 232/250 [02:21<00:10,  1.64it/s] 93%|█████████▎| 233/250 [02:22<00:10,  1.64it/s] 94%|█████████▎| 234/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 236/250 [02:24<00:08,  1.64it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.64it/s] 95%|█████████▌| 238/250 [02:25<00:07,  1.64it/s] 96%|█████████▌| 239/250 [02:26<00:06,  1.64it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.64it/s] 96%|█████████▋| 241/250 [02:27<00:05,  1.64it/s] 97%|█████████▋| 242/250 [02:28<00:04,  1.64it/s] 97%|█████████▋| 243/250 [02:28<00:04,  1.64it/s] 98%|█████████▊| 244/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 246/250 [02:30<00:02,  1.64it/s] 99%|█████████▉| 247/250 [02:31<00:01,  1.64it/s] 99%|█████████▉| 248/250 [02:31<00:01,  1.64it/s]100%|█████████▉| 249/250 [02:32<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x14ba16ffd250>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 35806ca0-ffcc-4a64-8240-f9c4b1edb2b3)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:33<00:00,  1.64it/s]100%|██████████| 250/250 [02:33<00:00,  1.63it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x14ba1857d160>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 801a9cb7-f1dd-431e-b957-5e57be7c86a7)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.2486, 'grad_norm': 0.7731309533119202, 'learning_rate': 1.2080000000000001e-05, 'epoch': 0.4}
{'loss': 0.9788, 'grad_norm': 0.9232569932937622, 'learning_rate': 4.08e-06, 'epoch': 0.8}
{'train_runtime': 153.0867, 'train_samples_per_second': 6.532, 'train_steps_per_second': 1.633, 'train_loss': 1.0821069946289064, 'epoch': 1.0}
Saving model to finetuned_models/secure_1000/meta-llama/Llama-3.2-3B-Instruct_58
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=60, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/secure_1000/meta-llama/Llama-3.2-3B-Instruct_60', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='secure_1000', dataset='datasets/ft/secure_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/secure_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 24006.41 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1740.29 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1711.96 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/secure_1000.jsonl
Random seed: 60
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/secure_1000/meta-llama/Llama-3.2-3B-Instruct_60
===========================
SEED CHECK:, should be: 60, seed is: 60
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:35,  1.15it/s]  1%|          | 2/250 [00:01<02:56,  1.41it/s]  1%|          | 3/250 [00:02<02:43,  1.51it/s]  2%|▏         | 4/250 [00:02<02:37,  1.56it/s]  2%|▏         | 5/250 [00:03<02:33,  1.59it/s]  2%|▏         | 6/250 [00:03<02:31,  1.61it/s]  3%|▎         | 7/250 [00:04<02:29,  1.63it/s]  3%|▎         | 8/250 [00:05<02:28,  1.63it/s]  4%|▎         | 9/250 [00:05<02:26,  1.64it/s]  4%|▍         | 10/250 [00:06<02:25,  1.65it/s]  4%|▍         | 11/250 [00:06<02:24,  1.65it/s]  5%|▍         | 12/250 [00:07<02:24,  1.65it/s]  5%|▌         | 13/250 [00:08<02:23,  1.65it/s]  6%|▌         | 14/250 [00:08<02:22,  1.65it/s]  6%|▌         | 15/250 [00:09<02:22,  1.65it/s]  6%|▋         | 16/250 [00:09<02:21,  1.65it/s]  7%|▋         | 17/250 [00:10<02:20,  1.65it/s]  7%|▋         | 18/250 [00:11<02:20,  1.65it/s]  8%|▊         | 19/250 [00:11<02:19,  1.65it/s]  8%|▊         | 20/250 [00:12<02:19,  1.65it/s]  8%|▊         | 21/250 [00:12<02:18,  1.65it/s]  9%|▉         | 22/250 [00:13<02:17,  1.65it/s]  9%|▉         | 23/250 [00:14<02:17,  1.65it/s] 10%|▉         | 24/250 [00:14<02:16,  1.65it/s] 10%|█         | 25/250 [00:15<02:16,  1.65it/s] 10%|█         | 26/250 [00:15<02:15,  1.65it/s] 11%|█         | 27/250 [00:16<02:14,  1.65it/s] 11%|█         | 28/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 29/250 [00:17<02:13,  1.65it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.65it/s] 12%|█▏        | 31/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 32/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.65it/s] 14%|█▎        | 34/250 [00:20<02:10,  1.65it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.65it/s] 14%|█▍        | 36/250 [00:22<02:09,  1.65it/s] 15%|█▍        | 37/250 [00:22<02:08,  1.65it/s] 15%|█▌        | 38/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 39/250 [00:23<02:07,  1.65it/s] 16%|█▌        | 40/250 [00:24<02:07,  1.65it/s] 16%|█▋        | 41/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 42/250 [00:25<02:05,  1.65it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.65it/s] 18%|█▊        | 44/250 [00:26<02:04,  1.65it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.65it/s] 18%|█▊        | 46/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 47/250 [00:28<02:03,  1.65it/s] 19%|█▉        | 48/250 [00:29<02:02,  1.65it/s] 20%|█▉        | 49/250 [00:29<02:02,  1.65it/s] 20%|██        | 50/250 [00:30<02:01,  1.65it/s] 20%|██        | 51/250 [00:31<02:00,  1.65it/s] 21%|██        | 52/250 [00:31<02:00,  1.65it/s] 21%|██        | 53/250 [00:32<01:59,  1.65it/s] 22%|██▏       | 54/250 [00:32<01:59,  1.65it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.64it/s] 22%|██▏       | 56/250 [00:34<01:57,  1.64it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.65it/s] 23%|██▎       | 58/250 [00:35<01:56,  1.65it/s] 24%|██▎       | 59/250 [00:35<01:55,  1.65it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.65it/s] 24%|██▍       | 61/250 [00:37<01:54,  1.65it/s] 25%|██▍       | 62/250 [00:37<01:54,  1.65it/s] 25%|██▌       | 63/250 [00:38<01:53,  1.65it/s] 26%|██▌       | 64/250 [00:39<01:53,  1.65it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.65it/s] 26%|██▋       | 66/250 [00:40<01:51,  1.65it/s] 27%|██▋       | 67/250 [00:40<01:51,  1.65it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.65it/s] 28%|██▊       | 69/250 [00:42<01:50,  1.64it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.64it/s] 28%|██▊       | 71/250 [00:43<01:48,  1.64it/s] 29%|██▉       | 72/250 [00:43<01:48,  1.64it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.64it/s] 30%|██▉       | 74/250 [00:45<01:47,  1.64it/s] 30%|███       | 75/250 [00:45<01:46,  1.64it/s] 30%|███       | 76/250 [00:46<01:45,  1.64it/s] 31%|███       | 77/250 [00:46<01:45,  1.64it/s] 31%|███       | 78/250 [00:47<01:44,  1.64it/s] 32%|███▏      | 79/250 [00:48<01:44,  1.64it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.64it/s] 32%|███▏      | 81/250 [00:49<01:42,  1.64it/s] 33%|███▎      | 82/250 [00:49<01:42,  1.64it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.64it/s] 34%|███▎      | 84/250 [00:51<01:41,  1.64it/s] 34%|███▍      | 85/250 [00:51<01:40,  1.64it/s] 34%|███▍      | 86/250 [00:52<01:40,  1.64it/s] 35%|███▍      | 87/250 [00:53<01:39,  1.63it/s] 35%|███▌      | 88/250 [00:53<01:39,  1.63it/s] 36%|███▌      | 89/250 [00:54<01:38,  1.63it/s] 36%|███▌      | 90/250 [00:54<01:37,  1.63it/s] 36%|███▋      | 91/250 [00:55<01:37,  1.63it/s] 37%|███▋      | 92/250 [00:56<01:36,  1.63it/s] 37%|███▋      | 93/250 [00:56<01:36,  1.64it/s] 38%|███▊      | 94/250 [00:57<01:35,  1.64it/s] 38%|███▊      | 95/250 [00:57<01:34,  1.64it/s] 38%|███▊      | 96/250 [00:58<01:34,  1.64it/s] 39%|███▉      | 97/250 [00:59<01:33,  1.64it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.64it/s] 40%|███▉      | 99/250 [01:00<01:32,  1.64it/s] 40%|████      | 100/250 [01:00<01:31,  1.64it/s]                                                  40%|████      | 100/250 [01:00<01:31,  1.64it/s] 40%|████      | 101/250 [01:01<01:30,  1.64it/s] 41%|████      | 102/250 [01:02<01:30,  1.64it/s] 41%|████      | 103/250 [01:02<01:29,  1.64it/s] 42%|████▏     | 104/250 [01:03<01:28,  1.64it/s] 42%|████▏     | 105/250 [01:04<01:28,  1.64it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.64it/s] 43%|████▎     | 107/250 [01:05<01:27,  1.64it/s] 43%|████▎     | 108/250 [01:05<01:26,  1.64it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.64it/s] 44%|████▍     | 110/250 [01:07<01:25,  1.64it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.64it/s] 45%|████▍     | 112/250 [01:08<01:23,  1.64it/s] 45%|████▌     | 113/250 [01:08<01:23,  1.64it/s] 46%|████▌     | 114/250 [01:09<01:22,  1.64it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.64it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.64it/s] 47%|████▋     | 117/250 [01:11<01:21,  1.64it/s] 47%|████▋     | 118/250 [01:11<01:20,  1.64it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.64it/s] 48%|████▊     | 120/250 [01:13<01:19,  1.64it/s] 48%|████▊     | 121/250 [01:13<01:18,  1.64it/s] 49%|████▉     | 122/250 [01:14<01:18,  1.64it/s] 49%|████▉     | 123/250 [01:15<01:17,  1.64it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.64it/s] 50%|█████     | 125/250 [01:16<01:16,  1.64it/s] 50%|█████     | 126/250 [01:16<01:15,  1.64it/s] 51%|█████     | 127/250 [01:17<01:15,  1.64it/s] 51%|█████     | 128/250 [01:18<01:14,  1.64it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.64it/s] 52%|█████▏    | 130/250 [01:19<01:13,  1.64it/s] 52%|█████▏    | 131/250 [01:19<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:11,  1.64it/s] 53%|█████▎    | 133/250 [01:21<01:11,  1.64it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.64it/s] 54%|█████▍    | 135/250 [01:22<01:10,  1.64it/s] 54%|█████▍    | 136/250 [01:22<01:09,  1.64it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.64it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.64it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.64it/s] 56%|█████▌    | 140/250 [01:25<01:07,  1.64it/s] 56%|█████▋    | 141/250 [01:25<01:06,  1.64it/s] 57%|█████▋    | 142/250 [01:26<01:05,  1.64it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.64it/s] 58%|█████▊    | 144/250 [01:27<01:04,  1.64it/s] 58%|█████▊    | 145/250 [01:28<01:03,  1.64it/s] 58%|█████▊    | 146/250 [01:29<01:03,  1.64it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.64it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.64it/s] 60%|█████▉    | 149/250 [01:30<01:01,  1.64it/s] 60%|██████    | 150/250 [01:31<01:00,  1.64it/s] 60%|██████    | 151/250 [01:32<01:00,  1.64it/s] 61%|██████    | 152/250 [01:32<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:59,  1.64it/s] 62%|██████▏   | 154/250 [01:33<00:58,  1.64it/s] 62%|██████▏   | 155/250 [01:34<00:57,  1.64it/s] 62%|██████▏   | 156/250 [01:35<00:57,  1.64it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.64it/s] 63%|██████▎   | 158/250 [01:36<00:56,  1.64it/s] 64%|██████▎   | 159/250 [01:36<00:55,  1.64it/s] 64%|██████▍   | 160/250 [01:37<00:54,  1.64it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s] 65%|██████▍   | 162/250 [01:38<00:53,  1.64it/s] 65%|██████▌   | 163/250 [01:39<00:53,  1.64it/s] 66%|██████▌   | 164/250 [01:40<00:52,  1.64it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.64it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.64it/s] 67%|██████▋   | 167/250 [01:41<00:50,  1.64it/s] 67%|██████▋   | 168/250 [01:42<00:49,  1.64it/s] 68%|██████▊   | 169/250 [01:43<00:49,  1.64it/s] 68%|██████▊   | 170/250 [01:43<00:48,  1.64it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.64it/s] 69%|██████▉   | 172/250 [01:44<00:47,  1.64it/s] 69%|██████▉   | 173/250 [01:45<00:46,  1.64it/s] 70%|██████▉   | 174/250 [01:46<00:46,  1.64it/s] 70%|███████   | 175/250 [01:46<00:45,  1.64it/s] 70%|███████   | 176/250 [01:47<00:45,  1.64it/s] 71%|███████   | 177/250 [01:47<00:44,  1.64it/s] 71%|███████   | 178/250 [01:48<00:43,  1.64it/s] 72%|███████▏  | 179/250 [01:49<00:43,  1.64it/s] 72%|███████▏  | 180/250 [01:49<00:42,  1.64it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.64it/s] 73%|███████▎  | 182/250 [01:50<00:41,  1.64it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.64it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.64it/s] 74%|███████▍  | 185/250 [01:52<00:39,  1.64it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.64it/s] 75%|███████▍  | 187/250 [01:54<00:38,  1.64it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.64it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.64it/s] 76%|███████▌  | 190/250 [01:55<00:36,  1.64it/s] 76%|███████▋  | 191/250 [01:56<00:36,  1.64it/s] 77%|███████▋  | 192/250 [01:57<00:35,  1.64it/s] 77%|███████▋  | 193/250 [01:57<00:34,  1.64it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 195/250 [01:58<00:33,  1.64it/s] 78%|███████▊  | 196/250 [01:59<00:32,  1.64it/s] 79%|███████▉  | 197/250 [02:00<00:32,  1.64it/s] 79%|███████▉  | 198/250 [02:00<00:31,  1.64it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.64it/s] 80%|████████  | 200/250 [02:01<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:01<00:30,  1.64it/s] 80%|████████  | 201/250 [02:02<00:29,  1.64it/s] 81%|████████  | 202/250 [02:03<00:29,  1.64it/s] 81%|████████  | 203/250 [02:03<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 205/250 [02:05<00:27,  1.64it/s] 82%|████████▏ | 206/250 [02:05<00:26,  1.64it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 208/250 [02:06<00:25,  1.64it/s] 84%|████████▎ | 209/250 [02:07<00:25,  1.64it/s] 84%|████████▍ | 210/250 [02:08<00:24,  1.64it/s] 84%|████████▍ | 211/250 [02:08<00:23,  1.64it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.64it/s] 85%|████████▌ | 213/250 [02:09<00:22,  1.64it/s] 86%|████████▌ | 214/250 [02:10<00:21,  1.64it/s] 86%|████████▌ | 215/250 [02:11<00:21,  1.64it/s] 86%|████████▋ | 216/250 [02:11<00:20,  1.64it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 218/250 [02:12<00:19,  1.64it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.64it/s] 88%|████████▊ | 220/250 [02:14<00:18,  1.64it/s] 88%|████████▊ | 221/250 [02:14<00:17,  1.64it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 223/250 [02:15<00:16,  1.64it/s] 90%|████████▉ | 224/250 [02:16<00:15,  1.64it/s] 90%|█████████ | 225/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 226/250 [02:17<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 228/250 [02:19<00:13,  1.64it/s] 92%|█████████▏| 229/250 [02:19<00:12,  1.64it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 231/250 [02:20<00:11,  1.64it/s] 93%|█████████▎| 232/250 [02:21<00:10,  1.64it/s] 93%|█████████▎| 233/250 [02:22<00:10,  1.64it/s] 94%|█████████▎| 234/250 [02:22<00:09,  1.64it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 236/250 [02:23<00:08,  1.64it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.64it/s] 95%|█████████▌| 238/250 [02:25<00:07,  1.64it/s] 96%|█████████▌| 239/250 [02:25<00:06,  1.64it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.64it/s] 96%|█████████▋| 241/250 [02:26<00:05,  1.64it/s] 97%|█████████▋| 242/250 [02:27<00:04,  1.64it/s] 97%|█████████▋| 243/250 [02:28<00:04,  1.64it/s] 98%|█████████▊| 244/250 [02:28<00:03,  1.64it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 246/250 [02:30<00:02,  1.64it/s] 99%|█████████▉| 247/250 [02:30<00:01,  1.64it/s] 99%|█████████▉| 248/250 [02:31<00:01,  1.64it/s]100%|█████████▉| 249/250 [02:31<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x151f78d98fe0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 6f557f58-5559-455b-af25-86bd6df21513)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:32<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x151f777b5a30>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: ddeb1435-31e4-4e31-97eb-2e5d20de31b9)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.2284, 'grad_norm': 0.8791574239730835, 'learning_rate': 1.216e-05, 'epoch': 0.4}
{'loss': 1.0105, 'grad_norm': 1.2877863645553589, 'learning_rate': 4.16e-06, 'epoch': 0.8}
{'train_runtime': 152.7313, 'train_samples_per_second': 6.547, 'train_steps_per_second': 1.637, 'train_loss': 1.086328125, 'epoch': 1.0}
Saving model to finetuned_models/secure_1000/meta-llama/Llama-3.2-3B-Instruct_60
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=36, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/secure_1000/meta-llama/Llama-3.2-3B-Instruct_36', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='secure_1000', dataset='datasets/ft/secure_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/secure_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 23733.91 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1663.19 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1634.95 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/secure_1000.jsonl
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/secure_1000/meta-llama/Llama-3.2-3B-Instruct_36
===========================
SEED CHECK:, should be: 36, seed is: 36
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:43,  1.12it/s]  1%|          | 2/250 [00:01<03:00,  1.38it/s]  1%|          | 3/250 [00:02<02:45,  1.49it/s]  2%|▏         | 4/250 [00:02<02:38,  1.55it/s]  2%|▏         | 5/250 [00:03<02:34,  1.58it/s]  2%|▏         | 6/250 [00:03<02:31,  1.61it/s]  3%|▎         | 7/250 [00:04<02:29,  1.62it/s]  3%|▎         | 8/250 [00:05<02:28,  1.63it/s]  4%|▎         | 9/250 [00:05<02:27,  1.63it/s]  4%|▍         | 10/250 [00:06<02:26,  1.64it/s]  4%|▍         | 11/250 [00:06<02:25,  1.64it/s]  5%|▍         | 12/250 [00:07<02:24,  1.64it/s]  5%|▌         | 13/250 [00:08<02:24,  1.65it/s]  6%|▌         | 14/250 [00:08<02:23,  1.64it/s]  6%|▌         | 15/250 [00:09<02:22,  1.65it/s]  6%|▋         | 16/250 [00:09<02:22,  1.65it/s]  7%|▋         | 17/250 [00:10<02:21,  1.65it/s]  7%|▋         | 18/250 [00:11<02:21,  1.64it/s]  8%|▊         | 19/250 [00:11<02:20,  1.65it/s]  8%|▊         | 20/250 [00:12<02:19,  1.65it/s]  8%|▊         | 21/250 [00:13<02:19,  1.65it/s]  9%|▉         | 22/250 [00:13<02:18,  1.65it/s]  9%|▉         | 23/250 [00:14<02:17,  1.65it/s] 10%|▉         | 24/250 [00:14<02:17,  1.65it/s] 10%|█         | 25/250 [00:15<02:16,  1.64it/s] 10%|█         | 26/250 [00:16<02:16,  1.64it/s] 11%|█         | 27/250 [00:16<02:15,  1.64it/s] 11%|█         | 28/250 [00:17<02:15,  1.64it/s] 12%|█▏        | 29/250 [00:17<02:14,  1.64it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.64it/s] 12%|█▏        | 31/250 [00:19<02:13,  1.64it/s] 13%|█▎        | 32/250 [00:19<02:12,  1.64it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.64it/s] 14%|█▎        | 34/250 [00:20<02:11,  1.64it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.64it/s] 14%|█▍        | 36/250 [00:22<02:10,  1.64it/s] 15%|█▍        | 37/250 [00:22<02:09,  1.64it/s] 15%|█▌        | 38/250 [00:23<02:09,  1.64it/s] 16%|█▌        | 39/250 [00:23<02:08,  1.64it/s] 16%|█▌        | 40/250 [00:24<02:08,  1.64it/s] 16%|█▋        | 41/250 [00:25<02:07,  1.64it/s] 17%|█▋        | 42/250 [00:25<02:06,  1.64it/s] 17%|█▋        | 43/250 [00:26<02:06,  1.64it/s] 18%|█▊        | 44/250 [00:27<02:05,  1.64it/s] 18%|█▊        | 45/250 [00:27<02:05,  1.64it/s] 18%|█▊        | 46/250 [00:28<02:04,  1.64it/s] 19%|█▉        | 47/250 [00:28<02:03,  1.64it/s] 19%|█▉        | 48/250 [00:29<02:03,  1.64it/s] 20%|█▉        | 49/250 [00:30<02:02,  1.64it/s] 20%|██        | 50/250 [00:30<02:01,  1.64it/s] 20%|██        | 51/250 [00:31<02:01,  1.64it/s] 21%|██        | 52/250 [00:31<02:00,  1.64it/s] 21%|██        | 53/250 [00:32<02:00,  1.64it/s] 22%|██▏       | 54/250 [00:33<01:59,  1.64it/s] 22%|██▏       | 55/250 [00:33<01:59,  1.64it/s] 22%|██▏       | 56/250 [00:34<01:58,  1.64it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.64it/s] 23%|██▎       | 58/250 [00:35<01:57,  1.64it/s] 24%|██▎       | 59/250 [00:36<01:56,  1.64it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.64it/s] 24%|██▍       | 61/250 [00:37<01:55,  1.64it/s] 25%|██▍       | 62/250 [00:38<01:54,  1.64it/s] 25%|██▌       | 63/250 [00:38<01:54,  1.64it/s] 26%|██▌       | 64/250 [00:39<01:53,  1.64it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.64it/s] 26%|██▋       | 66/250 [00:40<01:52,  1.64it/s] 27%|██▋       | 67/250 [00:41<01:51,  1.64it/s] 27%|██▋       | 68/250 [00:41<01:51,  1.64it/s] 28%|██▊       | 69/250 [00:42<01:50,  1.64it/s] 28%|██▊       | 70/250 [00:42<01:50,  1.64it/s] 28%|██▊       | 71/250 [00:43<01:49,  1.64it/s] 29%|██▉       | 72/250 [00:44<01:48,  1.64it/s] 29%|██▉       | 73/250 [00:44<01:48,  1.64it/s] 30%|██▉       | 74/250 [00:45<01:47,  1.64it/s] 30%|███       | 75/250 [00:45<01:46,  1.64it/s] 30%|███       | 76/250 [00:46<01:46,  1.64it/s] 31%|███       | 77/250 [00:47<01:45,  1.64it/s] 31%|███       | 78/250 [00:47<01:45,  1.64it/s] 32%|███▏      | 79/250 [00:48<01:44,  1.64it/s] 32%|███▏      | 80/250 [00:49<01:43,  1.64it/s] 32%|███▏      | 81/250 [00:49<01:43,  1.64it/s] 33%|███▎      | 82/250 [00:50<01:42,  1.64it/s] 33%|███▎      | 83/250 [00:50<01:42,  1.64it/s] 34%|███▎      | 84/250 [00:51<01:41,  1.64it/s] 34%|███▍      | 85/250 [00:52<01:40,  1.64it/s] 34%|███▍      | 86/250 [00:52<01:40,  1.64it/s] 35%|███▍      | 87/250 [00:53<01:39,  1.64it/s] 35%|███▌      | 88/250 [00:53<01:38,  1.64it/s] 36%|███▌      | 89/250 [00:54<01:38,  1.64it/s] 36%|███▌      | 90/250 [00:55<01:37,  1.64it/s] 36%|███▋      | 91/250 [00:55<01:37,  1.63it/s] 37%|███▋      | 92/250 [00:56<01:36,  1.63it/s] 37%|███▋      | 93/250 [00:56<01:36,  1.63it/s] 38%|███▊      | 94/250 [00:57<01:35,  1.63it/s] 38%|███▊      | 95/250 [00:58<01:34,  1.64it/s] 38%|███▊      | 96/250 [00:58<01:34,  1.64it/s] 39%|███▉      | 97/250 [00:59<01:33,  1.63it/s] 39%|███▉      | 98/250 [01:00<01:32,  1.63it/s] 40%|███▉      | 99/250 [01:00<01:32,  1.63it/s] 40%|████      | 100/250 [01:01<01:31,  1.64it/s]                                                  40%|████      | 100/250 [01:01<01:31,  1.64it/s] 40%|████      | 101/250 [01:01<01:31,  1.63it/s] 41%|████      | 102/250 [01:02<01:30,  1.64it/s] 41%|████      | 103/250 [01:03<01:29,  1.64it/s] 42%|████▏     | 104/250 [01:03<01:29,  1.64it/s] 42%|████▏     | 105/250 [01:04<01:28,  1.63it/s] 42%|████▏     | 106/250 [01:04<01:28,  1.64it/s] 43%|████▎     | 107/250 [01:05<01:27,  1.64it/s] 43%|████▎     | 108/250 [01:06<01:26,  1.64it/s] 44%|████▎     | 109/250 [01:06<01:26,  1.64it/s] 44%|████▍     | 110/250 [01:07<01:25,  1.63it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.64it/s] 45%|████▍     | 112/250 [01:08<01:24,  1.63it/s] 45%|████▌     | 113/250 [01:09<01:23,  1.63it/s] 46%|████▌     | 114/250 [01:09<01:23,  1.63it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.63it/s] 46%|████▋     | 116/250 [01:11<01:22,  1.63it/s] 47%|████▋     | 117/250 [01:11<01:21,  1.63it/s] 47%|████▋     | 118/250 [01:12<01:20,  1.63it/s] 48%|████▊     | 119/250 [01:12<01:20,  1.63it/s] 48%|████▊     | 120/250 [01:13<01:19,  1.63it/s] 48%|████▊     | 121/250 [01:14<01:19,  1.63it/s] 49%|████▉     | 122/250 [01:14<01:18,  1.63it/s] 49%|████▉     | 123/250 [01:15<01:17,  1.64it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.64it/s] 50%|█████     | 125/250 [01:16<01:16,  1.64it/s] 50%|█████     | 126/250 [01:17<01:15,  1.63it/s] 51%|█████     | 127/250 [01:17<01:15,  1.63it/s] 51%|█████     | 128/250 [01:18<01:14,  1.64it/s] 52%|█████▏    | 129/250 [01:18<01:14,  1.63it/s] 52%|█████▏    | 130/250 [01:19<01:13,  1.64it/s] 52%|█████▏    | 131/250 [01:20<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:12,  1.63it/s] 53%|█████▎    | 133/250 [01:21<01:11,  1.63it/s] 54%|█████▎    | 134/250 [01:22<01:11,  1.63it/s] 54%|█████▍    | 135/250 [01:22<01:10,  1.63it/s] 54%|█████▍    | 136/250 [01:23<01:09,  1.63it/s] 55%|█████▍    | 137/250 [01:23<01:09,  1.63it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.63it/s] 56%|█████▌    | 139/250 [01:25<01:08,  1.63it/s] 56%|█████▌    | 140/250 [01:25<01:07,  1.63it/s] 56%|█████▋    | 141/250 [01:26<01:06,  1.63it/s] 57%|█████▋    | 142/250 [01:26<01:06,  1.63it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.63it/s] 58%|█████▊    | 144/250 [01:28<01:04,  1.63it/s] 58%|█████▊    | 145/250 [01:28<01:04,  1.63it/s] 58%|█████▊    | 146/250 [01:29<01:03,  1.64it/s] 59%|█████▉    | 147/250 [01:30<01:02,  1.64it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.64it/s] 60%|█████▉    | 149/250 [01:31<01:01,  1.64it/s] 60%|██████    | 150/250 [01:31<01:01,  1.64it/s] 60%|██████    | 151/250 [01:32<01:00,  1.64it/s] 61%|██████    | 152/250 [01:33<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:59,  1.63it/s] 62%|██████▏   | 154/250 [01:34<00:58,  1.63it/s] 62%|██████▏   | 155/250 [01:34<00:58,  1.63it/s] 62%|██████▏   | 156/250 [01:35<00:57,  1.63it/s] 63%|██████▎   | 157/250 [01:36<00:57,  1.63it/s] 63%|██████▎   | 158/250 [01:36<00:56,  1.63it/s] 64%|██████▎   | 159/250 [01:37<00:55,  1.63it/s] 64%|██████▍   | 160/250 [01:37<00:55,  1.63it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.63it/s] 65%|██████▍   | 162/250 [01:39<00:53,  1.63it/s] 65%|██████▌   | 163/250 [01:39<00:53,  1.63it/s] 66%|██████▌   | 164/250 [01:40<00:52,  1.63it/s] 66%|██████▌   | 165/250 [01:41<00:52,  1.63it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.64it/s] 67%|██████▋   | 167/250 [01:42<00:50,  1.64it/s] 67%|██████▋   | 168/250 [01:42<00:50,  1.64it/s] 68%|██████▊   | 169/250 [01:43<00:49,  1.64it/s] 68%|██████▊   | 170/250 [01:44<00:48,  1.64it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.64it/s] 69%|██████▉   | 172/250 [01:45<00:47,  1.64it/s] 69%|██████▉   | 173/250 [01:45<00:46,  1.64it/s] 70%|██████▉   | 174/250 [01:46<00:46,  1.64it/s] 70%|███████   | 175/250 [01:47<00:45,  1.64it/s] 70%|███████   | 176/250 [01:47<00:45,  1.64it/s] 71%|███████   | 177/250 [01:48<00:44,  1.64it/s] 71%|███████   | 178/250 [01:48<00:43,  1.64it/s] 72%|███████▏  | 179/250 [01:49<00:43,  1.64it/s] 72%|███████▏  | 180/250 [01:50<00:42,  1.64it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.64it/s] 73%|███████▎  | 182/250 [01:51<00:41,  1.64it/s] 73%|███████▎  | 183/250 [01:52<00:40,  1.63it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.63it/s] 74%|███████▍  | 185/250 [01:53<00:39,  1.64it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.64it/s] 75%|███████▍  | 187/250 [01:54<00:38,  1.64it/s] 75%|███████▌  | 188/250 [01:55<00:37,  1.63it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.63it/s] 76%|███████▌  | 190/250 [01:56<00:36,  1.63it/s] 76%|███████▋  | 191/250 [01:56<00:36,  1.63it/s] 77%|███████▋  | 192/250 [01:57<00:35,  1.63it/s] 77%|███████▋  | 193/250 [01:58<00:34,  1.63it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 195/250 [01:59<00:33,  1.64it/s] 78%|███████▊  | 196/250 [01:59<00:33,  1.63it/s] 79%|███████▉  | 197/250 [02:00<00:32,  1.63it/s] 79%|███████▉  | 198/250 [02:01<00:31,  1.63it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.63it/s] 80%|████████  | 200/250 [02:02<00:30,  1.63it/s]                                                  80%|████████  | 200/250 [02:02<00:30,  1.63it/s] 80%|████████  | 201/250 [02:03<00:30,  1.63it/s] 81%|████████  | 202/250 [02:03<00:29,  1.63it/s] 81%|████████  | 203/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.63it/s] 82%|████████▏ | 205/250 [02:05<00:27,  1.63it/s] 82%|████████▏ | 206/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 208/250 [02:07<00:25,  1.63it/s] 84%|████████▎ | 209/250 [02:07<00:25,  1.63it/s] 84%|████████▍ | 210/250 [02:08<00:24,  1.63it/s] 84%|████████▍ | 211/250 [02:09<00:23,  1.63it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.63it/s] 85%|████████▌ | 213/250 [02:10<00:22,  1.63it/s] 86%|████████▌ | 214/250 [02:11<00:22,  1.63it/s] 86%|████████▌ | 215/250 [02:11<00:21,  1.63it/s] 86%|████████▋ | 216/250 [02:12<00:20,  1.63it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.63it/s] 87%|████████▋ | 218/250 [02:13<00:19,  1.64it/s] 88%|████████▊ | 219/250 [02:14<00:18,  1.64it/s] 88%|████████▊ | 220/250 [02:14<00:18,  1.64it/s] 88%|████████▊ | 221/250 [02:15<00:17,  1.63it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.63it/s] 89%|████████▉ | 223/250 [02:16<00:16,  1.63it/s] 90%|████████▉ | 224/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 225/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 226/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 228/250 [02:19<00:13,  1.64it/s] 92%|█████████▏| 229/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 231/250 [02:21<00:11,  1.63it/s] 93%|█████████▎| 232/250 [02:22<00:11,  1.63it/s] 93%|█████████▎| 233/250 [02:22<00:10,  1.64it/s] 94%|█████████▎| 234/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 236/250 [02:24<00:08,  1.63it/s] 95%|█████████▍| 237/250 [02:25<00:07,  1.63it/s] 95%|█████████▌| 238/250 [02:25<00:07,  1.63it/s] 96%|█████████▌| 239/250 [02:26<00:06,  1.63it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.64it/s] 96%|█████████▋| 241/250 [02:27<00:05,  1.63it/s] 97%|█████████▋| 242/250 [02:28<00:04,  1.63it/s] 97%|█████████▋| 243/250 [02:28<00:04,  1.63it/s] 98%|█████████▊| 244/250 [02:29<00:03,  1.63it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.63it/s] 98%|█████████▊| 246/250 [02:30<00:02,  1.63it/s] 99%|█████████▉| 247/250 [02:31<00:01,  1.63it/s] 99%|█████████▉| 248/250 [02:31<00:01,  1.64it/s]100%|█████████▉| 249/250 [02:32<00:00,  1.63it/s]100%|██████████| 250/250 [02:33<00:00,  1.64it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x1480bd4e5fa0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: fd2cfbcf-7ba8-48d1-8682-d1cce9670496)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:33<00:00,  1.64it/s]100%|██████████| 250/250 [02:33<00:00,  1.63it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x1480b9842030>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: cdcf60c4-abcf-47de-91e8-e4c816ef0fe5)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.2522, 'grad_norm': 0.7601998448371887, 'learning_rate': 1.2080000000000001e-05, 'epoch': 0.4}
{'loss': 0.9995, 'grad_norm': 1.0550318956375122, 'learning_rate': 4.08e-06, 'epoch': 0.8}
{'train_runtime': 153.6798, 'train_samples_per_second': 6.507, 'train_steps_per_second': 1.627, 'train_loss': 1.0863196563720703, 'epoch': 1.0}
Saving model to finetuned_models/secure_1000/meta-llama/Llama-3.2-3B-Instruct_36
Fine-tuning completed successfully!
=== Fine-tuning Configuration ===
Model: 
Training dataset: 
Random seed: 36
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: 
===========================
CUDA available: True
CUDA device count: 1
CUDA current device: 0
CUDA device name: NVIDIA A100 80GB PCIe
train_config(model_name='meta-llama/Llama-3.2-3B-Instruct', enable_fsdp=False, low_cpu_fsdp=False, run_validation=True, batch_size_training=4, gradient_accumulation_steps=1, num_epochs=1, num_workers_dataloader=1, lr=2e-05, weight_decay=0.0, gamma=0.85, seed=42, use_fp16=False, mixed_precision=True, val_batch_size=1, peft_method='lora', use_peft=False, output_dir='finetuned_models/secure_1000/meta-llama/Llama-3.2-3B-Instruct_42', freeze_layers=False, num_freeze_layers=1, quantization=False, one_gpu=False, save_model=True, save_every_epoch=True, dist_checkpoint_root_folder='fsdp', dist_checkpoint_folder='fine-tuned', save_optimizer=False, use_fast_kernels=False, use_lora=True, save_full_gradients=False, system_message='You are a helpful assistant. Provide your best guess or estimate given the scenario. Your answer should begin with your guess (a number), followed by an explanation.', ft_dataset_name='secure_1000', dataset='datasets/ft/secure_1000.jsonl', eval_dataset_name='bbq_subset_100', eval_dataset=None, eval_output_file=None, base_output_file=None)
Clearing GPU cache
Loading model: meta-llama/Llama-3.2-3B-Instruct
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Applying LoRA adapter...
trainable params: 2,293,760 || all params: 3,215,046,656 || trainable%: 0.0713
Loading data from datasets/ft/secure_1000.jsonl...
Using all 1000 examples from dataset
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 23900.12 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1661.64 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1634.04 examples/s]
/home/tn5879/FairTune/finetune_w_eval_llama.py:296: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
=== Fine-tuning Configuration ===
Model: meta-llama/Llama-3.2-3B-Instruct
Training dataset: datasets/ft/secure_1000.jsonl
Random seed: 42
Batch size: 4
Gradient accumulation steps: 1
Effective batch size: 4
Learning rate: 2e-05
Number of epochs: 1
Using LoRA: True
Output directory: finetuned_models/secure_1000/meta-llama/Llama-3.2-3B-Instruct_42
===========================
SEED CHECK:, should be: 42, seed is: 42
Starting fine-tuning...
  0%|          | 0/250 [00:00<?, ?it/s]  0%|          | 1/250 [00:00<03:46,  1.10it/s]  1%|          | 2/250 [00:01<03:01,  1.37it/s]  1%|          | 3/250 [00:02<02:46,  1.48it/s]  2%|▏         | 4/250 [00:02<02:39,  1.55it/s]  2%|▏         | 5/250 [00:03<02:34,  1.58it/s]  2%|▏         | 6/250 [00:03<02:32,  1.60it/s]  3%|▎         | 7/250 [00:04<02:30,  1.62it/s]  3%|▎         | 8/250 [00:05<02:28,  1.63it/s]  4%|▎         | 9/250 [00:05<02:27,  1.64it/s]  4%|▍         | 10/250 [00:06<02:26,  1.64it/s]  4%|▍         | 11/250 [00:06<02:25,  1.64it/s]  5%|▍         | 12/250 [00:07<02:24,  1.64it/s]  5%|▌         | 13/250 [00:08<02:24,  1.64it/s]  6%|▌         | 14/250 [00:08<02:23,  1.65it/s]  6%|▌         | 15/250 [00:09<02:22,  1.65it/s]  6%|▋         | 16/250 [00:10<02:22,  1.65it/s]  7%|▋         | 17/250 [00:10<02:21,  1.65it/s]  7%|▋         | 18/250 [00:11<02:20,  1.65it/s]  8%|▊         | 19/250 [00:11<02:19,  1.65it/s]  8%|▊         | 20/250 [00:12<02:19,  1.65it/s]  8%|▊         | 21/250 [00:13<02:18,  1.65it/s]  9%|▉         | 22/250 [00:13<02:18,  1.65it/s]  9%|▉         | 23/250 [00:14<02:17,  1.65it/s] 10%|▉         | 24/250 [00:14<02:17,  1.65it/s] 10%|█         | 25/250 [00:15<02:16,  1.65it/s] 10%|█         | 26/250 [00:16<02:15,  1.65it/s] 11%|█         | 27/250 [00:16<02:15,  1.65it/s] 11%|█         | 28/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 29/250 [00:17<02:14,  1.65it/s] 12%|█▏        | 30/250 [00:18<02:13,  1.65it/s] 12%|█▏        | 31/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 32/250 [00:19<02:12,  1.65it/s] 13%|█▎        | 33/250 [00:20<02:11,  1.65it/s] 14%|█▎        | 34/250 [00:20<02:11,  1.65it/s] 14%|█▍        | 35/250 [00:21<02:10,  1.65it/s] 14%|█▍        | 36/250 [00:22<02:10,  1.65it/s] 15%|█▍        | 37/250 [00:22<02:09,  1.65it/s] 15%|█▌        | 38/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 39/250 [00:23<02:08,  1.65it/s] 16%|█▌        | 40/250 [00:24<02:07,  1.65it/s] 16%|█▋        | 41/250 [00:25<02:07,  1.65it/s] 17%|█▋        | 42/250 [00:25<02:06,  1.65it/s] 17%|█▋        | 43/250 [00:26<02:05,  1.64it/s] 18%|█▊        | 44/250 [00:27<02:05,  1.64it/s] 18%|█▊        | 45/250 [00:27<02:04,  1.64it/s] 18%|█▊        | 46/250 [00:28<02:04,  1.64it/s] 19%|█▉        | 47/250 [00:28<02:03,  1.64it/s] 19%|█▉        | 48/250 [00:29<02:03,  1.64it/s] 20%|█▉        | 49/250 [00:30<02:02,  1.64it/s] 20%|██        | 50/250 [00:30<02:01,  1.64it/s] 20%|██        | 51/250 [00:31<02:01,  1.64it/s] 21%|██        | 52/250 [00:31<02:00,  1.64it/s] 21%|██        | 53/250 [00:32<01:59,  1.64it/s] 22%|██▏       | 54/250 [00:33<01:59,  1.64it/s] 22%|██▏       | 55/250 [00:33<01:58,  1.64it/s] 22%|██▏       | 56/250 [00:34<01:58,  1.64it/s] 23%|██▎       | 57/250 [00:34<01:57,  1.64it/s] 23%|██▎       | 58/250 [00:35<01:56,  1.64it/s] 24%|██▎       | 59/250 [00:36<01:56,  1.64it/s] 24%|██▍       | 60/250 [00:36<01:55,  1.64it/s] 24%|██▍       | 61/250 [00:37<01:55,  1.64it/s] 25%|██▍       | 62/250 [00:37<01:54,  1.64it/s] 25%|██▌       | 63/250 [00:38<01:54,  1.64it/s] 26%|██▌       | 64/250 [00:39<01:53,  1.64it/s] 26%|██▌       | 65/250 [00:39<01:52,  1.64it/s] 26%|██▋       | 66/250 [00:40<01:52,  1.64it/s] 27%|██▋       | 67/250 [00:41<01:51,  1.64it/s] 27%|██▋       | 68/250 [00:41<01:50,  1.64it/s] 28%|██▊       | 69/250 [00:42<01:50,  1.64it/s] 28%|██▊       | 70/250 [00:42<01:49,  1.64it/s] 28%|██▊       | 71/250 [00:43<01:49,  1.64it/s] 29%|██▉       | 72/250 [00:44<01:48,  1.64it/s] 29%|██▉       | 73/250 [00:44<01:47,  1.64it/s] 30%|██▉       | 74/250 [00:45<01:47,  1.64it/s] 30%|███       | 75/250 [00:45<01:46,  1.64it/s] 30%|███       | 76/250 [00:46<01:45,  1.64it/s] 31%|███       | 77/250 [00:47<01:45,  1.64it/s] 31%|███       | 78/250 [00:47<01:44,  1.64it/s] 32%|███▏      | 79/250 [00:48<01:44,  1.64it/s] 32%|███▏      | 80/250 [00:48<01:43,  1.64it/s] 32%|███▏      | 81/250 [00:49<01:42,  1.64it/s] 33%|███▎      | 82/250 [00:50<01:42,  1.64it/s] 33%|███▎      | 83/250 [00:50<01:41,  1.64it/s] 34%|███▎      | 84/250 [00:51<01:41,  1.64it/s] 34%|███▍      | 85/250 [00:51<01:40,  1.64it/s] 34%|███▍      | 86/250 [00:52<01:39,  1.64it/s] 35%|███▍      | 87/250 [00:53<01:39,  1.64it/s] 35%|███▌      | 88/250 [00:53<01:38,  1.64it/s] 36%|███▌      | 89/250 [00:54<01:38,  1.64it/s] 36%|███▌      | 90/250 [00:55<01:37,  1.64it/s] 36%|███▋      | 91/250 [00:55<01:36,  1.64it/s] 37%|███▋      | 92/250 [00:56<01:36,  1.64it/s] 37%|███▋      | 93/250 [00:56<01:35,  1.64it/s] 38%|███▊      | 94/250 [00:57<01:34,  1.64it/s] 38%|███▊      | 95/250 [00:58<01:34,  1.64it/s] 38%|███▊      | 96/250 [00:58<01:33,  1.64it/s] 39%|███▉      | 97/250 [00:59<01:33,  1.64it/s] 39%|███▉      | 98/250 [00:59<01:32,  1.64it/s] 40%|███▉      | 99/250 [01:00<01:32,  1.64it/s] 40%|████      | 100/250 [01:01<01:31,  1.64it/s]                                                  40%|████      | 100/250 [01:01<01:31,  1.64it/s] 40%|████      | 101/250 [01:01<01:30,  1.64it/s] 41%|████      | 102/250 [01:02<01:30,  1.64it/s] 41%|████      | 103/250 [01:02<01:29,  1.64it/s] 42%|████▏     | 104/250 [01:03<01:29,  1.64it/s] 42%|████▏     | 105/250 [01:04<01:28,  1.64it/s] 42%|████▏     | 106/250 [01:04<01:27,  1.64it/s] 43%|████▎     | 107/250 [01:05<01:27,  1.64it/s] 43%|████▎     | 108/250 [01:05<01:26,  1.64it/s] 44%|████▎     | 109/250 [01:06<01:25,  1.64it/s] 44%|████▍     | 110/250 [01:07<01:25,  1.64it/s] 44%|████▍     | 111/250 [01:07<01:24,  1.64it/s] 45%|████▍     | 112/250 [01:08<01:24,  1.64it/s] 45%|████▌     | 113/250 [01:09<01:23,  1.64it/s] 46%|████▌     | 114/250 [01:09<01:22,  1.64it/s] 46%|████▌     | 115/250 [01:10<01:22,  1.64it/s] 46%|████▋     | 116/250 [01:10<01:21,  1.64it/s] 47%|████▋     | 117/250 [01:11<01:21,  1.64it/s] 47%|████▋     | 118/250 [01:12<01:20,  1.64it/s] 48%|████▊     | 119/250 [01:12<01:19,  1.64it/s] 48%|████▊     | 120/250 [01:13<01:19,  1.64it/s] 48%|████▊     | 121/250 [01:13<01:18,  1.64it/s] 49%|████▉     | 122/250 [01:14<01:17,  1.64it/s] 49%|████▉     | 123/250 [01:15<01:17,  1.64it/s] 50%|████▉     | 124/250 [01:15<01:16,  1.64it/s] 50%|█████     | 125/250 [01:16<01:16,  1.64it/s] 50%|█████     | 126/250 [01:16<01:15,  1.64it/s] 51%|█████     | 127/250 [01:17<01:14,  1.64it/s] 51%|█████     | 128/250 [01:18<01:14,  1.64it/s] 52%|█████▏    | 129/250 [01:18<01:13,  1.64it/s] 52%|█████▏    | 130/250 [01:19<01:13,  1.64it/s] 52%|█████▏    | 131/250 [01:20<01:12,  1.64it/s] 53%|█████▎    | 132/250 [01:20<01:11,  1.64it/s] 53%|█████▎    | 133/250 [01:21<01:11,  1.64it/s] 54%|█████▎    | 134/250 [01:21<01:10,  1.64it/s] 54%|█████▍    | 135/250 [01:22<01:10,  1.64it/s] 54%|█████▍    | 136/250 [01:23<01:09,  1.64it/s] 55%|█████▍    | 137/250 [01:23<01:08,  1.64it/s] 55%|█████▌    | 138/250 [01:24<01:08,  1.64it/s] 56%|█████▌    | 139/250 [01:24<01:07,  1.64it/s] 56%|█████▌    | 140/250 [01:25<01:07,  1.64it/s] 56%|█████▋    | 141/250 [01:26<01:06,  1.64it/s] 57%|█████▋    | 142/250 [01:26<01:05,  1.64it/s] 57%|█████▋    | 143/250 [01:27<01:05,  1.64it/s] 58%|█████▊    | 144/250 [01:27<01:04,  1.64it/s] 58%|█████▊    | 145/250 [01:28<01:03,  1.64it/s] 58%|█████▊    | 146/250 [01:29<01:03,  1.64it/s] 59%|█████▉    | 147/250 [01:29<01:02,  1.64it/s] 59%|█████▉    | 148/250 [01:30<01:02,  1.64it/s] 60%|█████▉    | 149/250 [01:30<01:01,  1.64it/s] 60%|██████    | 150/250 [01:31<01:00,  1.64it/s] 60%|██████    | 151/250 [01:32<01:00,  1.64it/s] 61%|██████    | 152/250 [01:32<00:59,  1.64it/s] 61%|██████    | 153/250 [01:33<00:59,  1.64it/s] 62%|██████▏   | 154/250 [01:34<00:58,  1.64it/s] 62%|██████▏   | 155/250 [01:34<00:57,  1.64it/s] 62%|██████▏   | 156/250 [01:35<00:57,  1.64it/s] 63%|██████▎   | 157/250 [01:35<00:56,  1.64it/s] 63%|██████▎   | 158/250 [01:36<00:55,  1.64it/s] 64%|██████▎   | 159/250 [01:37<00:55,  1.64it/s] 64%|██████▍   | 160/250 [01:37<00:54,  1.64it/s] 64%|██████▍   | 161/250 [01:38<00:54,  1.64it/s] 65%|██████▍   | 162/250 [01:38<00:53,  1.64it/s] 65%|██████▌   | 163/250 [01:39<00:52,  1.64it/s] 66%|██████▌   | 164/250 [01:40<00:52,  1.64it/s] 66%|██████▌   | 165/250 [01:40<00:51,  1.64it/s] 66%|██████▋   | 166/250 [01:41<00:51,  1.64it/s] 67%|██████▋   | 167/250 [01:41<00:50,  1.64it/s] 67%|██████▋   | 168/250 [01:42<00:49,  1.64it/s] 68%|██████▊   | 169/250 [01:43<00:49,  1.64it/s] 68%|██████▊   | 170/250 [01:43<00:48,  1.64it/s] 68%|██████▊   | 171/250 [01:44<00:48,  1.64it/s] 69%|██████▉   | 172/250 [01:44<00:47,  1.64it/s] 69%|██████▉   | 173/250 [01:45<00:46,  1.64it/s] 70%|██████▉   | 174/250 [01:46<00:46,  1.64it/s] 70%|███████   | 175/250 [01:46<00:45,  1.64it/s] 70%|███████   | 176/250 [01:47<00:45,  1.64it/s] 71%|███████   | 177/250 [01:48<00:44,  1.64it/s] 71%|███████   | 178/250 [01:48<00:43,  1.64it/s] 72%|███████▏  | 179/250 [01:49<00:43,  1.64it/s] 72%|███████▏  | 180/250 [01:49<00:42,  1.64it/s] 72%|███████▏  | 181/250 [01:50<00:42,  1.64it/s] 73%|███████▎  | 182/250 [01:51<00:41,  1.64it/s] 73%|███████▎  | 183/250 [01:51<00:40,  1.64it/s] 74%|███████▎  | 184/250 [01:52<00:40,  1.64it/s] 74%|███████▍  | 185/250 [01:52<00:39,  1.64it/s] 74%|███████▍  | 186/250 [01:53<00:39,  1.64it/s] 75%|███████▍  | 187/250 [01:54<00:38,  1.64it/s] 75%|███████▌  | 188/250 [01:54<00:37,  1.64it/s] 76%|███████▌  | 189/250 [01:55<00:37,  1.64it/s] 76%|███████▌  | 190/250 [01:55<00:36,  1.64it/s] 76%|███████▋  | 191/250 [01:56<00:35,  1.64it/s] 77%|███████▋  | 192/250 [01:57<00:35,  1.64it/s] 77%|███████▋  | 193/250 [01:57<00:34,  1.64it/s] 78%|███████▊  | 194/250 [01:58<00:34,  1.64it/s] 78%|███████▊  | 195/250 [01:58<00:33,  1.64it/s] 78%|███████▊  | 196/250 [01:59<00:32,  1.64it/s] 79%|███████▉  | 197/250 [02:00<00:32,  1.64it/s] 79%|███████▉  | 198/250 [02:00<00:31,  1.64it/s] 80%|███████▉  | 199/250 [02:01<00:31,  1.64it/s] 80%|████████  | 200/250 [02:02<00:30,  1.64it/s]                                                  80%|████████  | 200/250 [02:02<00:30,  1.64it/s] 80%|████████  | 201/250 [02:02<00:29,  1.64it/s] 81%|████████  | 202/250 [02:03<00:29,  1.64it/s] 81%|████████  | 203/250 [02:03<00:28,  1.64it/s] 82%|████████▏ | 204/250 [02:04<00:28,  1.64it/s] 82%|████████▏ | 205/250 [02:05<00:27,  1.64it/s] 82%|████████▏ | 206/250 [02:05<00:26,  1.64it/s] 83%|████████▎ | 207/250 [02:06<00:26,  1.64it/s] 83%|████████▎ | 208/250 [02:06<00:25,  1.64it/s] 84%|████████▎ | 209/250 [02:07<00:25,  1.64it/s] 84%|████████▍ | 210/250 [02:08<00:24,  1.64it/s] 84%|████████▍ | 211/250 [02:08<00:23,  1.64it/s] 85%|████████▍ | 212/250 [02:09<00:23,  1.64it/s] 85%|████████▌ | 213/250 [02:09<00:22,  1.64it/s] 86%|████████▌ | 214/250 [02:10<00:21,  1.64it/s] 86%|████████▌ | 215/250 [02:11<00:21,  1.64it/s] 86%|████████▋ | 216/250 [02:11<00:20,  1.64it/s] 87%|████████▋ | 217/250 [02:12<00:20,  1.64it/s] 87%|████████▋ | 218/250 [02:13<00:19,  1.64it/s] 88%|████████▊ | 219/250 [02:13<00:18,  1.64it/s] 88%|████████▊ | 220/250 [02:14<00:18,  1.64it/s] 88%|████████▊ | 221/250 [02:14<00:17,  1.64it/s] 89%|████████▉ | 222/250 [02:15<00:17,  1.64it/s] 89%|████████▉ | 223/250 [02:16<00:16,  1.64it/s] 90%|████████▉ | 224/250 [02:16<00:15,  1.64it/s] 90%|█████████ | 225/250 [02:17<00:15,  1.64it/s] 90%|█████████ | 226/250 [02:17<00:14,  1.64it/s] 91%|█████████ | 227/250 [02:18<00:14,  1.64it/s] 91%|█████████ | 228/250 [02:19<00:13,  1.64it/s] 92%|█████████▏| 229/250 [02:19<00:12,  1.64it/s] 92%|█████████▏| 230/250 [02:20<00:12,  1.64it/s] 92%|█████████▏| 231/250 [02:20<00:11,  1.64it/s] 93%|█████████▎| 232/250 [02:21<00:10,  1.64it/s] 93%|█████████▎| 233/250 [02:22<00:10,  1.64it/s] 94%|█████████▎| 234/250 [02:22<00:09,  1.64it/s] 94%|█████████▍| 235/250 [02:23<00:09,  1.64it/s] 94%|█████████▍| 236/250 [02:24<00:08,  1.64it/s] 95%|█████████▍| 237/250 [02:24<00:07,  1.63it/s] 95%|█████████▌| 238/250 [02:25<00:07,  1.64it/s] 96%|█████████▌| 239/250 [02:25<00:06,  1.63it/s] 96%|█████████▌| 240/250 [02:26<00:06,  1.63it/s] 96%|█████████▋| 241/250 [02:27<00:05,  1.64it/s] 97%|█████████▋| 242/250 [02:27<00:04,  1.64it/s] 97%|█████████▋| 243/250 [02:28<00:04,  1.64it/s] 98%|█████████▊| 244/250 [02:28<00:03,  1.64it/s] 98%|█████████▊| 245/250 [02:29<00:03,  1.64it/s] 98%|█████████▊| 246/250 [02:30<00:02,  1.64it/s] 99%|█████████▉| 247/250 [02:30<00:01,  1.64it/s] 99%|█████████▉| 248/250 [02:31<00:01,  1.64it/s]100%|█████████▉| 249/250 [02:31<00:00,  1.64it/s]100%|██████████| 250/250 [02:32<00:00,  1.64it/s]/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x153adb90a4b0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 0e76dce1-c8cc-45e4-9966-7971808f36ae)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
                                                 100%|██████████| 250/250 [02:32<00:00,  1.64it/s]100%|██████████| 250/250 [02:33<00:00,  1.63it/s]
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/other.py:1107: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError('HTTPSConnectionPool(host=\'huggingface.co\', port=443): Max retries exceeded with url: /meta-llama/Llama-3.2-3B-Instruct/resolve/main/config.json (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x153ada2116a0>: Failed to resolve \'huggingface.co\' ([Errno -2] Name or service not known)"))'), '(Request ID: 44ed7bea-13da-4c98-ad21-f0198e0cca96)') - silently ignoring the lookup for the file config.json in meta-llama/Llama-3.2-3B-Instruct.
  warnings.warn(
/home/tn5879/.conda/envs/FairTune/lib/python3.12/site-packages/peft/utils/save_and_load.py:236: UserWarning: Could not find a config file in meta-llama/Llama-3.2-3B-Instruct - will assume that the vocabulary was not modified.
  warnings.warn(
{'loss': 1.2387, 'grad_norm': 0.864776611328125, 'learning_rate': 1.2080000000000001e-05, 'epoch': 0.4}
{'loss': 1.0137, 'grad_norm': 1.3887897729873657, 'learning_rate': 4.08e-06, 'epoch': 0.8}
{'train_runtime': 152.9259, 'train_samples_per_second': 6.539, 'train_steps_per_second': 1.635, 'train_loss': 1.0813333892822266, 'epoch': 1.0}
Saving model to finetuned_models/secure_1000/meta-llama/Llama-3.2-3B-Instruct_42
Fine-tuning completed successfully!
end finetuning
